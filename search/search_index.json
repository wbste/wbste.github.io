{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>This site will be for playing around and testing workflows, and maybe documenting things that a quick search didn't reveal. Thanks to Material for MkDocs, MkDocs, and omg.lol for making this easy!</p> <p>Useful keyboard shortcuts while on this site include... - <code>s</code> for search - or <code>f</code> for find - <code>n</code> for next page - <code>p</code> for previous page</p>"},{"location":"AI/Ask/","title":"Ask","text":"<p>Notes on setting up the MIT-licensed Danswer. From the GitHub page, Danswer lets you ask questions in natural language and get back answers based on your team specific documents. Think ChatGPT if it had access to your team's unique knowledge. Connects to all common workplace tools such as Slack, Google Drive, Confluence, etc.</p> <p>It also serves as a basic chatbot as well (without using any docs). A lot of the below comes straight from their website. I copied the important bits below, just in case it gets tweaked in the future and links change.</p> <p></p>"},{"location":"AI/Ask/#Setup","title":"Setup","text":"<p>Quickstart was pretty good; here are some addition notes.</p> <ol> <li>Clone the Danswer repo:</li> </ol> <pre><code>git clone https://github.com/danswer-ai/danswer.git\n</code></pre> <ol> <li>Navigate to danswer/deployment/docker_compose</li> </ol> <pre><code>cd danswer/deployment/docker_compose\n</code></pre> <ol> <li>Bring up your docker engine and run:</li> </ol> <p>To pull images from DockerHub and run Danswer:    </p> <pre><code>docker compose -f docker-compose.dev.yml -p danswer-stack up -d --pull always --force-recreate\n</code></pre> <p>Alternatively, to build the containers from source and start Danswer, run:</p> <pre><code>docker compose -f docker-compose.dev.yml -p danswer-stack up -d --build --force-recreate\n</code></pre>"},{"location":"AI/Ask/#Details","title":"Details","text":"<p>Defaults to OpenAI, but you need to enter a key. Can tweak to other endpoints as required. For embeddings, those are done within the Docker container via intfloat/e5-base-v2. Some of the connectors create links to the sources, but others like PDFs required custom metadata be added.</p>"},{"location":"AI/Ask/#File%20Uploads","title":"File Uploads","text":"<p>The File Connector indexes user uploaded files. - Currently supports <code>.txt</code>, <code>.pdf</code>, <code>.md</code> and <code>.mdx</code> files - Can also upload a <code>.zip</code> containing these files - If there are other file types in the zip, the other file types are ignored - Optional metadata line that supports links, document owners, and time updated as metadata.</p>"},{"location":"AI/Ask/#Metadata","title":"Metadata","text":"<p>Can add within the file:</p> <ul> <li><code>#DANSWER_METADATA={\"link\": \"&lt;LINK&gt;\"}</code></li> <li><code>&lt;!-- DANSWER_METADATA={\"link\": \"&lt;LINK&gt;\"} --&gt;</code></li> </ul> <p>Where DANSWER_METADATA= is followed by a json. The valid json keys are:</p> <ul> <li>link</li> <li>primary_owners</li> <li>secondary_owners</li> <li>doc_updated_at</li> <li>file_display_name</li> </ul> <p>For example</p> <p><code>#DANSWER_METADATA={\"link\": \"https://github.com/danswer-ai/danswer/blob/main/CONTRIBUTING.md\", \"primary_owners\": [\"yuhong@danswer.ai\", \"chris@danswer.ai\"], \"secondary_owners\": [\"founders@danswer.ai\"], \"doc_updated_at\": \"2023-11-30T13:06:08.589616-08:00\", \"file_display_name\": \"Desired File Name!\", \"tag_of_your_choice\": \"tag_value\"}</code></p> <p>Or as a separate file as shown below:</p> <pre><code>| file1.txt\n| file2.txt\n| .danswer_metadata.json\n</code></pre> <pre><code>[\n    {\n        \"filename\": \"file1.txt\", \n        \"link\": \"&lt;LINK_TO_FILE1&gt;\", \n        \"file_display_name\": \"&lt;WHAT_YOU_WANT_THE_NAME_OF_FILE1_TO_BE_IN_THE_UI&gt;\"},\n        \"primary_owners\": [\"&lt;FILE1_OWNER&gt;\"],\n        // this is an arbitrary tag, can be any key/value pair and can be used in the UI as \n        // a filter if you want to constrain your search / conversation to only documents with\n        // this tag attached\n        \"status\": \"&lt;SOME_STATUS&gt;\"\n    },\n    {\n        \"filename\": \"file2.txt\", \n        \"link\": \"&lt;LINK_TO_FILE2&gt;\", \n        \"file_display_name\": \"&lt;WHAT_YOU_WANT_THE_NAME_OF_FILE2_TO_BE_IN_THE_UI&gt;\"},\n        \"primary_owners\": [\"&lt;FILE2_OWNER&gt;\"],\n        // this is an arbitrary tag, can be any key/value pair and can be used in the UI as \n        // a filter if you want to constrain your search / conversation to only documents with\n        // this tag attached\n        \"status\": \"&lt;SOME_OTHER_STATUS&gt;\"\n    }\n]\n</code></pre>"},{"location":"AI/Ask/#Local%20LLM","title":"Local LLM","text":"<p>I started with <code>env.prod.template</code> as the template, copied it, and renamed it to use <code>.env</code>. Keep it in the same directory as the compose files. Here are the tweaks I made to get it to work on a local server for the LLM, like LM Studio. It's important to note I needed to use <code>http://host.docker.internal:8000/v1</code> so docker could talk to the host.</p> <pre><code>...\nGEN_AI_LLM_PROVIDER_TYPE=openai  # Since it's an OpenAI compatible API\nGEN_AI_MODEL_VERSION=llama2 # Don't think this matters\nGEN_AI_API_KEY=nokeyneeded # Not needed for LM Studio\nGEN_AI_API_ENDPOINT=http://host.docker.internal:8000/v1\n...\n</code></pre> <p>I'm still playing with other recommendations for local models. So far <code>DISABLE_LLM_CHOOSE_SEARCH=True</code> seems like one of the more important ones if you want it to adhere to the docs only.</p> <pre><code>...\n# Let's also make some changes to accommodate the weaker locally hosted LLM\nQA_TIMEOUT=120  # Set a longer timeout, running models on CPU can be slow\n# Always run search, never skip\nDISABLE_LLM_CHOOSE_SEARCH=True\n# Don't use LLM for reranking, the prompts aren't properly tuned for these models\nDISABLE_LLM_CHUNK_FILTER=True\n# Don't try to rephrase the user query, the prompts aren't properly tuned for these models\nDISABLE_LLM_QUERY_REPHRASE=True\n# Don't use LLM to automatically discover time/source filters\nDISABLE_LLM_FILTER_EXTRACTION=True\n# Uncomment this one if you find that the model is struggling (slow or distracted by too many docs)\n# Use only 1 section from the documents and do not require quotes\n# QA_PROMPT_OVERRIDE=weak\n...\n</code></pre>"},{"location":"AI/Ask/#Branding","title":"Branding","text":"<p>Still a WIP, but here's what I found in terms of tweaking the interface. Note you'll have to build it as mentioned above.</p> <ul> <li><code>Danswer\\web\\src\\app\\favicon.ico</code>, fav icon</li> <li><code>Danswer\\web\\src\\app\\layout.tsx</code>, site title and description</li> <li><code>Danswer\\web\\src\\components\\Header.tsx</code>, header name</li> <li><code>Danswer\\web\\public\\logo.png</code>, logo used throughout app</li> <li><code>Danswer\\web\\src\\app\\chat\\ChatIntro.tsx</code>, chat section of app</li> </ul> <p>For the rest it's probably easier to hide then recreate the Danswer persona in the admin panel. You can see the default <code>system</code> and <code>task</code> prompt for Danswer persona in <code>Danswer\\backend\\danswer\\chat\\prompts.yaml</code>, under <code>id: 0</code>.</p> <p></p>"},{"location":"AI/Chat/","title":"Chat","text":"<p>This section has to do with text generation models (same ideas as ChatGPT) that can run 100% local. See Stable Diffusion for the information on image generation AI, 100% local.</p> <p>Want the TL;DR on how to run a model 100% locally?</p> <ol> <li>Regardless if you have a CPU or GPU, download LM Studio. It's the best GUI I've found, and integrates with HuggingFace, can act as a API server, and allows for running on CPU, GPU, or a mix of both.</li> <li>Open the app, and download one of the models on the home page. Smaller models are a good start (something with 2B or 7B in the name).</li> <li>Download the model Quantization Q4_K_M to start with. We can get smaller or larger ones after seeing how this one performs.</li> <li>After it's downloaded it will appear in LM Studio under the \ud83d\udcc2 icon in the app.</li> <li>Click on the \ud83d\udcac icon, New Chat.</li> <li>On the right you may want to select GPU Acceleration under Model Initialization if you have one, and start with 10 layers (we can always modify later).</li> <li>From the top, select one of the models you downloaded and load it.</li> <li>Chat away!</li> </ol> <p>Example</p> <p>What size model should you get? See the below table 4-bit Model Requirements for GPU inference for a starting point. For example, assuming you have at least 32GB RAM and a 3090, you can run a 4-bit 34B with good performance.</p>"},{"location":"AI/Chat/#Models","title":"Models","text":"<ul> <li>Leaderboards here and here</li> <li>TheBloke on \ud83e\udd17 offers great models.</li> </ul> <p>More parameters (i.e. more data) in the model, the higher quality the output. Consumer hardware typically doesn't have the capability to fit the largest models and run them. With some exceptions the typical parameters you can run locally is up to 34B with nice hardware (3090, 32GB Ram). Some do run 70B and 180B parameter models, but that gets into custom built AI machines (64GB+ RAM and 2+ GPUs, or professional level GPUs like the NVIDIA A100). Here's an example of where things stand today. Source.</p> <p></p> <p></p>"},{"location":"AI/Chat/#GUIs","title":"GUIs","text":"<ul> <li>LM Studio<ul> <li>Beta versions here.</li> </ul> </li> <li>Oobabooga</li> </ul>"},{"location":"AI/Chat/#System%20Requirements","title":"System Requirements","text":"<p>Note the below is system RAM.</p> <p>8-bit Model Requirements for GPU inference</p> Model VRAM Used Card examples RAM/Swap to Load* LLaMA 7B / Llama 2 7B 10GB 3060 12GB, 3080 10GB 24 GB LLaMA 13B / Llama 2 13B 20GB 3090, 3090 Ti, 4090 32 GB LLaMA 33B / Llama 2 34B ~40GB A6000 48GB, A100 40GB ~64 GB LLaMA 65B / Llama 2 70B ~80GB A100 80GB ~128 GB <p>4-bit Model Requirements for GPU inference</p> Model Minimum Total VRAM Card examples RAM/Swap to Load* LLaMA 7B / Llama 2 7B 6GB GTX 1660, 2060, AMD 5700 XT, RTX 3050, 3060 6 GB LLaMA 13B / Llama 2 13B 10GB AMD 6900 XT, RTX 2060 12GB, 3060 12GB, 3080, A2000 12 GB LLaMA 33B / Llama 2 34B ~20GB RTX 3080 20GB, A4500, A5000, 3090, 4090, 6000, Tesla V100 ~32 GB LLaMA 65B / Llama 2 70B ~40GB A100 40GB, 2x3090, 2x4090, A40, RTX A6000, 8000 ~64 GB <p>*System RAM, not VRAM, required to load the model, in addition to having enough VRAM. Not required to run the model.</p> <p>llama.cpp Requirements for CPU inference</p> Model Original Size Quantized Size (4-bit) 7B 13 GB 3.9 GB 13B 24 GB 7.8 GB 33B 60 GB 19.5 GB 65B 120 GB 38.5 GB"},{"location":"AI/Chat/#Coding","title":"Coding","text":"<p>Can use LM studio as a local API with a VS Code extension like Continue.</p>"},{"location":"AI/Chat/#Quantization","title":"Quantization","text":"<p>Good read on what this means here.</p> <p>My dumbed down take is this. Imagine the \"full\" model stores a bunch of numbers. BILLIONS of them. Those numbers have a lot of digits hanging off the back (i.e. 3.123982709717963...). That's a lot of data to store when you store a lot of digits like that. but do we need them all? What if we just dropped a bunch of digits towards the end of those numbers? So our new number we store is 3.123982. What if we did it again? At some point the number isn't really close enough to the original number from the full model to be useful. Basically how long can you go on rounding the numbers until they lose their meaning? That's where quantization comes in. Smaller files are easier to run on hardware, but at what point does the model spit out gibberish?</p> <ul> <li>GGUF: Successor to GGML, CPU + GPU inference (you can adjust what percentage of the model is processed by which part). <ul> <li>GGUF is a new format introduced by the llama.cpp team on August 21st 2023. It is a replacement for GGML, which is no longer supported by llama.cpp. The key benefit of GGUF is that it is a extensible, future-proof format which stores more information about the model as metadata. It also includes significantly improved tokenization code, including for the first time full support for special tokens. This should improve performance, especially with models that use new special tokens and implement custom prompt templates.</li> </ul> </li> <li>GGML: CPU + GPU inference (but mostly CPU). No longer supported by llama.cpp, which is the foundation of most of these desktop applications.</li> <li>GPTQ: GPU inference</li> </ul> <p>Note the RAM below can be split between GPU and system RAM, depending on the quantization method used. The below is an extract on a specific model, but should serve as a good guideline in terms of what model quantization are best. The reason a model like <code>Q5_K_M</code> is preferred over <code>Q8_0</code> is because the quality different between the two is so small, loading the larger model doesn't really provide any benefit (it's less than half a percent \"better\" go to with the full model, at the expense of requiring more resources to load and use).</p> Quant method Bits Use case Q2_K 2 smallest, significant quality loss - not recommended Q3_K_S 3 very small, high quality loss Q3_K_M 3 very small, high quality loss Q3_K_L 3 small, substantial quality loss Q4_K_S 4 small, greater quality loss Q4_K_M 4 medium, balanced quality - recommended Q5_K_S 5 large, low quality loss - recommended Q5_K_M 5 large, very low quality loss - recommended Q6_K 6 very large, extremely low quality loss Q8_0 8 very large, extremely low quality loss - not recommended <p>The following new quantization types are added to <code>ggml</code>:</p> <ul> <li><code>GGML_TYPE_Q2_K</code> - \"type-1\" 2-bit quantization in super-blocks containing 16 blocks, each block having 16 weight. Block scales and mins are quantized with 4 bits. This ends up effectively using <code>2.5625</code> bits per weight (bpw)</li> <li><code>GGML_TYPE_Q3_K</code> - \"type-0\" 3-bit quantization in super-blocks containing 16 blocks, each block having 16 weights. Scales are quantized with 6 bits. This end up using <code>3.4375</code> bpw.</li> <li><code>GGML_TYPE_Q4_K</code> - \"type-1\" 4-bit quantization in super-blocks containing 8 blocks, each block having 32 weights. Scales and mins are quantized with 6 bits. This ends up using <code>4.5</code> bpw.</li> <li><code>GGML_TYPE_Q5_K</code> - \"type-1\" 5-bit quantization. Same super-block structure as <code>GGML_TYPE_Q4_K</code> resulting in <code>5.5</code> bpw</li> <li><code>GGML_TYPE_Q6_K</code> - \"type-0\" 6-bit quantization. Super-blocks with 16 blocks, each block having 16 weights. Scales are quantized with 8 bits. This ends up using <code>6.5625</code> bpw</li> <li><code>GGML_TYPE_Q8_K</code> - \"type-0\" 8-bit quantization. Only used for quantizing intermediate results. The difference to the existing <code>Q8_0</code> is that the block size is 256. All 2-6 bit dot products are implemented for this quantization type.</li> </ul> <p>This is exposed via <code>llama.cpp</code> quantization types that define various \"quantization mixes\" as follows:</p> <ul> <li><code>LLAMA_FTYPE_MOSTLY_Q2_K</code> - uses <code>GGML_TYPE_Q4_K</code> for the <code>attention.vw</code> and <code>feed_forward.w2</code> tensors, <code>GGML_TYPE_Q2_K</code> for the other tensors.</li> <li><code>LLAMA_FTYPE_MOSTLY_Q3_K_S</code> - uses <code>GGML_TYPE_Q3_K</code> for all tensors</li> <li><code>LLAMA_FTYPE_MOSTLY_Q3_K_M</code> - uses <code>GGML_TYPE_Q4_K</code> for the <code>attention.wv</code>, <code>attention.wo</code>, and <code>feed_forward.w2</code> tensors, else <code>GGML_TYPE_Q3_K</code></li> <li><code>LLAMA_FTYPE_MOSTLY_Q3_K_L</code> - uses <code>GGML_TYPE_Q5_K</code> for the <code>attention.wv</code>, <code>attention.wo</code>, and <code>feed_forward.w2</code> tensors, else <code>GGML_TYPE_Q3_K</code></li> <li><code>LLAMA_FTYPE_MOSTLY_Q4_K_S</code> - uses <code>GGML_TYPE_Q4_K</code> for all tensors</li> <li><code>LLAMA_FTYPE_MOSTLY_Q4_K_M</code> - uses <code>GGML_TYPE_Q6_K</code> for half of the <code>attention.wv</code> and <code>feed_forward.w2</code> tensors, else <code>GGML_TYPE_Q4_K</code></li> <li><code>LLAMA_FTYPE_MOSTLY_Q5_K_S</code> - uses <code>GGML_TYPE_Q5_K</code> for all tensors</li> <li><code>LLAMA_FTYPE_MOSTLY_Q5_K_M</code> - uses <code>GGML_TYPE_Q6_K</code> for half of the <code>attention.wv</code> and <code>feed_forward.w2</code> tensors, else <code>GGML_TYPE_Q5_K</code></li> <li><code>LLAMA_FTYPE_MOSTLY_Q6_K</code>- uses 6-bit quantization (<code>GGML_TYPE_Q8_K</code>) for all tensors</li> </ul> <p>As the models are currently fully loaded into memory, you will need adequate disk space to save them and sufficient RAM to load them. At the moment, memory and disk requirements are the same.</p> Model Original size Quantized size (4-bit) 7B 13 GB 3.9 GB 13B 24 GB 7.8 GB 30B 60 GB 19.5 GB 65B 120 GB 38.5 GB"},{"location":"AI/Chat/#Perplexity","title":"Perplexity","text":"<p>Simply, perplexity means to be surprised. We measure how much the model is surprised by seeing new data. The lower the perplexity, the better the training is. The take away here is it's always better to use a larger model, even if the quantization is greater. From a functional perspective, get the largest model (parameter-wise) you can, with the largest bit quantization until it's too slow for you to want to use.</p> <p></p> <p>Here are a few charts showing various models and quantization levels.</p> Model Measure F16 Q4_0 Q4_1 Q5_0 Q5_1 Q8_0 7B perplexity 5.9066 6.1565 6.0912 5.9862 5.9481 5.9070 7B file size 13.0G 3.5G 3.9G 4.3G 4.7G 6.7G 7B ms/tok @ 4th 127 55 54 76 83 72 7B ms/tok @ 8th 122 43 45 52 56 67 7B bits/weight 16.0 4.5 5.0 5.5 6.0 8.5 13B perplexity 5.2543 5.3860 5.3608 5.2856 5.2706 5.2548 13B file size 25.0G 6.8G 7.6G 8.3G 9.1G 13G 13B ms/tok @ 4th - 103 105 148 160 131 13B ms/tok @ 8th - 73 82 98 105 128 13B bits/weight 16.0 4.5 5.0 5.5 6.0 8.5 <p>Shown another way...</p> Model Measure Q2_K Q3_K_S Q3_K_M Q3_K_L Q4_0 Q4_1 Q4_K_S Q4_K_M Q5_0 Q5_1 Q5_K_S Q5_K_M Q6_K Q8_0 F16 7B perplexity 6.7764 6.4571 6.1503 6.0869 6.1565 6.0912 6.0215 5.9601 5.9862 5.9481 5.9419 5.9208 5.9110 5.9070 5.9066 13B perplexity 5.8545 5.6033 5.4498 5.4063 5.3860 5.3608 5.3404 5.3002 5.2856 5.2706 5.2785 5.2638 5.2568 5.2548 5.2543"},{"location":"AI/Chat/#Embeddings","title":"Embeddings","text":"<p>Good intro here. An embedding model lets you take a string of text - a word, sentence, paragraph or even a whole document - and turn that into an array of floating point numbers called an embedding vector.</p> <p>I like to think of an embedding vector as a location in 1,536-dimensional space. The distance between two vectors is a measure of how semantically similar they are in meaning, at least according to the model that produced them.</p> <p></p> <p>\u201cOne happy dog\u201d and \u201cA playful hound\u201d will end up close together, even though they don\u2019t share any keywords. The embedding vector represents the language model\u2019s interpretation of the meaning of the text.</p>"},{"location":"AI/Chat/#Parameters","title":"Parameters","text":"<p>Temperature is like a knob that adjusts how creative or focused the output becomes. Higher temperatures (eg., 1.2) increase randomness, resulting in more imaginative and diverse text. Lower temperatures (eg., 0.5) make the output more focused, predictable, and conservative. When the temperature is set to 0, the output becomes completely deterministic, always selecting the most probable next token and producing identical results each time. A safe range would be around 0.6 - 0.85, but you are free to search what value fits best for you.</p> <p>Top-P limits the selection of the next token to a subset of tokens with a cumulative probability above a threshold P. This method, also known as nucleus sampling, finds a balance between diversity and quality by considering both token probabilities and the number of tokens available for sampling. When using a higher value for top-P (eg., 0.95), the generated text becomes more diverse. On the other hand, a lower value (eg., 0.1) produces more focused and conservative text. The default value is 0.4, which is aimed to be the middle ground between focus and diversity, but for more creative tasks a higher top-p value will be beneficial, about 0.5-0.9 is a good range for that.</p> <p>Top-K sampling selects the next token only from the top K most likely tokens predicted by the model. It helps reduce the risk of generating low-probability or nonsensical tokens, but it may also limit the diversity of the output. A higher value for top-K (eg., 100) will consider more tokens and lead to more diverse text, while a lower value (eg., 10) will focus on the most probable tokens and generate more conservative text. 30 - 60 is a good range for most tasks.</p>"},{"location":"AI/Draw/","title":"Draw","text":"<p>Stable Diffusion is a deep learning, text-to-image model released in 2022. It is primarily used to generate detailed images conditioned on text descriptions, though it can also be applied to other tasks such as inpainting, outpainting, and generating image-to-image translations guided by a text prompt.</p> <p>Want the TL;DR on how to run a model 100% locally?</p> <ol> <li>Install  Stable Diffusion web UI by following the steps here.</li> <li>Download sd_xl_base_1.0_0.9vae.safetensors and sd_xl_refiner_1.0_0.9vae.safetensors. Save to where you extracted #1 to, at <code>.\\stable_diffusion\\webui\\models\\Stable-diffusion</code>. I think they're actually supposed to go to <code>.\\stable_diffusion\\webui\\models\\VAE</code> but I haven't tried and it doesn't seem to matter.</li> <li>Double-click <code>run.bat</code> to run the web interface!</li> </ol>"},{"location":"AI/Draw/#Installation","title":"Installation","text":"<p>AUTOMATIC1111's (A1111) Stable Diffusion web UI here is one of the more popular interfaces. Other options include InvokeAI and StableStudio. To run the latter 100% local you'll still need AUTOMATIC1111's tool in the first link. Details how how to set them up here. InvokeAI has a nicer interface but lacks some nice plugins, and StableStudio doesn't have many options (even the most basic).</p> <p>A1111 has some very nice extensions. I recommend StyleSelectorXL, which has a number of predefined styles. Also a good idea to modify <code>webui-user.bat</code> and replace the existing <code>set COMMANDLINE_ARGS</code> with <code>set COMMANDLINE_ARGS=--no-half-vae --xformers --autolaunch</code>.</p> <p>There's also InfiniteZoom. Details on how to load here. Note I had to replace <code>from webui import wrap_gradio_gpu_call</code> with <code>from modules.call_queue import wrap_gradio_gpu_call</code> in the file <code>\\stable-diffusion-webui\\extensions\\infinite-zoom-automatic1111-webui\\iz_helpers\\ui.py</code> to get it to load.</p>"},{"location":"AI/Draw/#Models","title":"Models","text":"<p>There are custom models everywhere. The best all purpose thus far seems to be SD XL. You'll want both <code>sd_xl_base_1.0_0.9vae.safetensors</code> and the refiner of the same type (<code>sd_xl_refiner_1.0_0.9vae.safetensors</code>). The <code>VAE</code> version seems to result in better color and saturation, and the refiner adds more detail as the image completes.</p>"},{"location":"AI/Draw/#Styles","title":"Styles","text":"<p>Below is a JSON version of the above extension StyleSelectorXL.</p> <pre><code>[\n  {\n    \"name\": \"base\",\n    \"prompt\": \"{prompt}\",\n    \"negative_prompt\": \"\"\n  },\n  {\n    \"name\": \"3D Model\",\n    \"prompt\": \"professional 3d model {prompt} . octane render, highly detailed, volumetric, dramatic lighting\",\n    \"negative_prompt\": \"ugly, deformed, noisy, low poly, blurry, painting\"\n  },\n  {\n    \"name\": \"Analog Film\",\n    \"prompt\": \"analog film photo {prompt} . faded film, desaturated, 35mm photo, grainy, vignette, vintage, Kodachrome, Lomography, stained, highly detailed, found footage\",\n    \"negative_prompt\": \"painting, drawing, illustration, glitch, deformed, mutated, cross-eyed, ugly, disfigured\"\n  },\n  {\n    \"name\": \"Anime\",\n    \"prompt\": \"anime artwork {prompt} . anime style, key visual, vibrant, studio anime,  highly detailed\",\n    \"negative_prompt\": \"photo, deformed, black and white, realism, disfigured, low contrast\"\n  },\n  {\n    \"name\": \"Cinematic\",\n    \"prompt\": \"cinematic film still {prompt} . shallow depth of field, vignette, highly detailed, high budget, bokeh, cinemascope, moody, epic, gorgeous, film grain, grainy\",\n    \"negative_prompt\": \"anime, cartoon, graphic, text, painting, crayon, graphite, abstract, glitch, deformed, mutated, ugly, disfigured\"\n  },\n  {\n    \"name\": \"Comic Book\",\n    \"prompt\": \"comic {prompt} . graphic illustration, comic art, graphic novel art, vibrant, highly detailed\",\n    \"negative_prompt\": \"photograph, deformed, glitch, noisy, realistic, stock photo\"\n  },\n  {\n    \"name\": \"Craft Clay\",\n    \"prompt\": \"play-doh style {prompt} . sculpture, clay art, centered composition, Claymation\",\n    \"negative_prompt\": \"sloppy, messy, grainy, highly detailed, ultra textured, photo\"\n  },\n  {\n    \"name\": \"Digital Art\",\n    \"prompt\": \"concept art {prompt} . digital artwork, illustrative, painterly, matte painting, highly detailed\",\n    \"negative_prompt\": \"photo, photorealistic, realism, ugly\"\n  },\n  {\n    \"name\": \"Enhance\",\n    \"prompt\": \"breathtaking {prompt} . award-winning, professional, highly detailed\",\n    \"negative_prompt\": \"ugly, deformed, noisy, blurry, distorted, grainy\"\n  },\n  {\n    \"name\": \"Fantasy Art\",\n    \"prompt\": \"ethereal fantasy concept art of  {prompt} . magnificent, celestial, ethereal, painterly, epic, majestic, magical, fantasy art, cover art, dreamy\",\n    \"negative_prompt\": \"photographic, realistic, realism, 35mm film, dslr, cropped, frame, text, deformed, glitch, noise, noisy, off-center, deformed, cross-eyed, closed eyes, bad anatomy, ugly, disfigured, sloppy, duplicate, mutated, black and white\"\n  },\n  {\n    \"name\": \"Isometric Style\",\n    \"prompt\": \"isometric style {prompt} . vibrant, beautiful, crisp, detailed, ultra detailed, intricate\",\n    \"negative_prompt\": \"deformed, mutated, ugly, disfigured, blur, blurry, noise, noisy, realistic, photographic\"\n  },\n  {\n    \"name\": \"Line Art\",\n    \"prompt\": \"line art drawing {prompt} . professional, sleek, modern, minimalist, graphic, line art, vector graphics\",\n    \"negative_prompt\": \"anime, photorealistic, 35mm film, deformed, glitch, blurry, noisy, off-center, deformed, cross-eyed, closed eyes, bad anatomy, ugly, disfigured, mutated, realism, realistic, impressionism, expressionism, oil, acrylic\"\n  },\n  {\n    \"name\": \"Lowpoly\",\n    \"prompt\": \"low-poly style {prompt} . low-poly game art, polygon mesh, jagged, blocky, wireframe edges, centered composition\",\n    \"negative_prompt\": \"noisy, sloppy, messy, grainy, highly detailed, ultra textured, photo\"\n  },\n  {\n    \"name\": \"Neon Punk\",\n    \"prompt\": \"neonpunk style {prompt} . cyberpunk, vaporwave, neon, vibes, vibrant, stunningly beautiful, crisp, detailed, sleek, ultramodern, magenta highlights, dark purple shadows, high contrast, cinematic, ultra detailed, intricate, professional\",\n    \"negative_prompt\": \"painting, drawing, illustration, glitch, deformed, mutated, cross-eyed, ugly, disfigured\"\n  },\n  {\n    \"name\": \"Origami\",\n    \"prompt\": \"origami style {prompt} . paper art, pleated paper, folded, origami art, pleats, cut and fold, centered composition\",\n    \"negative_prompt\": \"noisy, sloppy, messy, grainy, highly detailed, ultra textured, photo\"\n  },\n  {\n    \"name\": \"Photographic\",\n    \"prompt\": \"cinematic photo {prompt} . 35mm photograph, film, bokeh, professional, 4k, highly detailed\",\n    \"negative_prompt\": \"drawing, painting, crayon, sketch, graphite, impressionist, noisy, blurry, soft, deformed, ugly\"\n  },\n  {\n    \"name\": \"Pixel Art\",\n    \"prompt\": \"pixel-art {prompt} . low-res, blocky, pixel art style, 8-bit graphics\",\n    \"negative_prompt\": \"sloppy, messy, blurry, noisy, highly detailed, ultra textured, photo, realistic\"\n  },\n  {\n    \"name\": \"Texture\",\n    \"prompt\": \"texture {prompt} top down close-up\",\n    \"negative_prompt\": \"ugly, deformed, noisy, blurry\"\n  },\n  {\n    \"name\": \"Advertising\",\n    \"prompt\": \"Advertising poster style {prompt} . Professional, modern, product-focused, commercial, eye-catching, highly detailed\",\n    \"negative_prompt\": \"noisy, blurry, amateurish, sloppy, unattractive\"\n  },\n  {\n    \"name\": \"Food Photography\",\n    \"prompt\": \"Food photography style {prompt} . Appetizing, professional, culinary, high-resolution, commercial, highly detailed\",\n    \"negative_prompt\": \"unappetizing, sloppy, unprofessional, noisy, blurry\"\n  },\n  {\n    \"name\": \"Real Estate\",\n    \"prompt\": \"Real estate photography style {prompt} . Professional, inviting, well-lit, high-resolution, property-focused, commercial, highly detailed\",\n    \"negative_prompt\": \"dark, blurry, unappealing, noisy, unprofessional\"\n  },\n  {\n    \"name\": \"Abstract\",\n    \"prompt\": \"Abstract style {prompt} . Non-representational, colors and shapes, expression of feelings, imaginative, highly detailed\",\n    \"negative_prompt\": \"realistic, photographic, figurative, concrete\"\n  },\n  {\n    \"name\": \"Cubist\",\n    \"prompt\": \"Cubist artwork {prompt} . Geometric shapes, abstract, innovative, revolutionary\",\n    \"negative_prompt\": \"anime, photorealistic, 35mm film, deformed, glitch, low contrast, noisy\"\n  },\n  {\n    \"name\": \"Graffiti\",\n    \"prompt\": \"Graffiti style {prompt} . Street art, vibrant, urban, detailed, tag, mural\",\n    \"negative_prompt\": \"ugly, deformed, noisy, blurry, low contrast, realism, photorealistic\"\n  },\n  {\n    \"name\": \"Hyperrealism\",\n    \"prompt\": \"Hyperrealistic art {prompt} . Extremely high-resolution details, photographic, realism pushed to extreme, fine texture, incredibly lifelike\",\n    \"negative_prompt\": \"simplified, abstract, unrealistic, impressionistic, low resolution\"\n  },\n  {\n    \"name\": \"Impressionist\",\n    \"prompt\": \"Impressionist painting {prompt} . Loose brushwork, vibrant color, light and shadow play, captures feeling over form\",\n    \"negative_prompt\": \"anime, photorealistic, 35mm film, deformed, glitch, low contrast, noisy\"\n  },\n  {\n    \"name\": \"Pointillism\",\n    \"prompt\": \"Pointillism style {prompt} . Composed entirely of small, distinct dots of color, vibrant, highly detailed\",\n    \"negative_prompt\": \"line drawing, smooth shading, large color fields, simplistic\"\n  },\n  {\n    \"name\": \"Pop Art\",\n    \"prompt\": \"Pop Art style {prompt} . Bright colors, bold outlines, popular culture themes, ironic or kitsch\",\n    \"negative_prompt\": \"ugly, deformed, noisy, blurry, low contrast, realism, photorealistic, minimalist\"\n  },\n  {\n    \"name\": \"Psychedelic\",\n    \"prompt\": \"Psychedelic style {prompt} . Vibrant colors, swirling patterns, abstract forms, surreal, trippy\",\n    \"negative_prompt\": \"monochrome, black and white, low contrast, realistic, photorealistic, plain, simple\"\n  },\n  {\n    \"name\": \"Renaissance\",\n    \"prompt\": \"Renaissance style {prompt} . Realistic, perspective, light and shadow, religious or mythological themes, highly detailed\",\n    \"negative_prompt\": \"ugly, deformed, noisy, blurry, low contrast, modernist, minimalist, abstract\"\n  },\n  {\n    \"name\": \"Steampunk\",\n    \"prompt\": \"Steampunk style {prompt} . Antique, mechanical, brass and copper tones, gears, intricate, detailed\",\n    \"negative_prompt\": \"deformed, glitch, noisy, low contrast, anime, photorealistic\"\n  },\n  {\n    \"name\": \"Surrealist\",\n    \"prompt\": \"Surrealist art {prompt} . Dreamlike, mysterious, provocative, symbolic, intricate, detailed\",\n    \"negative_prompt\": \"anime, photorealistic, realistic, deformed, glitch, noisy, low contrast\"\n  },\n  {\n    \"name\": \"Typography\",\n    \"prompt\": \"Typographic art {prompt} . Stylized, intricate, detailed, artistic, text-based\",\n    \"negative_prompt\": \"ugly, deformed, noisy, blurry, low contrast, realism, photorealistic\"\n  },\n  {\n    \"name\": \"Watercolor\",\n    \"prompt\": \"Watercolor painting {prompt} . Vibrant, beautiful, painterly, detailed, textural, artistic\",\n    \"negative_prompt\": \"anime, photorealistic, 35mm film, deformed, glitch, low contrast, noisy\"\n  },\n  {\n    \"name\": \"Fighting Game\",\n    \"prompt\": \"Fighting game style {prompt} . Dynamic, vibrant, action-packed, detailed character design, reminiscent of fighting video games\",\n    \"negative_prompt\": \"peaceful, calm, minimalist, photorealistic\"\n  },\n  {\n    \"name\": \"GTA\",\n    \"prompt\": \"GTA-style artwork {prompt} . Satirical, exaggerated, pop art style, vibrant colors, iconic characters, action-packed\",\n    \"negative_prompt\": \"realistic, black and white, low contrast, impressionist, cubist, noisy, blurry, deformed\"\n  },\n  {\n    \"name\": \"Super Mario\",\n    \"prompt\": \"Super Mario style {prompt} . Vibrant, cute, cartoony, fantasy, playful, reminiscent of Super Mario series\",\n    \"negative_prompt\": \"realistic, modern, horror, dystopian, violent\"\n  },\n  {\n    \"name\": \"Minecraft\",\n    \"prompt\": \"Minecraft style {prompt} . Blocky, pixelated, vibrant colors, recognizable characters and objects, game assets\",\n    \"negative_prompt\": \"smooth, realistic, detailed, photorealistic, noise, blurry, deformed\"\n  },\n  {\n    \"name\": \"Pok\u00e9mon\",\n    \"prompt\": \"Pok\u00e9mon style {prompt} . Vibrant, cute, anime, fantasy, reminiscent of Pok\u00e9mon series\",\n    \"negative_prompt\": \"realistic, modern, horror, dystopian, violent\"\n  },\n  {\n    \"name\": \"Retro Arcade\",\n    \"prompt\": \"Retro arcade style {prompt} . 8-bit, pixelated, vibrant, classic video game, old school gaming, reminiscent of 80s and 90s arcade games\",\n    \"negative_prompt\": \"modern, ultra-high resolution, photorealistic, 3D\"\n  },\n  {\n    \"name\": \"Retro Game\",\n    \"prompt\": \"Retro game art {prompt} . 16-bit, vibrant colors, pixelated, nostalgic, charming, fun\",\n    \"negative_prompt\": \"realistic, photorealistic, 35mm film, deformed, glitch, low contrast, noisy\"\n  },\n  {\n    \"name\": \"RPG Fantasy Game\",\n    \"prompt\": \"Role-playing game (RPG) style fantasy {prompt} . Detailed, vibrant, immersive, reminiscent of high fantasy RPG games\",\n    \"negative_prompt\": \"sci-fi, modern, urban, futuristic, low detailed\"\n  },\n  {\n    \"name\": \"Strategy Game\",\n    \"prompt\": \"Strategy game style {prompt} . Overhead view, detailed map, units, reminiscent of real-time strategy video games\",\n    \"negative_prompt\": \"first-person view, modern, photorealistic\"\n  },\n  {\n    \"name\": \"Street Fighter\",\n    \"prompt\": \"Street Fighter style {prompt} . Vibrant, dynamic, arcade, 2D fighting game, highly detailed, reminiscent of Street Fighter series\",\n    \"negative_prompt\": \"3D, realistic, modern, photorealistic, turn-based strategy\"\n  },\n  {\n    \"name\": \"Legend of Zelda\",\n    \"prompt\": \"Legend of Zelda style {prompt} . Vibrant, fantasy, detailed, epic, heroic, reminiscent of The Legend of Zelda series\",\n    \"negative_prompt\": \"sci-fi, modern, realistic, horror\"\n  },\n  {\n    \"name\": \"Architectural\",\n    \"prompt\": \"Architectural style {prompt} . Clean lines, geometric shapes, minimalist, modern, architectural drawing, highly detailed\",\n    \"negative_prompt\": \"curved lines, ornate, baroque, abstract, grunge\"\n  },\n  {\n    \"name\": \"Disco\",\n    \"prompt\": \"Disco-themed {prompt} . Vibrant, groovy, retro 70s style, shiny disco balls, neon lights, dance floor, highly detailed\",\n    \"negative_prompt\": \"minimalist, rustic, monochrome, contemporary, simplistic\"\n  },\n  {\n    \"name\": \"Dreamscape\",\n    \"prompt\": \"Dreamscape {prompt} . Surreal, ethereal, dreamy, mysterious, fantasy, highly detailed\",\n    \"negative_prompt\": \"realistic, concrete, ordinary, mundane\"\n  },\n  {\n    \"name\": \"Dystopian\",\n    \"prompt\": \"Dystopian style {prompt} . Bleak, post-apocalyptic, somber, dramatic, highly detailed\",\n    \"negative_prompt\": \"ugly, deformed, noisy, blurry, low contrast, cheerful, optimistic, vibrant, colorful\"\n  },\n  {\n    \"name\": \"Fairy Tale\",\n    \"prompt\": \"Fairy tale {prompt} . Magical, fantastical, enchanting, storybook style, highly detailed\",\n    \"negative_prompt\": \"realistic, modern, ordinary, mundane\"\n  },\n  {\n    \"name\": \"Gothic\",\n    \"prompt\": \"Gothic style {prompt} . Dark, mysterious, haunting, dramatic, ornate, detailed\",\n    \"negative_prompt\": \"ugly, deformed, noisy, blurry, low contrast, realism, photorealistic, cheerful, optimistic\"\n  },\n  {\n    \"name\": \"Grunge\",\n    \"prompt\": \"Grunge style {prompt} . Textured, distressed, vintage, edgy, punk rock vibe, dirty, noisy\",\n    \"negative_prompt\": \"smooth, clean, minimalist, sleek, modern, photorealistic\"\n  },\n  {\n    \"name\": \"Horror\",\n    \"prompt\": \"Horror-themed {prompt} . Eerie, unsettling, dark, spooky, suspenseful, grim, highly detailed\",\n    \"negative_prompt\": \"cheerful, bright, vibrant, light-hearted, cute\"\n  },\n  {\n    \"name\": \"Minimalist\",\n    \"prompt\": \"Minimalist style {prompt} . Simple, clean, uncluttered, modern, elegant\",\n    \"negative_prompt\": \"ornate, complicated, highly detailed, cluttered, disordered, messy, noisy\"\n  },\n  {\n    \"name\": \"Monochrome\",\n    \"prompt\": \"Monochrome {prompt} . Black and white, contrast, tone, texture, detailed\",\n    \"negative_prompt\": \"colorful, vibrant, noisy, blurry, deformed\"\n  },\n  {\n    \"name\": \"Nautical\",\n    \"prompt\": \"Nautical-themed {prompt} . Sea, ocean, ships, maritime, beach, marine life, highly detailed\",\n    \"negative_prompt\": \"landlocked, desert, mountains, urban, rustic\"\n  },\n  {\n    \"name\": \"Space\",\n    \"prompt\": \"Space-themed {prompt} . Cosmic, celestial, stars, galaxies, nebulas, planets, science fiction, highly detailed\",\n    \"negative_prompt\": \"earthly, mundane, ground-based, realism\"\n  },\n  {\n    \"name\": \"Stained Glass\",\n    \"prompt\": \"Stained glass style {prompt} . Vibrant, beautiful, translucent, intricate, detailed\",\n    \"negative_prompt\": \"ugly, deformed, noisy, blurry, low contrast, realism, photorealistic\"\n  },\n  {\n    \"name\": \"Techwear Fashion\",\n    \"prompt\": \"Techwear fashion {prompt} . Futuristic, cyberpunk, urban, tactical, sleek, dark, highly detailed\",\n    \"negative_prompt\": \"vintage, rural, colorful, low contrast, realism, sketch, watercolor\"\n  },\n  {\n    \"name\": \"Tribal\",\n    \"prompt\": \"Tribal style {prompt} . Indigenous, ethnic, traditional patterns, bold, natural colors, highly detailed\",\n    \"negative_prompt\": \"modern, futuristic, minimalist, pastel\"\n  },\n  {\n    \"name\": \"Zentangle\",\n    \"prompt\": \"Zentangle {prompt} . Intricate, abstract, monochrome, patterns, meditative, highly detailed\",\n    \"negative_prompt\": \"colorful, representative, simplistic, large fields of color\"\n  },\n  {\n    \"name\": \"Collage\",\n    \"prompt\": \"Collage style {prompt} . Mixed media, layered, textural, detailed, artistic\",\n    \"negative_prompt\": \"ugly, deformed, noisy, blurry, low contrast, realism, photorealistic\"\n  },\n  {\n    \"name\": \"Flat Papercut\",\n    \"prompt\": \"Flat papercut style {prompt} . Silhouette, clean cuts, paper, sharp edges, minimalist, color block\",\n    \"negative_prompt\": \"3D, high detail, noise, grainy, blurry, painting, drawing, photo, disfigured\"\n  },\n  {\n    \"name\": \"Kirigami\",\n    \"prompt\": \"Kirigami representation of {prompt} . 3D, paper folding, paper cutting, Japanese, intricate, symmetrical, precision, clean lines\",\n    \"negative_prompt\": \"painting, drawing, 2D, noisy, blurry, deformed\"\n  },\n  {\n    \"name\": \"Paper Mache\",\n    \"prompt\": \"Paper mache representation of {prompt} . 3D, sculptural, textured, handmade, vibrant, fun\",\n    \"negative_prompt\": \"2D, flat, photo, sketch, digital art, deformed, noisy, blurry\"\n  },\n  {\n    \"name\": \"Paper Quilling\",\n    \"prompt\": \"Paper quilling art of {prompt} . Intricate, delicate, curling, rolling, shaping, coiling, loops, 3D, dimensional, ornamental\",\n    \"negative_prompt\": \"photo, painting, drawing, 2D, flat, deformed, noisy, blurry\"\n  },\n  {\n    \"name\": \"Papercut Collage\",\n    \"prompt\": \"Papercut collage of {prompt} . Mixed media, textured paper, overlapping, asymmetrical, abstract, vibrant\",\n    \"negative_prompt\": \"photo, 3D, realistic, drawing, painting, high detail, disfigured\"\n  },\n  {\n    \"name\": \"Papercut Shadow Box\",\n    \"prompt\": \"3D papercut shadow box of {prompt} . Layered, dimensional, depth, silhouette, shadow, papercut, handmade, high contrast\",\n    \"negative_prompt\": \"painting, drawing, photo, 2D, flat, high detail, blurry, noisy, disfigured\"\n  },\n  {\n    \"name\": \"Stacked Papercut\",\n    \"prompt\": \"Stacked papercut art of {prompt} . 3D, layered, dimensional, depth, precision cut, stacked layers, papercut, high contrast\",\n    \"negative_prompt\": \"2D, flat, noisy, blurry, painting, drawing, photo, deformed\"\n  },\n  {\n    \"name\": \"Thick Layered Papercut\",\n    \"prompt\": \"Thick layered papercut art of {prompt} . Deep 3D, volumetric, dimensional, depth, thick paper, high stack, heavy texture, tangible layers\",\n    \"negative_prompt\": \"2D, flat, thin paper, low stack, smooth texture, painting, drawing, photo, deformed\"\n  },\n  {\n    \"name\": \"Alien\",\n    \"prompt\": \"Alien-themed {prompt} . Extraterrestrial, cosmic, otherworldly, mysterious, sci-fi, highly detailed\",\n    \"negative_prompt\": \"earthly, mundane, common, realistic, simple\"\n  },\n  {\n    \"name\": \"Film Noir\",\n    \"prompt\": \"Film noir style {prompt} . Monochrome, high contrast, dramatic shadows, 1940s style, mysterious, cinematic\",\n    \"negative_prompt\": \"ugly, deformed, noisy, blurry, low contrast, realism, photorealistic, vibrant, colorful\"\n  },\n  {\n    \"name\": \"HDR\",\n    \"prompt\": \"HDR photo of {prompt} . High dynamic range, vivid, rich details, clear shadows and highlights, realistic, intense, enhanced contrast, highly detailed\",\n    \"negative_prompt\": \"flat, low contrast, oversaturated, underexposed, overexposed, blurred, noisy\"\n  },\n  {\n    \"name\": \"Long Exposure\",\n    \"prompt\": \"Long exposure photo of {prompt} . Blurred motion, streaks of light, surreal, dreamy, ghosting effect, highly detailed\",\n    \"negative_prompt\": \"static, noisy, deformed, shaky, abrupt, flat, low contrast\"\n  },\n  {\n    \"name\": \"Neon Noir\",\n    \"prompt\": \"Neon noir {prompt} . Cyberpunk, dark, rainy streets, neon signs, high contrast, low light, vibrant, highly detailed\",\n    \"negative_prompt\": \"bright, sunny, daytime, low contrast, black and white, sketch, watercolor\"\n  },\n  {\n    \"name\": \"Silhouette\",\n    \"prompt\": \"Silhouette style {prompt} . High contrast, minimalistic, black and white, stark, dramatic\",\n    \"negative_prompt\": \"ugly, deformed, noisy, blurry, low contrast, color, realism, photorealistic\"\n  },\n  {\n    \"name\": \"Tilt-Shift\",\n    \"prompt\": \"Tilt-shift photo of {prompt} . Selective focus, miniature effect, blurred background, highly detailed, vibrant, perspective control\",\n    \"negative_prompt\": \"blurry, noisy, deformed, flat, low contrast, unrealistic, oversaturated, underexposed\"\n  }\n]\n</code></pre>"},{"location":"AI/Llama.cpp/","title":"Llama.cpp","text":"<p>Content from here.</p> <p>This example program allows you to use various LLaMA language models in an easy and efficient way. It is specifically designed to work with the llama.cpp project, which provides a plain C/C++ implementation with optional 4-bit quantization support for faster, lower memory inference, and is optimized for desktop CPUs. This program can be used to perform various inference tasks with LLaMA models, including generating text based on user-provided prompts and chat-like interactions with reverse prompts.</p>"},{"location":"AI/Llama.cpp/#Build","title":"Build","text":"<p>This covers how to build for Windows (or at least what worked for me) if you have an NVIDIA GPU. You'll also need Git installed.</p> <ol> <li>Install Visual Studio 2022 Community<ol> <li>Install Desktop development with C++, with the Optional features:<ol> <li><code>MSVC v143 - VS Code C++ x64/x86 build tools (latest)</code></li> <li><code>C++ CMake tools for Windows</code></li> <li><code>C++ AddressSanitizer</code></li> <li><code>Windows 11 SDK...</code></li> </ol> </li> </ol> </li> <li>Install the CUDA Toolkit</li> <li>Copy the 4 files from CUDA to VS manually<ol> <li>Copy the files from <code>C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.2\\extras\\visual_studio_integration\\MSBuildExtensions</code></li> <li>To <code>C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\BuildCustomizations</code></li> </ol> </li> <li>Navigate to where you want the files extracted.</li> <li>Run <code>git clone https://github.com/ggerganov/llama.cpp</code>, then <code>cd llama.cpp</code></li> <li>Finally run the below.</li> </ol> <pre><code>mkdir build\ncd build\ncmake .. -DLLAMA_CUBLAS=ON\ncmake --build . --config Release\n</code></pre> <p>To update the local download to the latest run <code>git fetch origin</code>, then <code>git status</code>, and finally <code>git pull</code> from the working directory. Then you can run the <code>cmake</code> commands again from above. Don't forget to run them from an empty <code>build</code> directory, so you should back up or delete the original.</p>"},{"location":"AI/Llama.cpp/#Settings","title":"Settings","text":"<p>More details below; this is just a quick summary view</p> Name Type Description Default <code>embedding</code> <code>bool</code> Embedding mode only. <code>False</code> <code>f16_kv</code> <code>bool</code> Use half-precision for key/value cache. <code>True</code> <code>last_n_tokens_size</code> <code>int</code> Maximum number of tokens to keep in the last_n_tokens deque. <code>64</code> <code>logits_all</code> <code>bool</code> Return logits for all tokens, not just the last token. <code>False</code> <code>lora_base</code> <code>Optional[str]</code> Optional path to base model, useful if using a quantized base model and you want to apply LoRA to an f16 model. <code>None</code> <code>lora_path</code> <code>Optional[str]</code> Path to a LoRA file to apply to the model. <code>None</code> <code>model_path</code> <code>str</code> Path to the model. required <code>n_batch</code> <code>int</code> Maximum number of prompt tokens to batch together when calling llama_eval. <code>512</code> <code>n_ctx</code> <code>int</code> Maximum context size. <code>512</code> <code>n_gpu_layers</code> <code>int</code> Number of layers to offload to GPU (-ngl). If -1, all layers are offloaded. <code>0</code> <code>n_parts</code> <code>int</code> Number of parts to split the model into. If -1, the number of parts is automatically determined. <code>-1</code> <code>n_threads</code> <code>Optional[int]</code> Number of threads to use. If None, the number of threads is automatically determined. <code>None</code> <code>rope_freq_base</code> <code>float</code> Base frequency for rope sampling. <code>10000.0</code> <code>rope_freq_scale</code> <code>float</code> Scale factor for rope sampling. <code>1.0</code> <code>seed</code> <code>int</code> Random seed. -1 for random. <code>1337</code> <code>tensor_split</code> <code>Optional[List[float]]</code> List of floats to split the model across multiple GPUs. If None, the model is not split. <code>None</code> <code>use_mlock</code> <code>bool</code> Force the system to keep the model in RAM. <code>False</code> <code>use_mmap</code> <code>bool</code> Use mmap if possible. <code>True</code> <code>verbose</code> <code>bool</code> Print verbose output to stderr. <code>True</code> <code>vocab_only</code> <code>bool</code> Only load the vocabulary no weights. <code>False</code>"},{"location":"AI/Llama.cpp/#Server","title":"Server","text":"<p>Once installed you can run a script like this (make sure to change the server and model path): <code>D:\\AI\\llama.cpp\\build\\bin\\Release\\server.exe -c 4096 -ngl 100 --host 0.0.0.0 -t 16 --mlock --threads 6 -m \"D:\\AI\\TheBloke\\phind-codellama-34B-v2-GGUF\\phind-codellama-34b-v2.Q4_K_M.gguf\"</code></p>"},{"location":"AI/Llama.cpp/#Quick%20Start","title":"Quick Start","text":"<p>To get started right away, run the following command, making sure to use the correct path for the model you have:</p> <pre><code>main.exe -m models\\7B\\ggml-model.bin --prompt \"Once upon a time\"\n</code></pre> <p>For an interactive experience, try this command:</p> <pre><code>main.exe -m models\\7B\\ggml-model.bin -n -1 --color -r \"User:\" --in-prefix \" \" -i -e -p \"User: Hi\\nAI: Hello. I am an AI chatbot. Would you like to talk?\\nUser: Sure!\\nAI: What would you like to talk about?\\nUser:\"\n</code></pre> <p>The following command generates \"infinite\" text from a starting prompt (you can use <code>Ctrl-C</code> to stop it):</p> <pre><code>main.exe -m models\\7B\\ggml-model.bin --ignore-eos -n -1 --random-prompt\n</code></pre>"},{"location":"AI/Llama.cpp/#Common%20Options","title":"Common Options","text":"<p>In this section, we cover the most commonly used options for running the <code>main</code> program with the LLaMA models:</p> <ul> <li><code>-m FNAME, --model FNAME</code>: Specify the path to the LLaMA model file (e.g., <code>models/7B/ggml-model.bin</code>).</li> <li><code>-i, --interactive</code>: Run the program in interactive mode, allowing you to provide input directly and receive real-time responses.</li> <li><code>-ins, --instruct</code>: Run the program in instruction mode, which is particularly useful when working with Alpaca models.</li> <li><code>-n N, --n-predict N</code>: Set the number of tokens to predict when generating text. Adjusting this value can influence the length of the generated text.</li> <li><code>-c N, --ctx-size N</code>: Set the size of the prompt context. The default is 512, but LLaMA models were built with a context of 2048, which will provide better results for longer input/inference.</li> </ul>"},{"location":"AI/Llama.cpp/#Input%20Prompts","title":"Input Prompts","text":"<p>The <code>main</code> program provides several ways to interact with the LLaMA models using input prompts:</p> <ul> <li><code>--prompt PROMPT</code>: Provide a prompt directly as a command-line option.</li> <li><code>--file FNAME</code>: Provide a file containing a prompt or multiple prompts.</li> <li><code>--interactive-first</code>: Run the program in interactive mode and wait for input right away. (More on this below.)</li> <li><code>--random-prompt</code>: Start with a randomized prompt.</li> </ul>"},{"location":"AI/Llama.cpp/#Interaction","title":"Interaction","text":"<p>The <code>main</code> program offers a seamless way to interact with LLaMA models, allowing users to engage in real-time conversations or provide instructions for specific tasks. The interactive mode can be triggered using various options, including <code>--interactive</code>, <code>--interactive-first</code>, and <code>--instruct</code>.</p> <p>In interactive mode, users can participate in text generation by injecting their input during the process. Users can press <code>Ctrl+C</code> at any time to interject and type their input, followed by pressing <code>Return</code> to submit it to the LLaMA model. To submit additional lines without finalizing input, users can end the current line with a backslash (<code>\\</code>) and continue typing.</p>"},{"location":"AI/Llama.cpp/#Interaction%20Options","title":"Interaction Options","text":"<ul> <li><code>-i, --interactive</code>: Run the program in interactive mode, allowing users to engage in real-time conversations or provide specific instructions to the model.</li> <li><code>--interactive-first</code>: Run the program in interactive mode and immediately wait for user input before starting the text generation.</li> <li><code>-ins, --instruct</code>: Run the program in instruction mode, which is specifically designed to work with Alpaca models that excel in completing tasks based on user instructions.</li> <li><code>--color</code>: Enable colorized output to differentiate visually distinguishing between prompts, user input, and generated text.</li> </ul> <p>By understanding and utilizing these interaction options, you can create engaging and dynamic experiences with the LLaMA models, tailoring the text generation process to your specific needs.</p>"},{"location":"AI/Llama.cpp/#Reverse%20Prompts","title":"Reverse Prompts","text":"<p>Reverse prompts are a powerful way to create a chat-like experience with a LLaMA model by pausing the text generation when specific text strings are encountered:</p> <ul> <li><code>-r PROMPT, --reverse-prompt PROMPT</code>: Specify one or multiple reverse prompts to pause text generation and switch to interactive mode. For example, <code>-r \"User:\"</code> can be used to jump back into the conversation whenever it's the user's turn to speak. This helps create a more interactive and conversational experience. However, the reverse prompt doesn't work when it ends with a space.</li> </ul> <p>To overcome this limitation, you can use the <code>--in-prefix</code> flag to add a space or any other characters after the reverse prompt.</p>"},{"location":"AI/Llama.cpp/#In-Prefix","title":"In-Prefix","text":"<p>The <code>--in-prefix</code> flag is used to add a prefix to your input, primarily, this is used to insert a space after the reverse prompt. Here's an example of how to use the <code>--in-prefix</code> flag in conjunction with the <code>--reverse-prompt</code> flag:</p> <pre><code>./main -r \"User:\" --in-prefix \" \"\n</code></pre>"},{"location":"AI/Llama.cpp/#In-Suffix","title":"In-Suffix","text":"<p>The <code>--in-suffix</code> flag is used to add a suffix after your input. This is useful for adding an \"Assistant:\" prompt after the user's input. It's added after the new-line character (<code>\\n</code>) that's automatically added to the end of the user's input. Here's an example of how to use the <code>--in-suffix</code> flag in conjunction with the <code>--reverse-prompt</code> flag:</p> <pre><code>./main -r \"User:\" --in-prefix \" \" --in-suffix \"Assistant:\"\n</code></pre>"},{"location":"AI/Llama.cpp/#Instruction%20Mode","title":"Instruction Mode","text":"<p>Instruction mode is particularly useful when working with Alpaca models, which are designed to follow user instructions for specific tasks:</p> <ul> <li><code>-ins, --instruct</code>: Enable instruction mode to leverage the capabilities of Alpaca models in completing tasks based on user-provided instructions.</li> </ul> <p>Technical detail: the user's input is internally prefixed with the reverse prompt (or <code>### Instruction:</code> as the default), and followed by <code>### Response:</code> (except if you just press Return without any input, to keep generating a longer response).</p> <p>By understanding and utilizing these interaction options, you can create engaging and dynamic experiences with the LLaMA models, tailoring the text generation process to your specific needs.</p>"},{"location":"AI/Llama.cpp/#Context%20Management","title":"Context Management","text":"<p>During text generation, LLaMA models have a limited context size, which means they can only consider a certain number of tokens from the input and generated text. When the context fills up, the model resets internally, potentially losing some information from the beginning of the conversation or instructions. Context management options help maintain continuity and coherence in these situations.</p>"},{"location":"AI/Llama.cpp/#Context%20Size","title":"Context Size","text":"<p>The <code>--ctx-size</code> option allows you to set the size of the prompt context used by the LLaMA models during text generation. A larger context size helps the model to better comprehend and generate responses for longer input or conversations.</p> <ul> <li><code>-c N, --ctx-size N</code>: Set the size of the prompt context (default: 512). The LLaMA models were built with a context of 2048, which will yield the best results on longer input/inference. However, increasing the context size beyond 2048 may lead to unpredictable results.</li> </ul>"},{"location":"AI/Llama.cpp/#Extended%20Context%20Size","title":"Extended Context Size","text":"<p>Some fine-tuned models have extened the context length by scaling RoPE. For example, if the original pretrained model have a context length (max sequence length) of 4096 (4k) and the fine-tuned model have 32k. That is a scaling factor of 8, and should work by setting the above <code>--ctx-size</code> to 32768 (32k) and <code>--rope-scale</code> to 8.</p> <ul> <li><code>--rope-scale N</code>: Where N is the linear scaling factor used by the fine-tuned model.</li> </ul>"},{"location":"AI/Llama.cpp/#Keep%20Prompt","title":"Keep Prompt","text":"<p>The <code>--keep</code> option allows users to retain the original prompt when the model runs out of context, ensuring a connection to the initial instruction or conversation topic is maintained.</p> <ul> <li><code>--keep N</code>: Specify the number of tokens from the initial prompt to retain when the model resets its internal context. By default, this value is set to 0 (meaning no tokens are kept). Use <code>-1</code> to retain all tokens from the initial prompt.</li> </ul> <p>By utilizing context management options like <code>--ctx-size</code> and <code>--keep</code>, you can maintain a more coherent and consistent interaction with the LLaMA models, ensuring that the generated text remains relevant to the original prompt or conversation.</p>"},{"location":"AI/Llama.cpp/#Generation%20Flags","title":"Generation Flags","text":"<p>The following options allow you to control the text generation process and fine-tune the diversity, creativity, and quality of the generated text according to your needs. By adjusting these options and experimenting with different combinations of values, you can find the best settings for your specific use case.</p>"},{"location":"AI/Llama.cpp/#Number%20of%20Tokens%20to%20Predict","title":"Number of Tokens to Predict","text":"<ul> <li><code>-n N, --n-predict N</code>: Set the number of tokens to predict when generating text (default: 128, -1 = infinity, -2 = until context filled)</li> </ul> <p>The <code>--n-predict</code> option controls the number of tokens the model generates in response to the input prompt. By adjusting this value, you can influence the length of the generated text. A higher value will result in longer text, while a lower value will produce shorter text.</p> <p>A value of -1 will enable infinite text generation, even though we have a finite context window. When the context window is full, some of the earlier tokens (half of the tokens after <code>--n-keep</code>) will be discarded. The context must then be re-evaluated before generation can resume. On large models and/or large context windows, this will result in significant pause in output.</p> <p>If the pause is undesirable, a value of -2 will stop generation immediately when the context is filled.</p> <p>It is important to note that the generated text may be shorter than the specified number of tokens if an End-of-Sequence (EOS) token or a reverse prompt is encountered. In interactive mode text generation will pause and control will be returned to the user. In non-interactive mode, the program will end. In both cases, the text generation may stop before reaching the specified <code>n-predict</code> value. If you want the model to keep going without ever producing End-of-Sequence on its own, you can use the <code>--ignore-eos</code> parameter.</p>"},{"location":"AI/Llama.cpp/#Temperature","title":"Temperature","text":"<ul> <li><code>--temp N</code>: Adjust the randomness of the generated text (default: 0.8).</li> </ul> <p>Temperature is a hyperparameter that controls the randomness of the generated text. It affects the probability distribution of the model's output tokens. A higher temperature (e.g., 1.5) makes the output more random and creative, while a lower temperature (e.g., 0.5) makes the output more focused, deterministic, and conservative. The default value is 0.8, which provides a balance between randomness and determinism. At the extreme, a temperature of 0 will always pick the most likely next token, leading to identical outputs in each run.</p> <p>Example usage: <code>--temp 0.5</code></p>"},{"location":"AI/Llama.cpp/#Repeat%20Penalty","title":"Repeat Penalty","text":"<ul> <li><code>--repeat-penalty N</code>: Control the repetition of token sequences in the generated text (default: 1.1).</li> <li><code>--repeat-last-n N</code>: Last n tokens to consider for penalizing repetition (default: 64, 0 = disabled, -1 = ctx-size).</li> <li><code>--no-penalize-nl</code>: Disable penalization for newline tokens when applying the repeat penalty.</li> </ul> <p>The <code>repeat-penalty</code> option helps prevent the model from generating repetitive or monotonous text. A higher value (e.g., 1.5) will penalize repetitions more strongly, while a lower value (e.g., 0.9) will be more lenient. The default value is 1.1.</p> <p>The <code>repeat-last-n</code> option controls the number of tokens in the history to consider for penalizing repetition. A larger value will look further back in the generated text to prevent repetitions, while a smaller value will only consider recent tokens. A value of 0 disables the penalty, and a value of -1 sets the number of tokens considered equal to the context size (<code>ctx-size</code>).</p> <p>Use the <code>--no-penalize-nl</code> option to disable newline penalization when applying the repeat penalty. This option is particularly useful for generating chat conversations, dialogues, code, poetry, or any text where newline tokens play a significant role in structure and formatting. Disabling newline penalization helps maintain the natural flow and intended formatting in these specific use cases.</p> <p>Example usage: <code>--repeat-penalty 1.15 --repeat-last-n 128 --no-penalize-nl</code></p>"},{"location":"AI/Llama.cpp/#Top-K%20Sampling","title":"Top-K Sampling","text":"<ul> <li><code>--top-k N</code>: Limit the next token selection to the K most probable tokens (default: 40).</li> </ul> <p>Top-k sampling is a text generation method that selects the next token only from the top k most likely tokens predicted by the model. It helps reduce the risk of generating low-probability or nonsensical tokens, but it may also limit the diversity of the output. A higher value for top-k (e.g., 100) will consider more tokens and lead to more diverse text, while a lower value (e.g., 10) will focus on the most probable tokens and generate more conservative text. The default value is 40.</p> <p>Example usage: <code>--top-k 30</code></p>"},{"location":"AI/Llama.cpp/#Top-P%20Sampling","title":"Top-P Sampling","text":"<ul> <li><code>--top-p N</code>: Limit the next token selection to a subset of tokens with a cumulative probability above a threshold P (default: 0.9).</li> </ul> <p>Top-p sampling, also known as nucleus sampling, is another text generation method that selects the next token from a subset of tokens that together have a cumulative probability of at least p. This method provides a balance between diversity and quality by considering both the probabilities of tokens and the number of tokens to sample from. A higher value for top-p (e.g., 0.95) will lead to more diverse text, while a lower value (e.g., 0.5) will generate more focused and conservative text. The default value is 0.9.</p> <p>Example usage: <code>--top-p 0.95</code></p>"},{"location":"AI/Llama.cpp/#Tail%20Free%20Sampling%20TFS","title":"Tail Free Sampling (TFS)","text":"<ul> <li><code>--tfs N</code>: Enable tail free sampling with parameter z (default: 1.0, 1.0 = disabled).</li> </ul> <p>Tail free sampling (TFS) is a text generation technique that aims to reduce the impact of less likely tokens, which may be less relevant, less coherent, or nonsensical, on the output. Similar to Top-P it tries to determine the bulk of the most likely tokens dynamically. But TFS filters out logits based on the second derivative of their probabilities. Adding tokens is stopped after the sum of the second derivatives reaches the parameter z. In short: TFS looks how quickly the probabilities of the tokens decrease and cuts off the tail of unlikely tokens using the parameter z. Typical values for z are in the range of 0.9 to 0.95. A value of 1.0 would include all tokens, and thus disables the effect of TFS.</p> <p>Example usage: <code>--tfs 0.95</code></p>"},{"location":"AI/Llama.cpp/#Locally%20Typical%20Sampling","title":"Locally Typical Sampling","text":"<ul> <li><code>--typical N</code>: Enable locally typical sampling with parameter p (default: 1.0, 1.0 = disabled).</li> </ul> <p>Locally typical sampling promotes the generation of contextually coherent and diverse text by sampling tokens that are typical or expected based on the surrounding context. By setting the parameter p between 0 and 1, you can control the balance between producing text that is locally coherent and diverse. A value closer to 1 will promote more contextually coherent tokens, while a value closer to 0 will promote more diverse tokens. A value equal to 1 disables locally typical sampling.</p> <p>Example usage: <code>--typical 0.9</code></p>"},{"location":"AI/Llama.cpp/#Mirostat%20Sampling","title":"Mirostat Sampling","text":"<ul> <li><code>--mirostat N</code>: Enable Mirostat sampling, controlling perplexity during text generation (default: 0, 0 = disabled, 1 = Mirostat, 2 = Mirostat 2.0).</li> <li><code>--mirostat-lr N</code>: Set the Mirostat learning rate, parameter eta (default: 0.1).</li> <li><code>--mirostat-ent N</code>: Set the Mirostat target entropy, parameter tau (default: 5.0).</li> </ul> <p>Mirostat is an algorithm that actively maintains the quality of generated text within a desired range during text generation. It aims to strike a balance between coherence and diversity, avoiding low-quality output caused by excessive repetition (boredom traps) or incoherence (confusion traps).</p> <p>The <code>--mirostat-lr</code> option sets the Mirostat learning rate (eta). The learning rate influences how quickly the algorithm responds to feedback from the generated text. A lower learning rate will result in slower adjustments, while a higher learning rate will make the algorithm more responsive. The default value is <code>0.1</code>.</p> <p>The <code>--mirostat-ent</code> option sets the Mirostat target entropy (tau), which represents the desired perplexity value for the generated text. Adjusting the target entropy allows you to control the balance between coherence and diversity in the generated text. A lower value will result in more focused and coherent text, while a higher value will lead to more diverse and potentially less coherent text. The default value is <code>5.0</code>.</p> <p>Example usage: <code>--mirostat 2 --mirostat-lr 0.05 --mirostat-ent 3.0</code></p>"},{"location":"AI/Llama.cpp/#Logit%20Bias","title":"Logit Bias","text":"<ul> <li><code>-l TOKEN_ID(+/-)BIAS, --logit-bias TOKEN_ID(+/-)BIAS</code>: Modify the likelihood of a token appearing in the generated text completion.</li> </ul> <p>The logit bias option allows you to manually adjust the likelihood of specific tokens appearing in the generated text. By providing a token ID and a positive or negative bias value, you can increase or decrease the probability of that token being generated.</p> <p>For example, use <code>--logit-bias 15043+1</code> to increase the likelihood of the token 'Hello', or <code>--logit-bias 15043-1</code> to decrease its likelihood. Using a value of negative infinity, <code>--logit-bias 15043-inf</code> ensures that the token <code>Hello</code> is never produced.</p> <p>A more practical use case might be to prevent the generation of <code>\\code{begin}</code> and <code>\\code{end}</code> by setting the <code>\\</code> token (29905) to negative infinity with <code>-l 29905-inf</code>. (This is due to the prevalence of LaTeX codes that show up in LLaMA model inference.)</p> <p>Example usage: <code>--logit-bias 29905-inf</code></p>"},{"location":"AI/Llama.cpp/#RNG%20Seed","title":"RNG Seed","text":"<ul> <li><code>-s SEED, --seed SEED</code>: Set the random number generator (RNG) seed (default: -1, -1 = random seed).</li> </ul> <p>The RNG seed is used to initialize the random number generator that influences the text generation process. By setting a specific seed value, you can obtain consistent and reproducible results across multiple runs with the same input and settings. This can be helpful for testing, debugging, or comparing the effects of different options on the generated text to see when they diverge. If the seed is set to a value less than 0, a random seed will be used, which will result in different outputs on each run.</p>"},{"location":"AI/Llama.cpp/#Performance%20Tuning%20and%20Memory%20Options","title":"Performance Tuning and Memory Options","text":"<p>These options help improve the performance and memory usage of the LLaMA models. By adjusting these settings, you can fine-tune the model's behavior to better suit your system's capabilities and achieve optimal performance for your specific use case.</p>"},{"location":"AI/Llama.cpp/#Number%20of%20Threads","title":"Number of Threads","text":"<ul> <li><code>-t N, --threads N</code>: Set the number of threads to use during computation. For optimal performance, it is recommended to set this value to the number of physical CPU cores your system has (as opposed to the logical number of cores). Using the correct number of threads can greatly improve performance.</li> </ul>"},{"location":"AI/Llama.cpp/#Mlock","title":"Mlock","text":"<ul> <li><code>--mlock</code>: Lock the model in memory, preventing it from being swapped out when memory-mapped. This can improve performance but trades away some of the advantages of memory-mapping by requiring more RAM to run and potentially slowing down load times as the model loads into RAM.</li> </ul>"},{"location":"AI/Llama.cpp/#No%20Memory%20Mapping","title":"No Memory Mapping","text":"<ul> <li><code>--no-mmap</code>: Do not memory-map the model. By default, models are mapped into memory, which allows the system to load only the necessary parts of the model as needed. However, if the model is larger than your total amount of RAM or if your system is low on available memory, using mmap might increase the risk of pageouts, negatively impacting performance. Disabling mmap results in slower load times but may reduce pageouts if you're not using <code>--mlock</code>. Note that if the model is larger than the total amount of RAM, turning off mmap would prevent the model from loading at all.</li> </ul>"},{"location":"AI/Llama.cpp/#NUMA%20support","title":"NUMA support","text":"<ul> <li><code>--numa</code>: Attempt optimizations that help on some systems with non-uniform memory access. This currently consists of pinning an equal proportion of the threads to the cores on each NUMA node, and disabling prefetch and readahead for mmap. The latter causes mapped pages to be faulted in on first access instead of all at once, and in combination with pinning threads to NUMA nodes, more of the pages end up on the NUMA node where they are used. Note that if the model is already in the system page cache, for example because of a previous run without this option, this will have little effect unless you drop the page cache first. This can be done by rebooting the system or on Linux by writing '3' to '/proc/sys/vm/drop_caches' as root.</li> </ul>"},{"location":"AI/Llama.cpp/#Memory%20Float%2032","title":"Memory Float 32","text":"<ul> <li><code>--memory-f32</code>: Use 32-bit floats instead of 16-bit floats for memory key+value. This doubles the context memory requirement and cached prompt file size but does not appear to increase generation quality in a measurable way. Not recommended.</li> </ul>"},{"location":"AI/Llama.cpp/#Batch%20Size","title":"Batch Size","text":"<ul> <li><code>-b N, --batch-size N</code>: Set the batch size for prompt processing (default: 512). This large batch size benefits users who have BLAS installed and enabled it during the build. If you don't have BLAS enabled (\"BLAS=0\"), you can use a smaller number, such as 8, to see the prompt progress as it's evaluated in some situations.</li> </ul>"},{"location":"AI/Llama.cpp/#Prompt%20Caching","title":"Prompt Caching","text":"<ul> <li><code>--prompt-cache FNAME</code>: Specify a file to cache the model state after the initial prompt. This can significantly speed up the startup time when you're using longer prompts. The file is created during the first run and is reused and updated in subsequent runs. Note: Restoring a cached prompt does not imply restoring the exact state of the session at the point it was saved. So even when specifying a specific seed, you are not guaranteed to get the same sequence of tokens as the original generation.</li> </ul>"},{"location":"AI/Llama.cpp/#Grammars","title":"Grammars","text":"<ul> <li><code>--grammar GRAMMAR</code>, <code>--grammar-file FILE</code>: Specify a grammar (defined inline or in a file) to constrain model output to a specific format. For example, you could force the model to output JSON or to speak only in emojis. See the GBNF guide for details on the syntax.</li> </ul>"},{"location":"AI/Llama.cpp/#Quantization","title":"Quantization","text":"<p>For information about 4-bit quantization, which can significantly improve performance and reduce memory usage, please refer to llama.cpp's primary README.</p>"},{"location":"AI/Llama.cpp/#Additional%20Options","title":"Additional Options","text":"<p>These options provide extra functionality and customization when running the LLaMA models:</p> <ul> <li><code>-h, --help</code>: Display a help message showing all available options and their default values. This is particularly useful for checking the latest options and default values, as they can change frequently, and the information in this document may become outdated.</li> <li><code>--verbose-prompt</code>: Print the prompt before generating text.</li> <li><code>--mtest</code>: Test the model's functionality by running a series of tests to ensure it's working properly.</li> <li><code>-ngl N, --n-gpu-layers N</code>: When compiled with appropriate support (currently CLBlast or cuBLAS), this option allows offloading some layers to the GPU for computation. Generally results in increased performance.</li> <li><code>-mg i, --main-gpu i</code>: When using multiple GPUs this option controls which GPU is used for small tensors for which the overhead of splitting the computation across all GPUs is not worthwhile. The GPU in question will use slightly more VRAM to store a scratch buffer for temporary results. By default GPU 0 is used. Requires cuBLAS.</li> <li><code>-ts SPLIT, --tensor-split SPLIT</code>: When using multiple GPUs this option controls how large tensors should be split across all GPUs. <code>SPLIT</code> is a comma-separated list of non-negative values that assigns the proportion of data that each GPU should get in order. For example, \"3,2\" will assign 60% of the data to GPU 0 and 40% to GPU 1. By default the data is split in proportion to VRAM but this may not be optimal for performance. Requires cuBLAS.</li> <li><code>-lv, --low-vram</code>: Do not allocate a VRAM scratch buffer for holding temporary results. Reduces VRAM usage at the cost of performance, particularly prompt processing speed. Requires cuBLAS.</li> <li><code>--lora FNAME</code>: Apply a LoRA (Low-Rank Adaptation) adapter to the model (implies --no-mmap). This allows you to adapt the pretrained model to specific tasks or domains.</li> <li><code>--lora-base FNAME</code>: Optional model to use as a base for the layers modified by the LoRA adapter. This flag is used in conjunction with the <code>--lora</code> flag, and specifies the base model for the adaptation.</li> </ul>"},{"location":"AI/Llama.cpp/#Convert","title":"Convert","text":"<p>Outlines how to take a supported pytorch bin file and convert it to GGUF.</p> <pre><code># run the below from the root folder where llama.cpp was built/installed\n# obtain the original model and all the corresponding files, and create a new folder inside models (i.e. 7B)\n\n# install Python dependencies\npython3 -m pip install -r requirements.txt\n\n# convert the 7B model to ggml FP16 format\npython3 convert.py models/7B/\n\n  # [Optional] for models using BPE tokenizers\n  python convert.py models/7B/ --vocabtype bpe\n\n# quantize the model to 4-bits (using q4_k_m method)\n./quantize ./models/7B/ggml-model-f16.gguf ./models/7B/ggml-model-q4_k_m.gguf q4_k_m\n\n  # update the gguf filetype to current if older version is unsupported by another application\n  ./quantize ./models/7B/ggml-model-q4_k_m.gguf ./models/7B/ggml-model-q4_k_m-v2.gguf COPY\n\n# run the inference\n./main -m ./models/7B/ggml-model-q4_k_m.gguf -n 128\n</code></pre>"},{"location":"AI/The-Basics/","title":"The Basics","text":"<p>Some amazing reads here and here. Start with the first one for a introduction, and the second for a cool (and nerdy) representation of what's going on. </p>"},{"location":"AI/Transcribe/","title":"Transcribe","text":"<p>Content from here.</p> <p>Purpose: These instructions cover the steps not explicitly set out on the main Whisper page, e.g. for those who have never used python code/apps before and do not have the prerequisite software already installed. </p>"},{"location":"AI/Transcribe/#Requirements","title":"Requirements","text":"<ul> <li>Full admin rights on your computer.</li> <li>A PC with a CUDA-capable dedicated GPU with at least 4GB of VRAM (but more VRAM is better).  See: Available models and languages</li> <li>For online installation: An Internet connection for the initial download and setup.</li> <li>For offline installation: Download on another computer and then install manually using the \"OPTIONAL/OFFLINE\" instructions below.</li> </ul>"},{"location":"AI/Transcribe/#Installation","title":"Installation","text":""},{"location":"AI/Transcribe/#Unlisted%20Pre-Requisites","title":"Unlisted Pre-Requisites","text":"<ul> <li>Before you can run whisper you must download and install the following items. (For offline installation just download the files on another machine and move them to your offline machine to install them.) <ul> <li>NVIDIA CUDA drivers: https://developer.nvidia.com/cuda-downloads </li> <li>Python 3.9 or 3.10 (x64 version) from https://www.python.org/ (Whisper claims to run with &gt;3.7 but as of 2023-01-18 some dependencies require &gt;3.7 but &lt;3.11).</li> <li>FFMPEG<ul> <li>To install via Scoop (https://scoop.sh/), in PowerShell run<ul> <li><code>Set-ExecutionPolicy RemoteSigned -Scope CurrentUser</code></li> <li><code>irm get.scoop.sh | iex</code></li> <li><code>scoop install ffmpeg</code></li> </ul> </li> <li>OPTIONAL/OFFLINE: Follow instructions here: How to install and use FFMPEG and make sure not to skip the part about adding FFMPEG to the Windows PATH variable. </li> </ul> </li> <li>Git for windows from https://gitforwindows.org/</li> </ul> </li> <li>Reboot after installing these items.</li> </ul>"},{"location":"AI/Transcribe/#Whisper%20Install%20Online%20Install%20for%20later%20Offline%20Use","title":"Whisper Install (Online Install for later Offline Use)","text":"<ul> <li>Open a command prompt and type these commands:</li> <li><code>pip install git+https://github.com/openai/whisper.git</code></li> <li><code>pip install blobfile</code></li> <li>Continue to Step 3: Download Other Required Files</li> </ul>"},{"location":"AI/Transcribe/#Whisper%20Install%20Offline%20Install%20for%20later%20Offline%20Use","title":"Whisper Install (Offline Install for later Offline Use)","text":"<ul> <li>Option 1: Get the most up to date version of Whisper: <ul> <li>Install Python and Git from Step 1 on an second computer you can connect to the internet and reboot to ensure both are working. </li> <li>On the ONLINE machine open a command prompt in any empty folder and type the following commands:<ul> <li><code>pip download git+https://github.com/openai/whisper.git</code></li> <li><code>pip download blobfile</code></li> </ul> </li> </ul> </li> <li>Option 2: Download all the necessary files from here OPENAI-Whisper-20230314 Offline Install Package</li> <li>Copy the files to your OFFLINE machine and open a command prompt in that folder where you put the files, and run<ul> <li><code>pip install openai-whisper-20230314.zip</code> (note the date may have changed if you used Option 1 above).</li> <li><code>pip install blobfile-2.0.2-py3-none-any.whl</code>. (note the version may have changed if you used Option 1 above).</li> </ul> </li> <li>Continue to Step 3: Download Other Required Files</li> </ul>"},{"location":"AI/Transcribe/#Download%20Other%20Required%20Files%20for%20Offline%20Use","title":"Download Other Required Files (for Offline Use)","text":"<ul> <li>Download Whisper's Language Model files place them in <code>C:\\Users\\[Username]\\.cache\\whisper</code> Note: If the links are dead updated links can be found at lines 17-27 here: init.py <ul> <li>Tiny.En</li> <li>Tiny</li> <li>Base.En</li> <li>Base</li> <li>Small.En</li> <li>Small</li> <li>Medium.En</li> <li>Medium</li> <li>Large-v1</li> <li>Large-v2 (Annoucing the large-v2 model)</li> </ul> </li> <li>Download Whisper's vocabulary and encoder files. (Per issue 1399).<ul> <li>Download Vocab.bpe</li> <li>Download Encoder.json</li> <li>Install the files to a folder of your choosing, e.g. <code>C:\\Users\\[Username]\\.cache\\whisper</code>.</li> <li>Update file links in your local copy of openai_public.py which will be installed in your python folder e.g. <code>C:\\Users\\[UserName]\\AppData\\Local\\Programs\\Python\\Python310-32\\Lib\\site-packagespython3.9/site-packages/tiktoken_ext/openai_public.py</code> to point to where you downloaded the files.<ul> <li>Remove the URL <code>\"https://openaipublic.blob.core.windows.net/gpt-2/encodings/main/\"</code> and replace it with your local copy, e.g. <code>\"C:/Users/[Username]/.cache/whisper/vocab.bpe\"</code> and <code>\"C:/Users/[Username]/.cache/whisper/encoder.json\"</code></li> </ul> </li> </ul> </li> </ul> <pre><code>def gpt2():\n    mergeable_ranks = data_gym_to_mergeable_bpe_ranks(\n        vocab_bpe_file=\"C:/Users/nic/.cache/whisper/vocab.bpe\",\n        encoder_json_file=\"C:/Users/nic/.cache/whisper/encoder.json\",\n    )\n</code></pre>"},{"location":"AI/Transcribe/#Alternative%20Offline%20Method","title":"Alternative Offline Method","text":"<p>See the pre-compiled .exe version of Whisper provided here: Purfview / Whisper Standalone</p>"},{"location":"AI/Vector-Search/","title":"Vector Search","text":"<p>There's an obvious need for production-level packages, but sometimes all you need is something simple. The developer of the search engine Kagi created their own VectorDB python package. It's a very easy (for me at least) package to understand and play with. After <code>pip install vectordb2</code>, the examples on that page are great. I'm adding them below in case something changes.</p> <pre><code>from vectordb import Memory\n\nmemory = Memory()\n\n# text = \"...\"\n# metadata = {...}\n\n# Save text with metadata\n# This will automatically embed content\nmemory.save(text, metadata)\n\n# Search for top n relevant chunks\n# We will automatically use the fastest vector search backend\nresults = memory.search(query, top_n=3)\n</code></pre> <p>and a more advanced one (again, from the above page, but with text removed)</p> <pre><code>from vectordb import Memory\n\nmemory = Memory(chunking_strategy={'mode':'sliding_window', 'window_size': 128, 'overlap': 16})\n\ntext = \"\"\"\nMachine learning is a method of data analysis that automates analytical model building.\nMachine learning is a powerful tool that can be used to solve a wide variety of problems. As the amount of data available continues to grow, machine learning is likely to become even more important in the future.\n\n\"\"\"\n\nmetadata = {\"title\": \"Introduction to Machine Learning\", \"url\": \"https://example.com/introduction-to-machine-learning\"}\n\nmemory.save(text, metadata)\n\ntext2 = \"\"\"\nArtificial intelligence (AI) is the simulation of human intelligence in machines\nthat are programmed to think like humans and mimic their actions.\nIt is important to weigh the potential benefits and risks of AI carefully as we continue to develop this technology. With careful planning and oversight, AI has the potential to make the world a better place. However, if we are not careful, it could also lead to serious problems.\n\"\"\"\n\nmetadata2 = {\"title\": \"Introduction to Artificial Intelligence\", \"url\": \"https://example.com/introduction-to-artificial-intelligence\"}\n\nmemory.save(text2, metadata2)\n\nquery = \"What is the relationship between AI and machine learning?\"\n\nresults = memory.search(query, top_n=3)\n\nprint(results)\n</code></pre>"},{"location":"AI/Vector-Search/#Function","title":"Function","text":"<p>Here's a function equivalent of the above, with the intent to enable bulk loading from other data sources.</p> <pre><code>from vectordb import Memory\n\ndef init_store(items):\n    memory = Memory(chunking_strategy={'mode': 'sliding_window', 'window_size': 128, 'overlap': 16})\n\n    for item in items:\n        text, metadata = item\n        memory.save(text, metadata)\n\n    return memory\n\ndef search_store(memory, query):\n    results = memory.search(query, top_n=3)\n    return results\n\nitems = [\n    (\"Machine learning is a method of data analysis that automates analytical model building.\", \n     {\"title\": \"Introduction to Machine Learning\", \"url\": \"https://example.com/introduction-to-machine-learning\"}),\n    (\"Artificial intelligence (AI) is the simulation of human intelligence in machines that are programmed to think like humans and mimic their actions.\", \n     {\"title\": \"Introduction to Artificial Intelligence\", \"url\": \"https://example.com/introduction-to-artificial-intelligence\"})\n]\n\nmemory = init_store(items)\n\nquery = \"What is the relationship between AI and machine learning?\"\n# query = \"What is the purpose of machine learning?\"\n\nresults = search_store(memory, query)\n\nchunk = results[0]['chunk']\ntitle = results[0]['metadata']['title']\nurl = results[0]['metadata']['url']\n\nprint(f\"Chunk: {chunk}\\nTitle: {title}\\nURL: {url}\")\n</code></pre>"},{"location":"AI/Vector-Search/#CSV","title":"CSV","text":"<p>Here's an extended example with a CSV as the source for items. Each column after <code>text</code> will be added to the metadata object. Note I added a file to store the results, which is a Python pickle.</p> <pre><code>from vectordb import Memory\nfrom pathlib import Path\nimport csv\nimport os\n\nos.chdir(Path(__file__).parent)\n\n\ndef init_store(csv_file):\n    memory = Memory(memory_file='memory.pickle',chunking_strategy={\n        'mode':\n        'sliding_window',\n        'window_size': 128,\n        'overlap': 16})\n\n    with open(csv_file, newline='') as csvfile:\n        reader = csv.reader(csvfile)\n        headers = next(reader)   # First row is the header row\n        for row in reader:\n            text = row[0]\n            metadata = {header: value for header,\n                        value in zip(headers[1:], row[1:])}\n            memory.save(text, metadata)\n\n    return memory\n\n\ndef search_store(memory, query):\n    results = memory.search(query, top_n=3)\n    return results\n\n\nmemory = init_store(\"example.csv\")\n\nquery = \"What is the relationship between AI and machine learning?\"\n# query = \"What is the purpose of machine learning?\"\n\nresults = search_store(memory, query)\n\nchunk = results[0]['chunk']\ntitle = results[0]['metadata']['title']\nurl = results[0]['metadata']['url']\n\nprint(f\"Chunk: {chunk}\\nTitle: {title}\\nURL: {url}\")\n</code></pre> <p>The csv should look like this:</p> text title url Machine learning is a method of data analysis that automates analytical model building. Introduction to Machine Learning https://example.com/introduction-to-machine-learning Artificial intelligence (AI) is the simulation of human intelligence in machines that are programmed to think like humans and mimic their actions. Introduction to Artificial Intelligence https://example.com/introduction-to-artificial-intelligence"},{"location":"AI/Vector-Search/#Web%20App","title":"Web App","text":"<p>Assuming you created a stored memory file <code>memory.pickle</code> (see above), a quick and easy way to search it is to create a web app. Flask is popular, and with <code>pip install flask</code> you're off to the races. Call this first file <code>app.py</code>, and after creating the others start is with <code>python app.py</code>.</p> <pre><code>from flask import Flask, request, render_template\nfrom vectordb import Memory\nimport os\nfrom pathlib import Path\n\nos.chdir(Path(__file__).parent)\n\napp = Flask(__name__)\nmemory=Memory(memory_file='memory.pickle')\n\n@app.route('/', methods=['GET', 'POST'])\ndef search():\n    results = None\n    if request.method == 'POST':\n        query = request.form.get('query')\n        results = memory.search(query, top_n=10, unique=True, batch_results=\"flatten\")\n    return render_template('index.html', results=results)\n\nif __name__ == \"__main__\":\n    app.run(debug=True)\n</code></pre> <p>Here's the HTML page to get going, which you'll name <code>index.html</code>.</p> <pre><code>&lt;!-- Put this file in templates/index.html --&gt;\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n    &lt;head&gt;\n        &lt;title&gt;Super Cool Search&lt;/title&gt;\n        &lt;link rel=\"stylesheet\" type=\"text/css\" href=\"{{ url_for('static', filename='styles.css') }}\"&gt;\n    &lt;/head&gt;\n    &lt;body&gt;\n        &lt;div id=\"header\"&gt;&lt;h2 style=\"text-align: center;\"&gt;Super Cool Search, now with embeddings!&lt;/h2&gt;&lt;/div&gt;\n        &lt;form method=\"POST\" class=\"search-box\"&gt;\n            &lt;input type=\"text\" name=\"query\" required&gt;\n            &lt;button type=\"submit\"&gt;Search&lt;/button&gt;\n        &lt;/form&gt;\n        {% if results %}\n            {% for result in results %}\n                &lt;div class=\"card\"&gt;\n                    &lt;h3&gt;{{result['chunk']}}&lt;/h3&gt;\n                    &lt;p&gt;{{result['metadata']['title']}}&lt;/p&gt;\n                    &lt;a href=\"{{result['metadata']['url']}}\" target=\"_blank\" rel=\"noopener noreferrer\"&gt;{{result['metadata']['url']}}&lt;/a&gt;\n                &lt;/div&gt;\n            {% endfor %}\n        {% else %}\n            &lt;h2&gt;No results found.&lt;/h2&gt;\n        {% endif %}\n    &lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>and the css</p> <pre><code>/* Put this file in static/styles.css */\nbody {\n    background: linear-gradient(to bottom right, #03254c, #167F92);\n    padding: 10%;\n}\n\n#header {\n    border: 1px solid #ddd;\n    background-color: #fff;\n    padding: 1rem;\n    margin: 1rem 0;\n}\n\nform.search-box {\n    display: flex;\n    justify-content: center;\n    align-items: center;\n    height: 10vh;\n    background-color: #000;\n    padding: 1rem;\n}\n\nform.search-box input[type=\"text\"] {\n    flex: 1;\n    margin-right: 1rem;\n    max-width: 90%;\n    padding: 20px;\n}\n\ndiv.card {\n    border: 1px solid #ddd;\n    background-color: #fff;\n    padding: 1rem;\n    margin: 1rem 0;\n    z-index: 1;\n    position: relative;\n}\n</code></pre>"},{"location":"AI/Vector-Search/#Pickle","title":"Pickle","text":"<p>Want to see the contents you saved? Here are a few options...</p> <p><code>import pickle; pickle.load(open('memory.pickle', 'rb'))</code></p> <p>or a bit prettier...</p> <pre><code>import pickle\nimport pprint\n\nloaded_data = pickle.load(open('memory.pickle', 'rb'))\npprint.pprint(loaded_data)\n</code></pre> <p>or have it more JSON-y with:</p> <pre><code>import json\nimport pickle\n\nloaded_data = pickle.load(open('memory.pickle', 'rb'))\njson_data = json.dumps(loaded_data, indent=4)  # Set indent=4 for improved readability\nprint(json_data)\n</code></pre>"},{"location":"Apps/Chat%20with%20Docs/","title":"Chat with Docs","text":"<p>Based on this. Added a few lines to run local. This changes the API base URL to whatever you want.</p> <pre><code>...\nimport openai, os\nos.environ[\"OPENAI_API_BASE\"] = \"http://localhost:8000/v1\"\nopenai.api_key = \"nothing\"\n...\n</code></pre> <p>A lot of the other stuff, like the <code>venv</code> setup, used the same steps as previously. I also added <code>include-system-site-packages = true</code> to <code>pyvenv.cfg</code> so I wouldn't have to download CUDA and torch again. Entire code is below.</p> <pre><code>import streamlit as st\nfrom llama_index import VectorStoreIndex, ServiceContext, StorageContext, load_index_from_storage\nfrom llama_index.llms import OpenAI\nimport openai, os\nfrom llama_index import SimpleDirectoryReader\n\n# All based on this: https://blog.streamlit.io/build-a-chatbot-with-custom-data-sources-powered-by-llamaindex/\n# To do: Figure out storing, loading, and updating indices.\n\nos.environ[\"OPENAI_API_BASE\"] = \"http://localhost:8000/v1\"\n\nst.set_page_config(page_title=\"PrivateChat\", page_icon=\"\ud83e\udd99\", layout=\"centered\", initial_sidebar_state=\"auto\", menu_items=None)\nopenai.api_key = \"nothing\"\nst.title(\"Chat with your docs!\")\nst.info(\"Thanks to LlamaIndex and LM Studio\", icon=\"\ud83d\udd25\")\n\nif \"messages\" not in st.session_state.keys(): # Initialize the chat messages history\n    st.session_state.messages = [\n        {\"role\": \"assistant\", \"content\": \"Ask me a question about Streamlit's open-source Python library!\"}\n    ]\n\n@st.cache_resource(show_spinner=False)\ndef load_data():\n    with st.spinner(text=\"Loading and indexing the docs \u2013 hang tight! This should take 1-2 minutes.\"):\n        reader = SimpleDirectoryReader(input_dir=\"./data\", recursive=True)\n        docs = reader.load_data()\n        service_context = ServiceContext.from_defaults(embed_model=\"local:BAAI/bge-base-en-v1.5\")\n        index = VectorStoreIndex.from_documents(docs, service_context=service_context)\n        return index\n\nindex = load_data() # Builds index\n# index.storage_context.persist(persist_dir=\"./storage\") # To save data to disk.\n# index = load_index_from_storage(StorageContext.from_defaults(persist_dir=\"./storage\")) # To load existing data\n\nif \"chat_engine\" not in st.session_state.keys(): # Initialize the chat engine\n        st.session_state.chat_engine = index.as_chat_engine(chat_mode=\"condense_question\", verbose=True)\n\nif prompt := st.chat_input(\"Your question\"): # Prompt for user input and save to chat history\n    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n\nfor message in st.session_state.messages: # Display the prior chat messages\n    with st.chat_message(message[\"role\"]):\n        st.write(message[\"content\"])\n\n# If last message is not from assistant, generate a new response\nif st.session_state.messages[-1][\"role\"] != \"assistant\":\n    with st.chat_message(\"assistant\"):\n        with st.spinner(\"Thinking...\"):\n            response = st.session_state.chat_engine.chat(prompt)\n            st.write(response.response)\n            message = {\"role\": \"assistant\", \"content\": response.response}\n            st.session_state.messages.append(message) # Add response to message history\n</code></pre>"},{"location":"Apps/Python/","title":"Python","text":""},{"location":"Apps/Python/#Path","title":"Path","text":"<p><code>os.path</code> is a Python module that provides functions to interact with filesystem paths. It allows you to manipulate file paths in a way that is compatible with different operating systems. Here are some common functions provided by <code>os.path</code>:</p> <ul> <li><code>os.path.join(path, *paths)</code>: Join one or more path components intelligently. If any component is an absolute path, all previous components are thrown away and joining continues from the absolute path component.</li> </ul> <p>Example: <pre><code>import os\nprint(os.path.join('home', 'user', 'documents', 'file.txt'))\n# Output: home/user/documents/file.txt (on Linux)\n# Output: home\\\\user\\\\documents\\\\file.txt (on Windows)\n</code></pre></p> <ul> <li><code>os.path.split(path)</code>: Split the path into a pair head and tail. The tail is the final component of the path, and the head is everything leading up to that. The result is always a tuple, even if the path ends in a slash.</li> </ul> <p>Example: <pre><code>import os\nprint(os.path.split('/home/user/documents/file.txt'))\n# Output: ('/home/user/documents', 'file.txt')\n</code></pre></p> <ul> <li><code>os.path.splitext(path)</code>: Split the path into a pair root and extension. The extension is everything starting from the last dot in the last path component; the root is everything before that. If there is no dot in the last path component, the root is the entire path and the extension is an empty string.</li> </ul> <p>Example: <pre><code>import os\nprint(os.path.splitext('/home/user/documents/file.txt'))\n# Output: ('/home/user/documents/file', '.txt')\n</code></pre></p> <ul> <li><code>os.path.basename(path)</code>: Return the final component of a path. This is the same as the tail if the path ends in a slash, or the last path component otherwise.</li> </ul> <p>Example: <pre><code>import os\nprint(os.path.basename('/home/user/documents/file.txt'))\n# Output: file.txt\n</code></pre></p> <ul> <li><code>os.path.dirname(path)</code>: Return the full directory component of a path. This is the same as the head if the path ends in a slash, or the whole path otherwise.</li> </ul> <p>Example: <pre><code>import os\nprint(os.path.dirname('/home/user/documents/file.txt'))\n# Output: /home/user/documents\n</code></pre></p> <ul> <li><code>os.path.dirname(file_path)</code>: Get just the folder name a file is in. This function will return the directory component of a path.</li> </ul> <p>Example: <pre><code>import os\nfile_path = '/home/user/documents/file.txt'\nfolder_name = os.path.basename(os.path.dirname(file_path))\nprint(folder_name)  # Output: documents\n</code></pre></p> <ul> <li><code>os.path.isabs(path)</code>: Return True if the path is absolute (i.e., it starts from the root of the filesystem).</li> </ul> <p>Example: <pre><code>import os\nprint(os.path.isabs('/home/user/documents'))\n# Output: True\nprint(os.path.isabs('./relative_path'))\n# Output: False\n</code></pre></p> <ul> <li><code>os.path.exists(path)</code>: Return True if the path exists on the filesystem, or False otherwise.</li> </ul> <p>Example: <pre><code>import os\nprint(os.path.exists('/home/user/documents'))\n# Output: True (if the directory exists)\n# Output: False (if the directory does not exist)\n</code></pre></p> <p>To use <code>os.path</code> in your Python script, you first need to import it: <pre><code>import os\n</code></pre> Then you can call any of its functions as described above.</p>"},{"location":"Apps/Python/#Current%20Directory","title":"Current Directory","text":"<p>There are several ways to set the current working directory to the same location as your Python script:</p> <ul> <li>Using <code>os.chdir()</code> function:</li> </ul> <pre><code>import os\n\nscript_path = os.path.dirname(os.path.abspath(__file__))\nos.chdir(script_path)\n</code></pre> <ul> <li>Using the <code>pathlib</code> library (Python 3.4+):</li> </ul> <pre><code>from pathlib import Path\n\nscript_path = Path(__file__).resolve().parent\nos.chdir(str(script_path))\n</code></pre> <p>Both of these methods will change the current working directory to the same location as your script, making it easy to reference files in relation to the script's location.</p>"},{"location":"Apps/Remove%20Background/","title":"Remove Background","text":"<p>Deployed this app. Made a few tweaks of the icons and UI (including this) but that's about it. Note the primary magic rembg has a lot of additional options and features.</p>"},{"location":"Apps/Remove%20Background/#Setup","title":"Setup","text":"<ol> <li>Navigate to folder where you want to place files.</li> <li>Clone repo with <code>git clone https://github.com/tyler-simons/BackgroundRemoval.git</code></li> <li><code>cd BackgroundRemoval</code></li> <li>Create a virtual environment with <code>python -m venv venv</code></li> <li>Activate with <code>.\\venv\\Scripts\\Activate.ps1</code></li> <li>Install requirements with <code>pip install -r requirements.txt</code></li> <li>Create a folder in the project <code>.\\streamlit\\config.toml</code></li> <li>Run the app with <code>streamlit run bg_remove.py</code></li> </ol> <p>Modify the <code>config.toml</code> to have the below.</p> <pre><code>[browser]\ngatherUsageStats = false\n\n[server]\nport = 80\n</code></pre> <p>Supported icons and their names are here. Basically just changed a few of them.</p> <pre><code>from io import BytesIO\n\nimport streamlit as st\nfrom PIL import Image\nfrom rembg import remove\n\nhide_st_style = \"\"\"\n            &lt;style&gt;\n            MainMenu {visibility: hidden;}\n            footer {visibility: hidden;}\n            header {visibility: hidden;}\n            &lt;/style&gt;\n            \"\"\"\n\nst.set_page_config(layout=\"wide\", page_title=\"Image Background Remover\")\n\nst.write(\"## Remove background from your image\")\nst.write(\n    \"Upload an image to watch the background magically be removed. Full quality images can be downloaded from the sidebar. This code is open source and available [here](&lt;https://github.com/tyler-simons/BackgroundRemoval&gt;) on GitHub.\"\n)\nst.sidebar.write(\"## :arrow_up: Upload and Download :arrow_down:\")\n\n# Create the columns\ncol1, col2 = st.columns(2)\n\n# Download the fixed image\ndef convert_image(img):\n    buf = BytesIO()\n    img.save(buf, format=\"PNG\")\n    byte_im = buf.getvalue()\n    return byte_im\n\n# Package the transform into a function\ndef fix_image(upload):\n    image = Image.open(upload)\n    col1.write(\"Original Image :camera:\")\n    col1.image(image)\n\n    fixed = remove(image)\n    col2.write(\"Fixed Image :wrench:\")\n    col2.image(fixed)\n    st.sidebar.markdown(hide_st_style, unsafe_allow_html=True)\n    st.sidebar.download_button(\n        \":sparkles: :sparkles: Download fixed image :sparkles: :sparkles:\", convert_image(fixed), \"fixed.png\", \"image/png\"\n    )\n\n# Create the file uploader\nmy_upload = st.sidebar.file_uploader(\"Upload file here\", label_visibility=\"hidden\", type=[\"png\", \"jpg\", \"jpeg\"])\n\n# Fix the image!\nif my_upload is not None:\n    fix_image(upload=my_upload)\nelse:\n    fix_image(\"./wallaby.jpg\")\n</code></pre> <p></p>"},{"location":"Apps/Shiori/","title":"Shiori","text":"<p>I was looking for a lightweight bookmark manager tool. Stumbled across Shiori. The intent was to move my bookmarks over and add a bit more context to them. At first I was going to use AI to generate tags (and still may), but I figured since the extract is searchable, that's a better place to enter data. The below outlines the process from using my exported <code>bookmarks.html</code> file from Firefox, parsing it, sending the website's contents to a local LLM to summarize, and feeding back into the db. FYI I run the server in portable mode on Windows with <code>.\\shiori.exe serve --portable</code>.</p> <p>There's a lot of optimization you could do with the below, but this works well enough for me.</p> <p>Tip</p> <p>Setup the software with the settings you want (metadata, archive, etc.) before you do the below.</p> <p></p> <p>Danger</p> <p>I used AI to write all the below. It may break/not work for you/etc. Always review and understand code before running. Run at your own risk.</p>"},{"location":"Apps/Shiori/#Bookmark%20to%20CLI","title":"Bookmark to CLI","text":"<p>I ran the CLI call <code>.\\shiori add https://example.com</code> (because PowerShell) to create the entries based on the extracted data. V1 is just the bookmark, V2 creates bookmarks and tags based on the folder name. The below just outputs to the terminal, and I copy/paste into another terminal to add them.</p> <p>I also used this to create a CSV with just the URLs in it, with the header <code>url</code>. I called the file <code>website-list.csv</code>.</p> <p>Tip</p> <p>If you're using the <code>--portable</code> flag don't forget to update the below to use it. So the CLI call would be <code>.\\shiori add http://example.com --portable</code>. Otherwise it will write to the default database in <code>%LOCALAPPDATA%</code>.</p>"},{"location":"Apps/Shiori/#V1","title":"V1","text":"<pre><code>import re\nimport os\n\ndef clear_console():\n    os.system('cls')  # for Windows\n\nclear_console()\n\n# Get the current working directory\ncwd = os.getcwd()\n\n# Change the CWD to the location of this script\nscript_dir = os.path.dirname(os.path.realpath(__file__))\nos.chdir(script_dir)\n\n# Open and read the file\nwith open(\"bookmarks.html\", encoding='utf-8') as file:\n    content = file.read()\n\npattern = r'&lt;H3.*?&gt;(.*?)&lt;/H3&gt;'\nmatches = re.findall(pattern, content)\nformatted_folders = [\"{}\".format(match) for match in matches]\nprint(\"Bookmark folders\\n\")\nprint(\"\\n\".join(formatted_folders))\n\nlinks = re.findall('&lt;A HREF=\"([^\"]*)\"', content)\nformatted_links = [\".\\shiori add {} --portable\".format(link) for link in links]\nprint(\"\\n\\nFormatting to make CLI calls\\n\")\nprint(\"\\n\".join(formatted_links))\n\nformatted_links = [\"{}\".format(link) for link in links]\nprint(\"\\n\\nFormatting to make CSVs\\n\")\nprint(\"\\n\".join(formatted_links))\n</code></pre>"},{"location":"Apps/Shiori/#V2","title":"V2","text":"<p>Example</p> <p>This one is largely untested. Turns out I didn't organize my bookmarks into folders as well as I should have \ud83d\ude10.</p> <pre><code>import re\nimport os\nfrom pathlib import Path\ndef clear_console():\n    os.system('cls')  # for Windows\n\n\nclear_console()\n\n# Get the current working directory\ncwd = os.getcwd()\n\n# Change the CWD to the location of this script\nscript_dir = os.path.dirname(os.path.realpath(__file__))\nos.chdir(script_dir)\n\ndef parse_bookmarks_file(filename):\n    \"\"\"\n    Parses a bookmarks.html file and extracts URL, title, and tags information.\n\n    Args:\n        filename (str): The path to the bookmarks.html file.\n\n    Returns:\n        list: A list of dictionaries, where each dictionary represents a bookmark with keys\n              'url', 'title', and 'tags'.\n    \"\"\"\n\n    bookmarks = []\n    current_folder = []  # Keep track of current folder hierarchy\n    with open(filename, 'r') as f:\n        lines = f.readlines()\n\n    # Regular expression patterns to match different parts of the HTML data\n    url_pattern = re.compile(r'HREF=\"(.*?)\"')\n    title_pattern = re.compile(r'&gt;([^&lt;]*)&lt;')\n    # Updated pattern for folders\n    folder_pattern = re.compile(r'&lt;H3.*?&gt;(.*?)&lt;/H3&gt;')\n\n    for line in lines:\n        folder_match = folder_pattern.search(line)\n        if folder_match:\n            # Reset folder hierarchy for each new folder\n            current_folder = [folder_match.group(1)]\n\n        url_match = url_pattern.search(line)\n        title_match = title_pattern.search(line)\n\n        if url_match:\n            url = url_match.group(1)\n            title = title_match.group(1) if title_match else None\n            tags = current_folder  # Use current folder hierarchy as tags\n\n            bookmarks.append({'url': url, 'title': title, 'tags': tags})\n\n    return bookmarks\n\n\ndef generate_shiori_commands(bookmarks, tags_as_folders=False):\n    \"\"\"\n    Generates Shiori add commands based on the extracted bookmark information.\n\n    Args:\n        bookmarks (list): A list of dictionaries representing bookmarks.\n        tags_as_folders (bool, optional): Whether to treat tags as folders (default: False).\n\n    Returns:\n        list: A list of Shiori add commands as strings.\n    \"\"\"\n\n    commands = []\n    for bookmark in bookmarks:\n        url = bookmark['url']\n        title = bookmark['title'] or '(no title)'\n        tags = ','.join(bookmark['tags'])\n\n        if tags_as_folders:\n            folder_path = '/'.join(tags) if tags else ''\n            command = f\".\\\\shiori add {url} -t {folder_path}\"\n        else:\n            command = f\".\\\\shiori add {url} -t {tags}\"\n\n        commands.append(command)\n\n    return commands\n\n\n# Replace 'bookmarks.html' with the actual path to your file\nbookmarks = parse_bookmarks_file('bookmarks.html')\ncommands = generate_shiori_commands(bookmarks)\n\nprint(\"Generated Shiori commands:\")\nfor command in commands:\n    print(command)\n</code></pre>"},{"location":"Apps/Shiori/#Summarize%20URLs","title":"Summarize URLs","text":"<p>Took that CSV and fed it through Beautiful Soup then into LM Studio in server mode to create <code>websites-with-summaries.csv</code>. Since it's the standard OpenAI format you can use whatever you have access to and just update the <code>base_url</code> and other required fields below.</p> <pre><code>import csv\nimport os\nimport requests\nfrom bs4 import BeautifulSoup\nfrom openai import OpenAI\nimport pandas as pd\n\ndef clear_console():\n    os.system('cls')  # for Windows\n\nclear_console()\n\n# Get the current working directory\ncwd = os.getcwd()\n\n# Change the CWD to the location of this script\nscript_dir = os.path.dirname(os.path.realpath(__file__))\nos.chdir(script_dir)\n\n# Set your OpenAI secret key\nclient = OpenAI(base_url=\"http://localhost:8000/v1\", api_key=\"not-needed\")\n\nheaders = {\n    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'\n}\n\ndef get_text(url):\n    response = requests.get(url, headers=headers)\n    soup = BeautifulSoup(response.content, 'html.parser')\n    text = soup.get_text()\n    return text[:1000]   # Return first few hundred words\n\ndef summarize(text):\n    response = client.chat.completions.create(\n    model=\"local-model\", # this field is currently unused\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are an expert website description summary tool.\"},\n        {\"role\": \"user\", \"content\": f\"Summarize this webpage to around 500 characters. Add keywords at the end to make it easier to search for in the future. Text to summarize: {text}\"}\n    ],\n    temperature=0.7,\n    )\n    return response.choices[0].message.content\n\ndef main():\n    # Read CSV file using pandas\n    df = pd.read_csv('websites.csv')\n    with open(\"websites_with_summaries.csv\", \"w\", newline=\"\") as csvfile:\n        writer = csv.writer(csvfile)\n        for index, url in enumerate(df['url']):   # Assuming CSV has one column named 'url'\n            print(f\"\\nProcessing {index + 1}/{len(df)}:\")\n\n            try:\n                text = get_text(url)\n                summary = summarize(text)\n\n                writer.writerow([url, summary])\n\n                print(summary)\n            except Exception as e:\n                writer.writerow([url, f\"Error processing {url}: {e}\"])\n                print(f\"Error processing {url}: {e}\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"Apps/Shiori/#Extract%20into%20DB","title":"Extract into DB","text":"<p>I converted the CSV to XLSX (I don't get how Excel treats commas just fine within cells and CSVs struggle) and added the headers <code>url</code> and <code>excerpt</code>.</p> <p>Warning</p> <p>You're writing to your database! I recommend you write to a backup first, and see how it goes. You can always just browse the data with a tool like DB Browser for SQLite.</p> <pre><code>import openpyxl\nimport sqlite3\nimport os\n\ndef clear_console():\n    os.system('cls')  # for Windows\n\nclear_console()\n\n# Get the current working directory\ncwd = os.getcwd()\n\n# Change the CWD to the location of this script\nscript_dir = os.path.dirname(os.path.realpath(__file__))\nos.chdir(script_dir)\n\n# Define source and destination files\nexcel_file = r\"websites-with-summaries.xlsx\"\ndatabase_file = r\"shiori-data\\shiori.db\"\n\n# Connect to database\nconn = sqlite3.connect(database_file)\ncur = conn.cursor()\n\n# Open Excel workbook\nwb = openpyxl.load_workbook(excel_file)\n\n# Access specific sheet (optional)\nsheet = wb[\"websites-with-summaries\"]  # Change \"Sheet1\" to your desired sheet name\n\n# Iterate through rows and update database\nfor row in sheet.iter_rows(min_row=2):  # Skip header row (start from row 2)\n    url = row[0].value.strip()  # Access URL value from first cell\n    excerpt = row[1].value.strip()  # Access excerpt value from second cell\n    # Update excerpt in database\n    sql = \"UPDATE bookmark SET excerpt = ? WHERE url = ?\"\n    cur.execute(sql, (excerpt, url))\n\n# Commit changes and close connection\nconn.commit()\nconn.close()\n\nprint(\"Excerpts updated successfully from Excel file!\")\n</code></pre>"},{"location":"Apps/Shiori/#Success","title":"Success","text":"<p>Now you should have a much richer library of bookmarks and metadata. You could expand (and heavily optimize) the above to apply to tags and who knows what else.</p>"},{"location":"Markdown/Cheat%20Sheet/","title":"Cheat Sheet","text":"<p>Here's how to make bold text and italicized text</p> <p>blockquote text is here.</p> <p>You can embed video with an HTML tag like so (but it should NOT be in the code block). The below HTML needs an extra <code>../</code> as shown.</p> <pre><code>&lt;video width=\"100%\" controls&gt;\n  &lt;source src=\"../../_assets/VideoName.mp4\" type=\"video/mp4\"&gt;\n&lt;/video&gt;\n</code></pre> <p>This text will be italic This will also be italic</p> <p>This text will be bold This will also be bold</p> <p>~~this will be strikethrough'd~~</p> <p>==this will be highlighted==</p> <p>Mermaid for diagrams (disabled for now on this site, but easy to re-enable in <code>mkdocs.yml</code>). Example Diagrams will be broken too.</p> <pre><code>gantt\ntitle A Gantt Diagram\ndateFormat  YYYY-MM-DD\nsection Section\nA task           :a1, 2014-01-01, 30d\nAnother task     :after a1  , 20d\nsection Another\nTask in sec      :2014-01-12  , 12d\nanother task      : 24d</code></pre> <pre><code>graph TD\nA[Christmas] --&gt;|Get money| B(Go shopping)\nB --&gt; C{Let me think}\nC --&gt;|One| D[Laptop]\nC --&gt;|Two| E[iPhone]\nC --&gt;|Three| F[fa:fa-car Car]</code></pre> <pre><code>stateDiagram-v2\n[*] --&gt; Still\nStill --&gt; [*]\nStill --&gt; Moving\nMoving --&gt; Still\nMoving --&gt; Crash\nCrash --&gt; [*]</code></pre> <p>Here's a simple footnote,<sup>1</sup> and here's a longer one.<sup>2</sup></p> <p>You can also use inline footnotes. ^[notice that the carat goes outside of the brackets on this one.]</p> <p>Info</p> <p>You can use + to have it default open. More valid types are note, abstract, summary, tldr, info, todo, tip, hint, important, success, check, done, question, help, faq, warning, caution, attention, failure, fail, missing, danger, error, bug, example, quote, cite</p> <p>Resized inline image:</p> <p></p> <p>Numbered Lists</p> <ol> <li>First item</li> <li>Second item</li> <li>Third item</li> </ol> <p>Dashed Lists</p> <ul> <li>First item</li> <li>Second item</li> <li>Third item</li> </ul> <p>Checkboxes</p> <ul> <li> Write the press release</li> <li> Update the website</li> <li> Contact the media</li> </ul> <p><code>code sample here, code block below</code></p> <pre><code>{\n  \"firstName\": \"John\",\n  \"lastName\": \"Smith\",\n  \"age\": 25\n}\n</code></pre> <p>Link Google</p> <p>Network link Server Link</p> Syntax Description Header Title Paragraph Text <p>More Formatting: Format your notes - Obsidian Help</p> <p>Valid languages in Codeblocks (that I may care about): Prism (prismjs.com)</p> <ul> <li>Markup\u00a0-\u00a0<code>markup</code>,\u00a0<code>html</code>,\u00a0<code>xml</code>,\u00a0<code>svg</code>,\u00a0<code>mathml</code>,\u00a0<code>ssml</code>,\u00a0<code>atom</code>,\u00a0<code>rss</code></li> <li>CSS\u00a0-\u00a0<code>css</code></li> <li>C-like\u00a0-\u00a0<code>clike</code></li> <li>JavaScript\u00a0-\u00a0<code>javascript</code>,\u00a0<code>js</code></li> <li>ABAP\u00a0-\u00a0<code>abap</code></li> <li>ABNF\u00a0-\u00a0<code>abnf</code></li> <li>ActionScript\u00a0-\u00a0<code>actionscript</code></li> <li>Ada\u00a0-\u00a0<code>ada</code></li> <li>Agda\u00a0-\u00a0<code>agda</code></li> <li>AL\u00a0-\u00a0<code>al</code></li> <li>ANTLR4\u00a0-\u00a0<code>antlr4</code>,\u00a0<code>g4</code></li> <li>Apache Configuration\u00a0-\u00a0<code>apacheconf</code></li> <li>Apex\u00a0-\u00a0<code>apex</code></li> <li>APL\u00a0-\u00a0<code>apl</code></li> <li>AppleScript\u00a0-\u00a0<code>applescript</code></li> <li>AQL\u00a0-\u00a0<code>aql</code></li> <li>Arduino\u00a0-\u00a0<code>arduino</code>,\u00a0<code>ino</code></li> <li>ARFF\u00a0-\u00a0<code>arff</code></li> <li>ARM Assembly\u00a0-\u00a0<code>armasm</code>,\u00a0<code>arm-asm</code></li> <li>Arturo\u00a0-\u00a0<code>arturo</code>,\u00a0<code>art</code></li> <li>AsciiDoc\u00a0-\u00a0<code>asciidoc</code>,\u00a0<code>adoc</code></li> <li>ASP.NET (C#)\u00a0-\u00a0<code>aspnet</code></li> <li>6502 Assembly\u00a0-\u00a0<code>asm6502</code></li> <li>Atmel AVR Assembly\u00a0-\u00a0<code>asmatmel</code></li> <li>AutoHotkey\u00a0-\u00a0<code>autohotkey</code></li> <li>AutoIt\u00a0-\u00a0<code>autoit</code></li> <li>AviSynth\u00a0-\u00a0<code>avisynth</code>,\u00a0<code>avs</code></li> <li>Avro IDL\u00a0-\u00a0<code>avro-idl</code>,\u00a0<code>avdl</code></li> <li>AWK\u00a0-\u00a0<code>awk</code>,\u00a0<code>gawk</code></li> <li>Bash\u00a0-\u00a0<code>bash</code>,\u00a0<code>shell</code></li> <li>BASIC\u00a0-\u00a0<code>basic</code></li> <li>Batch\u00a0-\u00a0<code>batch</code></li> <li>BBcode\u00a0-\u00a0<code>bbcode</code>,\u00a0<code>shortcode</code></li> <li>Bicep\u00a0-\u00a0<code>bicep</code></li> <li>Birb\u00a0-\u00a0<code>birb</code></li> <li>Bison\u00a0-\u00a0<code>bison</code></li> <li>BNF\u00a0-\u00a0<code>bnf</code>,\u00a0<code>rbnf</code></li> <li>Brainfuck\u00a0-\u00a0<code>brainfuck</code></li> <li>BrightScript\u00a0-\u00a0<code>brightscript</code></li> <li>Bro\u00a0-\u00a0<code>bro</code></li> <li>BSL (1C:Enterprise)\u00a0-\u00a0<code>bsl</code>,\u00a0<code>oscript</code></li> <li>C\u00a0-\u00a0<code>c</code></li> <li>C#\u00a0-\u00a0<code>csharp</code>,\u00a0<code>cs</code>,\u00a0<code>dotnet</code></li> <li>C++\u00a0-\u00a0<code>cpp</code></li> <li>CFScript\u00a0-\u00a0<code>cfscript</code>,\u00a0<code>cfc</code></li> <li>ChaiScript\u00a0-\u00a0<code>chaiscript</code></li> <li>CIL\u00a0-\u00a0<code>cil</code></li> <li>Clojure\u00a0-\u00a0<code>clojure</code></li> <li>CMake\u00a0-\u00a0<code>cmake</code></li> <li>COBOL\u00a0-\u00a0<code>cobol</code></li> <li>CoffeeScript\u00a0-\u00a0<code>coffeescript</code>,\u00a0<code>coffee</code></li> <li>Concurnas\u00a0-\u00a0<code>concurnas</code>,\u00a0<code>conc</code></li> <li>Content-Security-Policy\u00a0-\u00a0<code>csp</code></li> <li>Cooklang\u00a0-\u00a0<code>cooklang</code></li> <li>Coq\u00a0-\u00a0<code>coq</code></li> <li>Crystal\u00a0-\u00a0<code>crystal</code></li> <li>CSS Extras\u00a0-\u00a0<code>css-extras</code></li> <li>CSV\u00a0-\u00a0<code>csv</code></li> <li>CUE\u00a0-\u00a0<code>cue</code></li> <li>Cypher\u00a0-\u00a0<code>cypher</code></li> <li>D\u00a0-\u00a0<code>d</code></li> <li>Dart\u00a0-\u00a0<code>dart</code></li> <li>DataWeave\u00a0-\u00a0<code>dataweave</code></li> <li>DAX\u00a0-\u00a0<code>dax</code></li> <li>Dhall\u00a0-\u00a0<code>dhall</code></li> <li>Diff\u00a0-\u00a0<code>diff</code></li> <li>Django/Jinja2\u00a0-\u00a0<code>django</code>,\u00a0<code>jinja2</code></li> <li>DNS zone file\u00a0-\u00a0<code>dns-zone-file</code>,\u00a0<code>dns-zone</code></li> <li>Docker\u00a0-\u00a0<code>docker</code>,\u00a0<code>dockerfile</code></li> <li>DOT (Graphviz)\u00a0-\u00a0<code>dot</code>,\u00a0<code>gv</code></li> <li>EBNF\u00a0-\u00a0<code>ebnf</code></li> <li>EditorConfig\u00a0-\u00a0<code>editorconfig</code></li> <li>Eiffel\u00a0-\u00a0<code>eiffel</code></li> <li>EJS\u00a0-\u00a0<code>ejs</code>,\u00a0<code>eta</code></li> <li>Elixir\u00a0-\u00a0<code>elixir</code></li> <li>Elm\u00a0-\u00a0<code>elm</code></li> <li>Embedded Lua templating\u00a0-\u00a0<code>etlua</code></li> <li>ERB\u00a0-\u00a0<code>erb</code></li> <li>Erlang\u00a0-\u00a0<code>erlang</code></li> <li>Excel Formula\u00a0-\u00a0<code>excel-formula</code>,\u00a0<code>xlsx</code>,\u00a0<code>xls</code></li> <li>F#\u00a0-\u00a0<code>fsharp</code></li> <li>Factor\u00a0-\u00a0<code>factor</code></li> <li>False\u00a0-\u00a0<code>false</code></li> <li>Firestore security rules\u00a0-\u00a0<code>firestore-security-rules</code></li> <li>Flow\u00a0-\u00a0<code>flow</code></li> <li>Fortran\u00a0-\u00a0<code>fortran</code></li> <li>FreeMarker Template Language\u00a0-\u00a0<code>ftl</code></li> <li>GameMaker Language\u00a0-\u00a0<code>gml</code>,\u00a0<code>gamemakerlanguage</code></li> <li>GAP (CAS)\u00a0-\u00a0<code>gap</code></li> <li>G-code\u00a0-\u00a0<code>gcode</code></li> <li>GDScript\u00a0-\u00a0<code>gdscript</code></li> <li>GEDCOM\u00a0-\u00a0<code>gedcom</code></li> <li>gettext\u00a0-\u00a0<code>gettext</code>,\u00a0<code>po</code></li> <li>Gherkin\u00a0-\u00a0<code>gherkin</code></li> <li>Git\u00a0-\u00a0<code>git</code></li> <li>GLSL\u00a0-\u00a0<code>glsl</code></li> <li>GN\u00a0-\u00a0<code>gn</code>,\u00a0<code>gni</code></li> <li>GNU Linker Script\u00a0-\u00a0<code>linker-script</code>,\u00a0<code>ld</code></li> <li>Go\u00a0-\u00a0<code>go</code></li> <li>Go module\u00a0-\u00a0<code>go-module</code>,\u00a0<code>go-mod</code></li> <li>Gradle\u00a0-\u00a0<code>gradle</code></li> <li>GraphQL\u00a0-\u00a0<code>graphql</code></li> <li>Groovy\u00a0-\u00a0<code>groovy</code></li> <li>Haml\u00a0-\u00a0<code>haml</code></li> <li>Handlebars\u00a0-\u00a0<code>handlebars</code>,\u00a0<code>hbs</code>,\u00a0<code>mustache</code></li> <li>Haskell\u00a0-\u00a0<code>haskell</code>,\u00a0<code>hs</code></li> <li>Haxe\u00a0-\u00a0<code>haxe</code></li> <li>HCL\u00a0-\u00a0<code>hcl</code></li> <li>HLSL\u00a0-\u00a0<code>hlsl</code></li> <li>Hoon\u00a0-\u00a0<code>hoon</code></li> <li>HTTP\u00a0-\u00a0<code>http</code></li> <li>HTTP Public-Key-Pins\u00a0-\u00a0<code>hpkp</code></li> <li>HTTP Strict-Transport-Security\u00a0-\u00a0<code>hsts</code></li> <li>IchigoJam\u00a0-\u00a0<code>ichigojam</code></li> <li>Icon\u00a0-\u00a0<code>icon</code></li> <li>ICU Message Format\u00a0-\u00a0<code>icu-message-format</code></li> <li>Idris\u00a0-\u00a0<code>idris</code>,\u00a0<code>idr</code></li> <li>.ignore\u00a0-\u00a0<code>ignore</code>,\u00a0<code>gitignore</code>,\u00a0<code>hgignore</code>,\u00a0<code>npmignore</code></li> <li>Inform 7\u00a0-\u00a0<code>inform7</code></li> <li>Ini\u00a0-\u00a0<code>ini</code></li> <li>Io\u00a0-\u00a0<code>io</code></li> <li>J\u00a0-\u00a0<code>j</code></li> <li>Java\u00a0-\u00a0<code>java</code></li> <li>JavaDoc\u00a0-\u00a0<code>javadoc</code></li> <li>JavaDoc-like\u00a0-\u00a0<code>javadoclike</code></li> <li>Java stack trace\u00a0-\u00a0<code>javastacktrace</code></li> <li>Jexl\u00a0-\u00a0<code>jexl</code></li> <li>Jolie\u00a0-\u00a0<code>jolie</code></li> <li>JQ\u00a0-\u00a0<code>jq</code></li> <li>JSDoc\u00a0-\u00a0<code>jsdoc</code></li> <li>JS Extras\u00a0-\u00a0<code>js-extras</code></li> <li>JSON\u00a0-\u00a0<code>json</code>,\u00a0<code>webmanifest</code></li> <li>JSON5\u00a0-\u00a0<code>json5</code></li> <li>JSONP\u00a0-\u00a0<code>jsonp</code></li> <li>JS stack trace\u00a0-\u00a0<code>jsstacktrace</code></li> <li>JS Templates\u00a0-\u00a0<code>js-templates</code></li> <li>Julia\u00a0-\u00a0<code>julia</code></li> <li>Keepalived Configure\u00a0-\u00a0<code>keepalived</code></li> <li>Keyman\u00a0-\u00a0<code>keyman</code></li> <li>Kotlin\u00a0-\u00a0<code>kotlin</code>,\u00a0<code>kt</code>,\u00a0<code>kts</code></li> <li>KuMir (\u041a\u0443\u041c\u0438\u0440)\u00a0-\u00a0<code>kumir</code>,\u00a0<code>kum</code></li> <li>Kusto\u00a0-\u00a0<code>kusto</code></li> <li>LaTeX\u00a0-\u00a0<code>latex</code>,\u00a0<code>tex</code>,\u00a0<code>context</code></li> <li>Latte\u00a0-\u00a0<code>latte</code></li> <li>Less\u00a0-\u00a0<code>less</code></li> <li>LilyPond\u00a0-\u00a0<code>lilypond</code>,\u00a0<code>ly</code></li> <li>Liquid\u00a0-\u00a0<code>liquid</code></li> <li>Lisp\u00a0-\u00a0<code>lisp</code>,\u00a0<code>emacs</code>,\u00a0<code>elisp</code>,\u00a0<code>emacs-lisp</code></li> <li>LiveScript\u00a0-\u00a0<code>livescript</code></li> <li>LLVM IR\u00a0-\u00a0<code>llvm</code></li> <li>Log file\u00a0-\u00a0<code>log</code></li> <li>LOLCODE\u00a0-\u00a0<code>lolcode</code></li> <li>Lua\u00a0-\u00a0<code>lua</code></li> <li>Magma (CAS)\u00a0-\u00a0<code>magma</code></li> <li>Makefile\u00a0-\u00a0<code>makefile</code></li> <li>Markdown\u00a0-\u00a0<code>markdown</code>,\u00a0<code>md</code></li> <li>Markup templating\u00a0-\u00a0<code>markup-templating</code></li> <li>Mata\u00a0-\u00a0<code>mata</code></li> <li>MATLAB\u00a0-\u00a0<code>matlab</code></li> <li>MAXScript\u00a0-\u00a0<code>maxscript</code></li> <li>MEL\u00a0-\u00a0<code>mel</code></li> <li>Mermaid\u00a0-\u00a0<code>mermaid</code></li> <li>Mizar\u00a0-\u00a0<code>mizar</code></li> <li>MongoDB\u00a0-\u00a0<code>mongodb</code></li> <li>Monkey\u00a0-\u00a0<code>monkey</code></li> <li>MoonScript\u00a0-\u00a0<code>moonscript</code>,\u00a0<code>moon</code></li> <li>N1QL\u00a0-\u00a0<code>n1ql</code></li> <li>N4JS\u00a0-\u00a0<code>n4js</code>,\u00a0<code>n4jsd</code></li> <li>Nand To Tetris HDL\u00a0-\u00a0<code>nand2tetris-hdl</code></li> <li>Naninovel Script\u00a0-\u00a0<code>naniscript</code>,\u00a0<code>nani</code></li> <li>NASM\u00a0-\u00a0<code>nasm</code></li> <li>NEON\u00a0-\u00a0<code>neon</code></li> <li>Nevod\u00a0-\u00a0<code>nevod</code></li> <li>nginx\u00a0-\u00a0<code>nginx</code></li> <li>Nim\u00a0-\u00a0<code>nim</code></li> <li>Nix\u00a0-\u00a0<code>nix</code></li> <li>NSIS\u00a0-\u00a0<code>nsis</code></li> <li>Objective-C\u00a0-\u00a0<code>objectivec</code>,\u00a0<code>objc</code></li> <li>OCaml\u00a0-\u00a0<code>ocaml</code></li> <li>Odin\u00a0-\u00a0<code>odin</code></li> <li>OpenCL\u00a0-\u00a0<code>opencl</code></li> <li>OpenQasm\u00a0-\u00a0<code>openqasm</code>,\u00a0<code>qasm</code></li> <li>Oz\u00a0-\u00a0<code>oz</code></li> <li>PARI/GP\u00a0-\u00a0<code>parigp</code></li> <li>Parser\u00a0-\u00a0<code>parser</code></li> <li>Pascal\u00a0-\u00a0<code>pascal</code>,\u00a0<code>objectpascal</code></li> <li>Pascaligo\u00a0-\u00a0<code>pascaligo</code></li> <li>PATROL Scripting Language\u00a0-\u00a0<code>psl</code></li> <li>PC-Axis\u00a0-\u00a0<code>pcaxis</code>,\u00a0<code>px</code></li> <li>PeopleCode\u00a0-\u00a0<code>peoplecode</code>,\u00a0<code>pcode</code></li> <li>Perl\u00a0-\u00a0<code>perl</code></li> <li>PHP\u00a0-\u00a0<code>php</code></li> <li>PHPDoc\u00a0-\u00a0<code>phpdoc</code></li> <li>PHP Extras\u00a0-\u00a0<code>php-extras</code></li> <li>PlantUML\u00a0-\u00a0<code>plant-uml</code>,\u00a0<code>plantuml</code></li> <li>PL/SQL\u00a0-\u00a0<code>plsql</code></li> <li>PowerQuery\u00a0-\u00a0<code>powerquery</code>,\u00a0<code>pq</code>,\u00a0<code>mscript</code></li> <li>PowerShell\u00a0-\u00a0<code>powershell</code></li> <li>Processing\u00a0-\u00a0<code>processing</code></li> <li>Prolog\u00a0-\u00a0<code>prolog</code></li> <li>PromQL\u00a0-\u00a0<code>promql</code></li> <li>.properties\u00a0-\u00a0<code>properties</code></li> <li>Protocol Buffers\u00a0-\u00a0<code>protobuf</code></li> <li>Pug\u00a0-\u00a0<code>pug</code></li> <li>Puppet\u00a0-\u00a0<code>puppet</code></li> <li>Pure\u00a0-\u00a0<code>pure</code></li> <li>PureBasic\u00a0-\u00a0<code>purebasic</code>,\u00a0<code>pbfasm</code></li> <li>PureScript\u00a0-\u00a0<code>purescript</code>,\u00a0<code>purs</code></li> <li>Python\u00a0-\u00a0<code>python</code>,\u00a0<code>py</code></li> <li>Q#\u00a0-\u00a0<code>qsharp</code>,\u00a0<code>qs</code></li> <li>Q (kdb+ database)\u00a0-\u00a0<code>q</code></li> <li>QML\u00a0-\u00a0<code>qml</code></li> <li>Qore\u00a0-\u00a0<code>qore</code></li> <li>R\u00a0-\u00a0<code>r</code></li> <li>Racket\u00a0-\u00a0<code>racket</code>,\u00a0<code>rkt</code></li> <li>Razor C#\u00a0-\u00a0<code>cshtml</code>,\u00a0<code>razor</code></li> <li>React JSX\u00a0-\u00a0<code>jsx</code></li> <li>React TSX\u00a0-\u00a0<code>tsx</code></li> <li>Reason\u00a0-\u00a0<code>reason</code></li> <li>Regex\u00a0-\u00a0<code>regex</code></li> <li>Rego\u00a0-\u00a0<code>rego</code></li> <li>Ren'py\u00a0-\u00a0<code>renpy</code>,\u00a0<code>rpy</code></li> <li>ReScript\u00a0-\u00a0<code>rescript</code>,\u00a0<code>res</code></li> <li>reST (reStructuredText)\u00a0-\u00a0<code>rest</code></li> <li>Rip\u00a0-\u00a0<code>rip</code></li> <li>Roboconf\u00a0-\u00a0<code>roboconf</code></li> <li>Robot Framework\u00a0-\u00a0<code>robotframework</code>,\u00a0<code>robot</code></li> <li>Ruby\u00a0-\u00a0<code>ruby</code>,\u00a0<code>rb</code></li> <li>Rust\u00a0-\u00a0<code>rust</code></li> <li>SAS\u00a0-\u00a0<code>sas</code></li> <li>Sass (Sass)\u00a0-\u00a0<code>sass</code></li> <li>Sass (Scss)\u00a0-\u00a0<code>scss</code></li> <li>Scala\u00a0-\u00a0<code>scala</code></li> <li>Scheme\u00a0-\u00a0<code>scheme</code></li> <li>Shell session\u00a0-\u00a0<code>shell-session</code>,\u00a0<code>sh-session</code>,\u00a0<code>shellsession</code></li> <li>Smali\u00a0-\u00a0<code>smali</code></li> <li>Smalltalk\u00a0-\u00a0<code>smalltalk</code></li> <li>Smarty\u00a0-\u00a0<code>smarty</code></li> <li>SML\u00a0-\u00a0<code>sml</code>,\u00a0<code>smlnj</code></li> <li>Solidity (Ethereum)\u00a0-\u00a0<code>solidity</code>,\u00a0<code>sol</code></li> <li>Solution file\u00a0-\u00a0<code>solution-file</code>,\u00a0<code>sln</code></li> <li>Soy (Closure Template)\u00a0-\u00a0<code>soy</code></li> <li>SPARQL\u00a0-\u00a0<code>sparql</code>,\u00a0<code>rq</code></li> <li>Splunk SPL\u00a0-\u00a0<code>splunk-spl</code></li> <li>SQF: Status Quo Function (Arma 3)\u00a0-\u00a0<code>sqf</code></li> <li>SQL\u00a0-\u00a0<code>sql</code></li> <li>Squirrel\u00a0-\u00a0<code>squirrel</code></li> <li>Stan\u00a0-\u00a0<code>stan</code></li> <li>Stata Ado\u00a0-\u00a0<code>stata</code></li> <li>Structured Text (IEC 61131-3)\u00a0-\u00a0<code>iecst</code></li> <li>Stylus\u00a0-\u00a0<code>stylus</code></li> <li>SuperCollider\u00a0-\u00a0<code>supercollider</code>,\u00a0<code>sclang</code></li> <li>Swift\u00a0-\u00a0<code>swift</code></li> <li>Systemd configuration file\u00a0-\u00a0<code>systemd</code></li> <li>T4 templating\u00a0-\u00a0<code>t4-templating</code></li> <li>T4 Text Templates (C#)\u00a0-\u00a0<code>t4-cs</code>,\u00a0<code>t4</code></li> <li>T4 Text Templates (VB)\u00a0-\u00a0<code>t4-vb</code></li> <li>TAP\u00a0-\u00a0<code>tap</code></li> <li>Tcl\u00a0-\u00a0<code>tcl</code></li> <li>Template Toolkit 2\u00a0-\u00a0<code>tt2</code></li> <li>Textile\u00a0-\u00a0<code>textile</code></li> <li>TOML\u00a0-\u00a0<code>toml</code></li> <li>Tremor\u00a0-\u00a0<code>tremor</code>,\u00a0<code>trickle</code>,\u00a0<code>troy</code></li> <li>Turtle\u00a0-\u00a0<code>turtle</code>,\u00a0<code>trig</code></li> <li>Twig\u00a0-\u00a0<code>twig</code></li> <li>TypeScript\u00a0-\u00a0<code>typescript</code>,\u00a0<code>ts</code></li> <li>TypoScript\u00a0-\u00a0<code>typoscript</code>,\u00a0<code>tsconfig</code></li> <li>UnrealScript\u00a0-\u00a0<code>unrealscript</code>,\u00a0<code>uscript</code>,\u00a0<code>uc</code></li> <li>UO Razor Script\u00a0-\u00a0<code>uorazor</code></li> <li>URI\u00a0-\u00a0<code>uri</code>,\u00a0<code>url</code></li> <li>V\u00a0-\u00a0<code>v</code></li> <li>Vala\u00a0-\u00a0<code>vala</code></li> <li>VB.Net\u00a0-\u00a0<code>vbnet</code></li> <li>Velocity\u00a0-\u00a0<code>velocity</code></li> <li>Verilog\u00a0-\u00a0<code>verilog</code></li> <li>VHDL\u00a0-\u00a0<code>vhdl</code></li> <li>vim\u00a0-\u00a0<code>vim</code></li> <li>Visual Basic\u00a0-\u00a0<code>visual-basic</code>,\u00a0<code>vb</code>,\u00a0<code>vba</code></li> <li>WarpScript\u00a0-\u00a0<code>warpscript</code></li> <li>WebAssembly\u00a0-\u00a0<code>wasm</code></li> <li>Web IDL\u00a0-\u00a0<code>web-idl</code>,\u00a0<code>webidl</code></li> <li>WGSL\u00a0-\u00a0<code>wgsl</code></li> <li>Wiki markup\u00a0-\u00a0<code>wiki</code></li> <li>Wolfram language\u00a0-\u00a0<code>wolfram</code>,\u00a0<code>mathematica</code>,\u00a0<code>nb</code>,\u00a0<code>wl</code></li> <li>Wren\u00a0-\u00a0<code>wren</code></li> <li>Xeora\u00a0-\u00a0<code>xeora</code>,\u00a0<code>xeoracube</code></li> <li>XML doc (.net)\u00a0-\u00a0<code>xml-doc</code></li> <li>Xojo (REALbasic)\u00a0-\u00a0<code>xojo</code></li> <li>XQuery\u00a0-\u00a0<code>xquery</code></li> <li>YAML\u00a0-\u00a0<code>yaml</code>,\u00a0<code>yml</code></li> <li>YANG\u00a0-\u00a0<code>yang</code></li> <li>Zig\u00a0-\u00a0<code>zig</code></li> </ul> <ol> <li> <p>meaningful!\u00a0\u21a9</p> </li> <li> <p>Here's one with multiple paragraphs and code.</p> <p>Indent paragraphs to include them in the footnote.</p> <p><code>{ my code }</code></p> <p>Add as many paragraphs as you like.\u00a0\u21a9</p> </li> </ol>"},{"location":"Markdown/Conversion/","title":"Conversion","text":""},{"location":"Markdown/Conversion/#Convert%20Word%20to%20Markdown","title":"Convert Word to Markdown","text":"<p>Navigate to the folder where the Word file is, and run this after changing the names:</p> <p><code>pandoc --extract-media=./_assets -s convert.docx  --wrap=none -t markdown -o convert.md</code></p> <p>After that, you can Find/Replace a regex of <code>\\{(.+)\\}</code> to remove the dimensions for images.</p> <p>Finally run a Find/Replace for <code>./_assets/media/</code> to <code>./_assets/</code> to align the images (and move the images!) so they're in the same structure as current notes.</p>"},{"location":"Markdown/Conversion/#Convert%20Markdown%20to","title":"Convert Markdown to...","text":"<p>Make sure you have the following installed: - Pandoc - Node.js - Mermaid Filter (for diagrams)</p> <p>You'll need to tweak the Mermaid Filter above to get it to look better. Go to <code>%APPDATA%\\nvm\\v16.13.2\\node_modules\\mermaid-filter\\index.js</code>, and update the line ~36 <code>MERMAID_FILTER_SCALE</code> to <code>2</code>. To make things look a bit nicer, change <code>MERMAID_FILTER_THEME</code> to <code>neutral</code>, and <code>MERMAID_FILTER_BACKGROUND</code> to <code>transparent</code>. Couldn't get SVG to work in DOCx.</p>"},{"location":"Markdown/Conversion/#Word","title":"Word","text":"<p>This will create a Word document with Mermaid diagrams loaded as PNG (see Mermaid Diagrams above to make sure that words/looks good).</p> <p>Failure</p> <p>Pandoc won't output good looking callouts with native Obsidian Notes syntax.</p> <p>Success</p> <p>Tables look good, code blocks are useable, and mermaid is fine with the filter.</p> <p>Example</p> <p>Can shift all headers with <code>--shift-heading-level-by=-1</code>.</p> <pre><code># Invokes standard Windows dialog box\nAdd-Type -AssemblyName System.Windows.Forms\n\n# Sets paths for directories\n$StartingDir = \"$env:USERPROFILE\"\n$DesktopPath = [Environment]::GetFolderPath(\"Desktop\")\n\n# Creates the object\n$FileBrowser = New-Object System.Windows.Forms.OpenFileDialog -Property @{ \n    InitialDirectory = $StartingDir\n    Filter = 'Markdown (*.md)|*.md|Text (*.txt)|*.txt'\n}\n\n# Opens the dialog box\n$null = $FileBrowser.ShowDialog()\n\n# variable where all things are stored FYI: $FileBrowser\n\n# Splits the filename and extension to just the filename and stored as $Prefix variable. So Test.md becomes Test.\n$Prefix=$FileBrowser.SafeFileName.Split(\".\")[0]\n\n# Sets execution directory for Pandoc, so it can correctly get any relative path images and the like.\n$FileLocation = Split-Path -Path $FileBrowser.FileName\nSet-Location -Path $FileLocation\n\n# Sets output directory for where the file will be saved.\n$OutputFile = \"$DesktopPath\\\" + $Prefix + \".docx\"\n# Creates the file\npandoc --to docx --from markdown+hard_line_breaks $FileBrowser.Filename --reference-doc=\"$env:USERPROFILE\\Template.docx\" --output $OutputFile --filter mermaid-filter.cmd\n\n# Remove a file that is useless\nRemove-Item mermaid-filter.err\n\n# Opens the file\n&amp; $OutputFile\n</code></pre> <p>Can also add the above into something like this to run through them all in a specific folder, to create one output file per input file. <pre><code>Get-ChildItem -filter *.md | ForEach-Object {pandoc --to docx --from markdown+hard_line_breaks $_.Name --reference-doc=\"$env:USERPROFILE\\Template.docx\" --output ($_.Basename + '.docx') --filter mermaid-filter.cmd}\n\n# Remove a file that is useless\nRemove-Item mermaid-filter.err\n</code></pre></p> <p>Combine multiple files (like meeting minutes) into one output file. Make sure if running the below there is a space at the end of each markdown file that is combined. Otherwise headers may not register correctly when converted.</p> <pre><code>Add-Type -AssemblyName System.Windows.Forms\n$FolderBrowser = New-Object System.Windows.Forms.FolderBrowserDialog -Property @{\n    RootFolder = 'MyDocuments'\n    ShowNewFolderButton = $false\n}\n$null = $FolderBrowser.ShowDialog()\n\nSet-Location -Path $FolderBrowser.SelectedPath\n\n# Sets paths for directories\n$StartingDir = \"$env:USERPROFILE\"\n$DesktopPath = [Environment]::GetFolderPath(\"Desktop\")\n\n# Outputs File\n$OutputFile = \"$DesktopPath\\Minutes.docx\"\n\n# Creats combined file and exports to Word\nSet-Content -Path .\\combined.txt (Get-Content WW*.md) | pandoc --to docx --from markdown+hard_line_breaks combined.txt --reference-doc=\"$env:USERPROFILE\\Template.docx\" --output $OutputFile --filter mermaid-filter.cmd\n\n# Removes files\nRemove-Item mermaid-filter.err\nRemove-Item combined.txt\n\n# Opens the file\n&amp; $OutputFile\n</code></pre>"},{"location":"Markdown/Conversion/#PDF","title":"PDF","text":"<p>Success</p> <p>Pandoc won't output good looking tables, and callouts with native Obsidian Notes syntax doesn't work. However mermaid graphs look okay, and table of contents works. Too many things broken, better to export to Word, then PDF from there. Can create bookmarks based on Headings in the Options menu.</p>"},{"location":"Markdown/Example%20Callouts/","title":"Example Callouts","text":"<p>Abstract</p> <p>Bug</p> <p>Danger</p> <p>Example</p> <p>Failure</p> <p>Info</p> <p>Note</p> <p>Question</p> <p>Quote</p> <p>Success</p> <p>Tip</p> <p>Warning</p>"},{"location":"Markdown/Example%20Diagrams/","title":"Example Diagrams","text":"<p>Some other more detailed examples here.</p>"},{"location":"Markdown/Example%20Diagrams/#Flow%20Chart","title":"Flow Chart","text":"<pre><code>flowchart LR\nA[Hard edge] --&gt;|Link text| B(Round edge)\nB --&gt; C{Decision}\nC --&gt;|One| D[Result one]\nC --&gt;|Two| E[Result two]</code></pre>"},{"location":"Markdown/Example%20Diagrams/#Sequence%20Diagram","title":"Sequence Diagram","text":"<pre><code>sequenceDiagram\nAlice -&gt;&gt; Bob: Hello Bob, how are you?\nBob--&gt;&gt;John: How about you John?\nBob--x Alice: I am good thanks!\nBob-x John: I am good thanks!\nNote right of John: Bob thinks a long&lt;br/&gt;long time, so long&lt;br/&gt;that the text does&lt;br/&gt;not fit on a row.\n\nBob--&gt;Alice: Checking with John...\nAlice-&gt;John: Yes... John, how are you?</code></pre>"},{"location":"Markdown/Example%20Diagrams/#Class%20Diagram","title":"Class Diagram","text":"<pre><code>classDiagram\nAnimal &lt;|-- Duck\nAnimal &lt;|-- Fish\nAnimal &lt;|-- Zebra\nAnimal : +int age\nAnimal : +String gender\nAnimal: +isMammal()\nAnimal: +mate()\nclass Duck{\n    +String beakColor\n    +swim()\n    +quack()\n}\nclass Fish{\n    -int sizeInFeet\n    -canEat()\n}\nclass Zebra{\n    +bool is_wild\n    +run()\n}</code></pre>"},{"location":"Markdown/Example%20Diagrams/#State%20Diagram","title":"State Diagram","text":"<pre><code>stateDiagram-v2\n[*] --&gt; Still\nStill --&gt; [*]\n\nStill --&gt; Moving\nMoving --&gt; Still\nMoving --&gt; Crash\nCrash --&gt; [*]</code></pre>"},{"location":"Markdown/Example%20Diagrams/#Entity%20Relationship%20Diagram","title":"Entity Relationship Diagram","text":"<pre><code>erDiagram\nCAR ||--o{ NAMED-DRIVER : allows\nCAR {\n    string allowedDriver FK \"The license of the allowed driver\"\n    string registrationNumber\n    string make\n    string model\n}\nPERSON ||--o{ NAMED-DRIVER : is\nPERSON {\n    string driversLicense PK \"The license #\"\n    string firstName\n    string lastName\n    int age\n}</code></pre>"},{"location":"Markdown/Example%20Diagrams/#User%20Journey","title":"User Journey","text":"<pre><code>journey\ntitle My working day\nsection Go to work\n  Make tea: 5: Me\n  Go upstairs: 3: Me\n  Do work: 1: Me, Cat\nsection Go home\n  Go downstairs: 5: Me\n  Sit down: 5: Me</code></pre>"},{"location":"Markdown/Example%20Diagrams/#Gantt","title":"Gantt","text":"<pre><code>gantt\ndateFormat  YYYY-MM-DD\ntitle       Adding GANTT diagram functionality to mermaid\nexcludes    weekends\n%% (`excludes` accepts specific dates in YYYY-MM-DD format, days of the week (\"sunday\") or \"weekends\", but not the word \"weekdays\".)\n\nsection A section\nCompleted task            :done,    des1, 2014-01-06,2014-01-08\nActive task               :active,  des2, 2014-01-09, 3d\nFuture task               :         des3, after des2, 5d\nFuture task2              :         des4, after des3, 5d\n\nsection Critical tasks\nCompleted task in the critical line :crit, done, 2014-01-06,24h\nImplement parser and jison          :crit, done, after des1, 2d\nCreate tests for parser             :crit, active, 3d\nFuture task in critical line        :crit, 5d\nCreate tests for renderer           :2d\nAdd to mermaid                      :1d\nFunctionality added                 :milestone, 2014-01-25, 0d\n\nsection Documentation\nDescribe gantt syntax               :active, a1, after des1, 3d\nAdd gantt diagram to demo page      :after a1  , 20h\nAdd another diagram to demo page    :doc1, after a1  , 48h\n\nsection Last section\nDescribe gantt syntax               :after doc1, 3d\nAdd gantt diagram to demo page      :20h\nAdd another diagram to demo page    :48h****</code></pre>"},{"location":"Markdown/Example%20Diagrams/#Pie%20Chart","title":"Pie Chart","text":"<pre><code>pie title NETFLIX\n\"Time spent looking for movie\" : 90\n\"Time spent watching it\" : 10</code></pre>"},{"location":"Markdown/Example%20Diagrams/#Requirements%20Diagram","title":"Requirements Diagram","text":"<pre><code>requirementDiagram\n\nrequirement test_req {\nid: 1\ntext: the test text.\nrisk: high\nverifymethod: test\n}\n\nelement test_entity {\ntype: simulation\n}\n\ntest_entity - satisfies -&gt; test_req</code></pre>"},{"location":"Markdown/Example%20Diagrams/#Gitgraph%20Diagram","title":"Gitgraph Diagram","text":"<pre><code>gitGraph\ncommit\ncommit\nbranch develop\ncheckout develop\ncommit\ncommit\ncheckout main\nmerge develop\ncommit\ncommit</code></pre>"},{"location":"Markdown/Getting%20Started/","title":"Getting Started","text":"<p>The below has been taken from here, which is an excellent guide and has more details worth reading. There's also a 60-second guide for formatting.</p> <p>Example</p> <p>Want to skip all the below and dive right in? Check out this free web editor (nothing to install) that instantly renders what you do!</p>"},{"location":"Markdown/Getting%20Started/#What%20is%20Markdown","title":"What is Markdown?","text":"<p>Markdown is a lightweight markup language that you can use to add formatting elements to plaintext text documents. Simplifying it more, Markdown is a text file that uses certain characters in certain ways to create a \"pretty\" document.</p> <p>Using Markdown is different than using a\u00a0WYSIWYG\u00a0editor. In an application like Microsoft Word, you click buttons to format words and phrases, and the changes are visible immediately. Markdown isn\u2019t like that. When you create a Markdown-formatted file, you add Markdown syntax to the text to indicate which words and phrases should look different.</p> <p>For example, to denote a heading (H1), you add a number sign before it with a space (e.g.,\u00a0<code># Heading One</code>). Or to make a word bold, you add two asterisks before and after it (e.g.,\u00a0<code>this text will be **bold**</code>). It may take a while to get used to seeing Markdown syntax in your text, especially if you\u2019re accustomed to WYSIWYG applications.</p> <p></p> <p>You can add Markdown formatting elements to a plaintext file using a text editor application. Or you can use one of the many Markdown applications for macOS, Windows, Linux, iOS, and Android operating systems. There are also several web-based applications specifically designed for writing in Markdown.</p> <p>Depending on the application you use, you may not be able to preview the formatted document in real time. But that\u2019s okay.\u00a0According to Gruber, Markdown syntax is designed to be readable and unobtrusive, so the text in Markdown files can be read even if it isn\u2019t rendered.</p> <p>The overriding design goal for Markdown\u2019s formatting syntax is to make it as readable as possible. The idea is that a Markdown-formatted document should be publishable as-is, as plain text, without looking like it\u2019s been marked up with tags or formatting instructions.</p>"},{"location":"Markdown/Getting%20Started/#Why%20Use%20Markdown","title":"Why Use Markdown?","text":"<p>You might be wondering why people use Markdown instead of a WYSIWYG editor. Why write with Markdown when you can press buttons in an interface to format your text? As it turns out, there are several reasons why people use Markdown instead of WYSIWYG editors.</p> <ul> <li> <p>Markdown can be used for everything. People use it to create\u00a0websites,\u00a0documents,\u00a0notes,\u00a0books,\u00a0presentations,\u00a0email messages, and\u00a0technical documentation.</p> </li> <li> <p>Markdown is portable. Files containing Markdown-formatted text can be opened using virtually any application. If you decide you don\u2019t like the Markdown application you\u2019re currently using, you can import your Markdown files into another Markdown application. That\u2019s in stark contrast to word processing applications like Microsoft Word that lock your content into a proprietary file format.</p> </li> <li> <p>Markdown is platform independent. You can create Markdown-formatted text on any device running any operating system.</p> </li> <li> <p>Markdown is future proof. Even if the application you\u2019re using stops working at some point in the future, you\u2019ll still be able to read your Markdown-formatted text using a text editing application. This is an important consideration when it comes to books, university theses, and other milestone documents that need to be preserved indefinitely.</p> </li> <li> <p>Markdown is everywhere. Websites like\u00a0Reddit\u00a0and GitHub support Markdown, and lots of desktop and web-based applications support it.</p> </li> </ul>"},{"location":"Markdown/Getting%20Started/#Notes","title":"Notes","text":"<p>In nearly every way, Markdown is the ideal syntax for taking notes. Sadly,\u00a0Evernote\u00a0and\u00a0OneNote, two of the most popular note applications, don\u2019t currently support Markdown. The good news is that several other note applications\u00a0do\u00a0support Markdown:</p> <ul> <li>Obsidian\u00a0is a popular Markdown note-taking application loaded with features.</li> <li>Simplenote\u00a0is a free, barebones note-taking application available for every platform.</li> <li>Notable\u00a0is a note-taking application that runs on a variety of platforms.</li> <li>Bear\u00a0is an Evernote-like application available for Mac and iOS devices. It doesn\u2019t exclusively use Markdown by default, but you can enable Markdown compatibility mode.</li> <li>Joplin\u00a0is a note taking application that respects your privacy. It\u2019s available for every platform.</li> <li>Boostnote\u00a0bills itself as an \u201copen source note-taking app designed for programmers.\u201d</li> </ul> <p>If you can\u2019t part with Evernote, check out\u00a0Marxico, a subscription-based Markdown editor for Evernote, or use\u00a0Markdown Here\u00a0with the Evernote website.</p>"},{"location":"Markdown/Getting%20Started/#Syntax","title":"Syntax","text":"<p>Learn everything you need to know here. For Obsidian Notes specifics check out this link.</p> <p>Warning</p> <p>While Markdown is an official standard (defined by CommonMark), the implementation of some non-standard items vary depending on the application used. A good example is callout blocks, also known as admonitions or just callouts. Note the use of <code>:::</code> in the first link and <code>!!!</code> in the next and <code>&gt;</code> in the last. If needed one can use regular expressions to find/replace content. This only comes up if you try to use a markdown file in another application.</p>"},{"location":"Markdown/Publish%20to%20Website/","title":"Publish to Website","text":""},{"location":"Markdown/Publish%20to%20Website/#Prerequisites","title":"Prerequisites","text":"<ul> <li>Visual Studio Code</li> <li>GIT</li> <li>Python 3.10+<ul> <li>That will install the command <code>PIP</code>. Make sure you add Python to PATH.</li> </ul> </li> </ul> <p>You'll have to close any terminals you have open already for commands to <code>PYTHON</code> and <code>PIP</code> to show up.</p>"},{"location":"Markdown/Publish%20to%20Website/#Getting%20Started","title":"Getting Started","text":"<p>The process to publish from Markdown to a website is done via a tool called MKDocs. On top of that, we use this theme to customize the look and feel of the site. Learn more about it at their website.</p> <p>You'll also want to download this plugin to auto-convert callouts to the correct format (that way you don't have to run regex commands to replace them). </p> <p>To install all the above run these commands in PowerShell:</p> <pre><code>pip install mkdocs-material\npip install mkdocs-callouts\npip install mkdocs-glightbox\npip3 install mkdocs-git-revision-date-localized-plugin\npip install mkdocs-awesome-pages-plugin\n</code></pre> <p>and make sure the <code>mkdocs.yml</code> file has the below added to it.</p> <pre><code>...\nmarkdown_extensions:\n  - nl2br\n  - admonition\n  - pymdownx.details\n  - pymdownx.superfences\n\nplugins:\n\u00a0 - search\n\u00a0 - callouts\n\u00a0 - glightbox\n\u00a0 - git-revision-date-localized\n...\n</code></pre> <p>To enable table sorting and mathjax support, I also added some JavaScript files to <code>/docs/javascripts/</code>, labeled <code>mathjax.js</code> and <code>tablesort.js</code>. See the Reference section for the code. A <code>favicon.png</code> was added to <code>/docs/images/</code> and a matching <code>logo.svg</code> was added to the <code>/docs/</code> folder.</p>"},{"location":"Markdown/Publish%20to%20Website/#Commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code>\u00a0- Create a new project.</li> <li><code>mkdocs serve</code>\u00a0- Start the live-reloading docs server.</li> <li><code>mkdocs build</code>\u00a0- Build the documentation site.</li> <li><code>mkdocs -h</code>\u00a0- Print help message and exit.</li> </ul> <p>Tip</p> <p>no need to ever really build with GitHub actions, as it does it when you upload.</p>"},{"location":"Markdown/Publish%20to%20Website/#Folder%20Structure","title":"Folder Structure","text":"<pre><code>mkdocs.yml                                       # The configuration file.\n.github/\n    workflows/                               \n        ci.yml                                   # Auto-builds the site\n.gitignore                                       # File telling DevOps what to ignore.\n.git                                             # Hidden folder where changes are tracked.\ndocs/\n    index.md                                     # The documentation homepage.\n    [more files].md                              # All the other markdown files and folders.\n    staticwebapp.config.json                     # From static web app creation.\n    ...                                          # Other markdown pages, images and other files.\n    images/\n        favicon.png                              # Favicon matching logo.svg\n    javascripts/\n        mathjax.js                               # From: https://squidfunk.github.io/mkdocs-material/reference/mathjax/\n        tablesort.js                             # From: https://squidfunk.github.io/mkdocs-material/reference/data-tables/#sortable-tables\n    stylesheets/\n        extra.css                                # CSS used for custom theme colors\n</code></pre>"},{"location":"Markdown/Publish%20to%20Website/#GitHub%20Actions","title":"GitHub Actions","text":"<pre><code>name: ci \non:\n  push:\n    branches:\n      - master \n      - main\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-python@v2\n        with:\n          python-version: 3.x\n      - run: pip install mkdocs-material \n      - run: pip install mkdocs-callouts \n      - run: pip install mkdocs-glightbox \n      - run: mkdocs gh-deploy --force\n</code></pre>"},{"location":"Markdown/Publish%20to%20Website/#Azure%20Pipeline","title":"Azure Pipeline","text":"<p>Add the following into the <code>yml</code> file generated when creating a static web app</p> <pre><code>...\n  - script: pip install mkdocs-material\n    displayName: Install MkDocs Material Theme\n\n  - script: pip install mkdocs-callouts\n    displayName: Install MkDocs Callout Converter\n\n  - script: pip install mkdocs-glightbox\n    displayName: Install MkDocs Material GLightBox\n\n  - script: pip3 install mkdocs-git-revision-date-localized-plugin\n    displayName: Install MkDocs Page Last Updated\n\n  - script: pip install mkdocs\n    displayName: Install MkDocs\n\n  - script: mkdocs build\n    displayName: Build MkDocs\n...\n</code></pre>"},{"location":"Markdown/Publish%20to%20Website/#Azure%20AAD","title":"Azure AAD","text":"<p>Add or create a <code>staticwebapp.config.json</code> file, and add the following so only specified users can access the website</p> <pre><code>{\n    \"routes\": [\n        {\n            \"route\": \"/*\",\n            \"allowedRoles\": [\n                \"authenticated\"\n            ]\n        }\n    ],\n    \"responseOverrides\": {\n        \"401\": {\n            \"redirect\": \"/.auth/login/aad?post_login_redirect_uri=.referrer\",\n            \"statusCode\": 302\n        },\n        \"404\": {\n            \"rewrite\": \"/404.html\",\n            \"statusCode\": 404\n        }\n    },\n    \"auth\": {\n        \"identityProviders\": {\n            \"azureActiveDirectory\": {\n                \"userDetailsClaim\": \"http://schemas.xmlsoap.org/ws/2005/05/identity/claims/name\",\n                \"registration\": {\n                    \"openIdIssuer\": \"https://login.microsoftonline.com/TENANT\",\n                    \"clientIdSettingName\": \"AZURE_CLIENT_ID\",\n                    \"clientSecretSettingName\": \"AZURE_CLIENT_SECRET\"\n                }\n            }\n        }\n    },\n    \"globalHeaders\": {\n        \"Cache-Control\": \"no-cache\"\n    }\n}\n</code></pre>"},{"location":"Markdown/Publish%20to%20Website/#Formatting","title":"Formatting","text":"<p><code>mkdocs.yml</code> controls a lot of stuff. Read the documentation in the Reference section above. Here's what I'm using so far. To remove downloading external stuff like fonts, I send <code>font: false</code> so it won't download from Google Fonts. Also disabled Mathjax as I'm not using that anymore, and TableSort really need yet.</p> <pre><code># Project Information\nsite_name: wbste for notes\nsite_url: https://wbste.github.io/\n\n# Repository\nrepo_name: wbste\nrepo_url: https://github.com/wbste/wbste.github.io\nedit_uri: edit/main/docs/\n\n# Configuration\ntheme:\n  name: material\n  font: false # disables downloading any fonts\n    # text: Open Sans\n  favicon: images/favicon.png\n  palette:\n    # Palette toggle for light mode\n    - media: \"(prefers-color-scheme: light)\"\n      primary: pink\n      accent: pink\n      scheme: default\n      toggle:\n        icon: material/weather-night \n        name: Switch to dark mode\n\n    # Palette toggle for dark mode\n    - media: \"(prefers-color-scheme: dark)\"\n      primary: pink\n      accent: pink\n      scheme: slate\n      toggle:\n        icon: material/weather-sunny\n        name: Switch to light mode\n\n  icon:\n    edit: material/file-edit\n    logo: fontawesome/solid/person-falling-burst\n\n  features:\n    - navigation.instant\n    - navigation.indexes\n    - navigation.tabs\n    - navigation.sections\n    - navigation.top\n    - navigation.tracking\n    - toc.follow\n    - search.suggest\n    - search.highlight\n    - search.share\n\n# Extensions\nmarkdown_extensions:\n  - pymdownx.highlight:\n      anchor_linenums: true\n  - pymdownx.arithmatex:\n      generic: true\n  - pymdownx.inlinehilite\n  - pymdownx.snippets\n  - admonition\n  - nl2br\n  - footnotes\n  - pymdownx.details\n  - attr_list\n  - def_list\n  - pymdownx.tasklist:\n      custom_checkbox: true\n  - pymdownx.superfences:\n      custom_fences:\n        - name: mermaid\n          class: mermaid\n          format: !!python/name:pymdownx.superfences.fence_code_format\n\nextra_javascript:\n#  - javascripts/mathjax.js # for MatJax\n#  - https://polyfill.io/v3/polyfill.min.js?features=es6 # for MatJax\n#  - https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js # for MatJax\n#  - https://unpkg.com/tablesort@5.3.0/dist/tablesort.min.js # for TableSort\n#  - javascripts/tablesort.js # for TableSort\n\n# Extras\nextra:\n  generator: false\n  social:\n    - icon: material/information\n      link: URL\ncopyright: SOMEONE\n\n\nplugins:\n  - search\n  - callouts\n  - glightbox\n  - git-revision-date-localized\n\nextra_css:\n  - stylesheets/extra.css\n</code></pre> <p>To use a red for example, here's what the <code>extra.css</code> looks like:</p> <pre><code>:root &gt; * {\n\u00a0 --md-primary-fg-color: \u00a0 \u00a0 \u00a0 \u00a0#FF0000;\n}\n</code></pre>"},{"location":"Markdown/Publish%20to%20Website/#Anchors","title":"Anchors","text":"<p><code>mkdocs</code> converts all anchors to lower case, and defaults to removing special characters and spaces for <code>-</code>. That means, even if the header you're linking to is <code># Header Text</code>, the link needs to be <code>#header-text</code>.</p>"},{"location":"Random/Art/","title":"Art","text":""},{"location":"Random/Art/#Elia%20Colombo","title":"Elia Colombo","text":"<ul> <li>Instagram</li> <li>Behance</li> <li>Dribble</li> </ul>"},{"location":"Random/Links/","title":"Links","text":""},{"location":"Random/Links/#Unique%20Links","title":"Unique Links","text":"<ul> <li>AI Database</li> <li>Boil the Frog</li> <li>Cheap PCB Fabrication</li> <li>DeepL Translate</li> <li>EE Textbook</li> <li>FakeYou. Deep Fake Text to Speech.</li> <li>Free AI Chest CT and Mammo</li> <li>Future Timeline</li> <li>Glowforge alternative (Muse)</li> <li>Hawk Watch</li> <li>How to use undocumented web APIs</li> <li>JustWatch</li> <li>LosslessCut</li> <li>Machine Learning Made Easy</li> <li>Marginalia Search</li> <li>Mattress Ratings</li> <li>Music Theory</li> <li>Near Real-Time Satellites</li> <li>Nightdrive</li> <li>No Code Founders</li> <li>Oh My Posh</li> <li>Pints in the Sun</li> <li>Practical Deep Learning</li> <li>Real Time Lightning Map</li> <li>Scan of the Month</li> <li>Search Landmarks Based on Location</li> <li>TIP of My Tongue</li> <li>Turn Audio into Videos</li> <li>Unsplash</li> <li>Weather Radar</li> </ul>"},{"location":"Random/Online%20Classes/","title":"Online Classes","text":""},{"location":"Random/Online%20Classes/#Make%20Almost%20Anything","title":"Make Almost Anything","text":"<ul> <li>MIT Class</li> </ul>"},{"location":"Random/Quotes/","title":"Quotes","text":"<p><code>\"We\u2019re engineers. It means the glass has been manufactured to the wrong specifications.\"</code></p> <p><code>If you want to walk fast, walk alone. If you want to walk far, walk together</code></p> <p><code>\"Happiness without meaning characterizes a relatively shallow, self-absorbed or even selfish life, in which things go well, needs and desire are easily satisfied, and difficult or taxing entanglements are avoided.\"</code></p> <p><code>\u201cMy goal in life is to be as good a person as my dog already thinks I am.\u201d</code></p> <p><code>Everything sucks, some of the time. Everything involves sacrifice.</code></p> <p><code>What is true today that would make your 8 year old self cry?</code></p> <p><code>What makes you forget to eat?</code></p> <p><code>If you had to leave the house all day, every day, where would you go and what would you do?</code></p> <p><code>If you were to die 1 year from today, what would you do and how would you want to be remembered?</code></p> <p><code>If a design is taking too long, the design is wrong.</code></p> <p><code>Don't optimize something that shouldn't exist.</code></p> <p><code>Faster alone, further together</code></p> <p><code>Whether it is to be utopia or oblivion will be a touch and go relay race right up to the final moment...</code></p> <p><code>Reason is not automatic. Those who deny it cannot be conquered by it. Do not count on them. Leave them alone.</code></p> <p><code>I'd rather see less middle management and administration in general. It's become a pigeon hole for people who can neither do nor teach the useful jobs themselves.</code></p> <p><code>There shouldn't be an abundance of admins and managers asking the doers at a company what the problem with their poorly managed company is that lands on any other answer than that itself.</code></p> <p><code>It has happened to me multiple times that I\u2019ve been writing the documentation for a system I\u2019ve created, and found that it\u2019s hard to even describe how to use the system, let alone to actually use it. I think \u201cwhy can\u2019t the system do all this automatically for me?\u201d, and I fix the system to do exactly that, and then I\u2019m relieved of the burden of having to write any documentation for how to do it manually. And as a result the system is better and easier to use for everyone.</code></p> <p><code>75% of the Time We Spend With Our Kids in Our Lifetime Will Be Spent By Age 12</code></p> <p><code>It\u2019s a dangerous thing to mistake speaking without thought for speaking the truth.</code></p> <p><code>Good habits have a price. Bad habits have a cost. Either way, you pay.</code></p>"},{"location":"Random/Recipes/","title":"Recipes","text":""},{"location":"Random/Recipes/#Vegan%20Cookie%20Dough","title":"Vegan Cookie Dough","text":"<p>Recipe from here. Soak the dates in hot water for 10 minutes. Then drain them and keep the date water for later use.  </p> <p>In a food processor, blend dates. Use date water if too dry, or try coconut milk or oat milk for more doughiness. Add almond butter, almond flour, coconut oil, cacao powder, a bit of salt (if almond butter is unsalted), chia seeds, and pulse it all together. You\u2019re after a cookie dough texture.</p> <p></p>"},{"location":"Random/Standards/","title":"Standards","text":"<p>Commonly known as Nationally Recognized Testing Laboratory (NRTL), these companies below certify compliance with various codes and standards.</p> <ul> <li>TUV Rheinland </li> <li>UL Listing </li> <li>Intertek ETL</li> <li>NSF Certification</li> </ul>"},{"location":"Reality%20Capture/","title":"Reality Capture","text":"<p>Reality capture involves the use of advanced technologies like 3D laser scanners, photogrammetry, and high definition 360-degree cameras to collect existing conditions. Certain Apple productions contain LiDAR (Light Detection And Ranging) sensors which enable the capturing of 3D information. That information can then be processed as a mesh or point cloud. A point cloud is simply a set of points (in many cases hundreds of thousands or more), which each point occupying a 3D point in space. A mesh is what would happen if you tried to \"shrink wrap\", or put fabric over all those points and and pulled it tight. Depending on their use case, what was captured, and other variables, each has their pros and cons.</p> <p>See the Capture page for how to use that device to capture both point clouds and meshes, Display for how to show that content in a web browser (or with mkdocs!), and Review and Edit for how to edit or combine different data types (i.e. point clouds and 3D models).</p>"},{"location":"Reality%20Capture/Capture/","title":"Capture","text":"<p>The later versions of the iPad Pro (and iPhone Pro for that matter) have a LiDAR sensor built in. I've tried Scaniverse, SiteScape, Polycam, 3d Scanner App, and a few others.</p> <p>The criteria for scanning software was:</p> <ul> <li>It must be process solely on the device. No sending data to the cloud for registration.</li> <li>It must be able to export, ideally both point cloud and mesh.</li> <li>It must be free, or very cheap if no free options were available. </li> </ul> <p>My personal favorite is Scaniverse. 100% free, exports to both point clouds and mesh file types, performs well, and has some basic crop functionality to cleanup scans. A close second is SiteScape, which limits how big a scan can be, but if you create a free account and log in, you can then export your scans and combine them manually in something like CloudCompare. Seems to create the most dense/detailed point cloud of them all. Specifically for mapping rooms with the goal of usable clean geometry, Polycam does an amazing job. It costs a few bucks for an export, but would be well worth it if that's the requirement.</p>"},{"location":"Reality%20Capture/Display/","title":"Display","text":"<p>The below sections cover how to display meshes or point clouds on the web. While many commercial and non-self hosted solutions exist, I was looking for open source solutions that I could host the file and service on my own, and use with Mkdocs for this site.</p>"},{"location":"Reality%20Capture/Display/#Mesh","title":"Mesh","text":"<p>Using information from here, you can actually embed a 3D mesh. They also have an editor that you can use to create annotation/hotspots, and modify the other variables to your liking.</p> <ol> <li>Save the file from <code>https://unpkg.com/@google/model-viewer@2.1.1/dist/model-viewer.min.js</code> to your project (or just reference it directly).</li> <li>Copy the rest of the example from <code>https://modelviewer.dev/</code>, or use the code below. Remove <code>poster</code>, <code>ar environment-image</code> if you don't have them.</li> </ol> <p>To display the below on this page, we first load up some javascript files:</p> <pre><code>&lt;script type=\"module\" src=\"../../javascripts/model-viewer.min.js\"&gt;&lt;/script&gt;\n&lt;script type=\"module\" src=\"../../javascripts/dimensions.js\"&gt;&lt;/script&gt;\n&lt;script type=\"module\" src=\"../../javascripts/fullscreen.js\"&gt;&lt;/script&gt;\n</code></pre> <p>I also added <code>stylesheets/modelviewer.css</code> to <code>mkdocs.yml</code>, under the <code>extra_css:</code> section. That defines what the buttons look like. I used the variable colors in the theme to make sure they always match.</p> <p>Then we load the asset, and create some buttons. Most of those buttons will be for the dimensions created from the model. The other is a callout. The position for the callout was found by uploading the model to the above editor and clicking on the location.</p> <p>Bug</p> <p>For some reason the online editor has now changed from outputting <code>data-position</code> and <code>data-normal</code> to <code>data-surface</code>, which doesn't seem to work when embedded. Need to test more.</p> <pre><code>&lt;model-viewer id=\"dimensionedmodel\"ar ar-modes=\"webxr scene-viewer quick-look\" camera-controls touch-action=\"pan-y\" auto-rotate shadow-intensity=\"1\" exposure=\"0.75\" environment-image=\"legacy\" src=\"../_assets/snowperson.glb\"&gt;\n  &lt;button slot=\"hotspot-dot+X-Y+Z\" class=\"dot\" data-position=\"1 -1 1\" data-normal=\"1 0 0\"&gt;&lt;/button&gt;\n  &lt;button slot=\"hotspot-dim+X-Y\" class=\"dim\" data-position=\"1 -1 0\" data-normal=\"1 0 0\"&gt;&lt;/button&gt;\n  &lt;button slot=\"hotspot-dot+X-Y-Z\" class=\"dot\" data-position=\"1 -1 -1\" data-normal=\"1 0 0\"&gt;&lt;/button&gt;\n  &lt;button slot=\"hotspot-dim+X-Z\" class=\"dim\" data-position=\"1 0 -1\" data-normal=\"1 0 0\"&gt;&lt;/button&gt;\n  &lt;button slot=\"hotspot-dot+X+Y-Z\" class=\"dot\" data-position=\"1 1 -1\" data-normal=\"0 1 0\"&gt;&lt;/button&gt;\n  &lt;button slot=\"hotspot-dim+Y-Z\" class=\"dim\" data-position=\"0 -1 -1\" data-normal=\"0 1 0\"&gt;&lt;/button&gt;\n  &lt;button slot=\"hotspot-dot-X+Y-Z\" class=\"dot\" data-position=\"-1 1 -1\" data-normal=\"0 1 0\"&gt;&lt;/button&gt;\n  &lt;button slot=\"hotspot-dim-X-Z\" class=\"dim\" data-position=\"-1 0 -1\" data-normal=\"-1 0 0\"&gt;&lt;/button&gt;\n  &lt;button slot=\"hotspot-dot-X-Y-Z\" class=\"dot\" data-position=\"-1 -1 -1\" data-normal=\"-1 0 0\"&gt;&lt;/button&gt;\n  &lt;button slot=\"hotspot-dim-X-Y\" class=\"dim\" data-position=\"-1 -1 0\" data-normal=\"-1 0 0\"&gt;&lt;/button&gt;\n  &lt;button slot=\"hotspot-dot-X-Y+Z\" class=\"dot\" data-position=\"-1 -1 1\" data-normal=\"-1 0 0\"&gt;&lt;/button&gt;\n  &lt;button class=\"Hotspot\" slot=\"hotspot-1\" data-position=\"-0.297m 0.973m 0.136m\" data-normal=\"-0.962m 0.267m 0.047m\" data-visibility-attribute=\"visible\"&gt;\n    &lt;div class=\"HotspotAnnotation\"&gt;First snowman of the year!&lt;/div&gt;\n  &lt;/button&gt;\n  &lt;button id=\"fullScreen\"&gt;Go Fullscreen&lt;/button&gt;\n</code></pre> <p>I did comment out the checkbox and multiple models bit as shown below, and renamed the value in <code>document.querySelector('...')</code> to <code>'#dimensionedmodel'</code> to match the id on this page (see second code block above).</p> <pre><code>const modelViewer = document.querySelector('#dimensionedmodel');\n// Below is for when you want to load multiple models.\n\u00a0 // modelViewer.querySelector('#src').addEventListener('input', (event) =&gt; {\n\u00a0 // \u00a0 modelViewer.src = event.target.value;\n\u00a0 // });\n// Below is for annotations (dimensions or callouts)\n\u00a0 // const checkbox = modelViewer.querySelector('#show-dimensions');\n\u00a0 // function setVisibility(element) {\n\u00a0 // \u00a0 if (checkbox.checked) {\n\u00a0 // \u00a0 \u00a0 element.classList.remove('hide');\n\u00a0 // \u00a0 } else {\n\u00a0 // \u00a0 \u00a0 element.classList.add('hide');\n\u00a0 // \u00a0 }\n\u00a0 // }\n\u00a0 // checkbox.addEventListener('change', () =&gt; {\n\u00a0 // \u00a0 setVisibility(modelViewer.querySelector('#lines'));\n\u00a0 // \u00a0 modelViewer.querySelectorAll('button').forEach((hotspot) =&gt; {\n\u00a0 // \u00a0 \u00a0 setVisibility(hotspot);\n\u00a0 // \u00a0 });\n\u00a0 // });\n\u00a0 // end toggle annotations\n\u00a0 // update svg\n\n\u00a0 function drawLine(svgLine, dotHotspot1, dotHotspot2, dimensionHotspot) {\n...\n</code></pre> <p>Once all that's done, you get this (which you can view in the source of this page between the <code>&lt;!--Start of actual code for 3d model below--&gt;</code> and <code>&lt;!--End of actual code for 3d model below--&gt;</code> comment).</p> <p> First snowman of the year! Go Fullscreen </p>"},{"location":"Reality%20Capture/Display/#Xeokit","title":"Xeokit","text":"<p>The below is a work in progress at this time. Looks like it fulfils all the needs I was looking for (nearly any model type, point clouds, measurements with X, Y, Z, and a number of other items). Information here. Need to work on the below so measurements are only started with someone left-clicks, not both left and right-click. You can also view the page full screen here.</p>"},{"location":"Reality%20Capture/Display/#Point%20Cloud","title":"Point Cloud","text":"<p>Use Potree to display .LAS (georeferenced color point clouds) in a web browser! There is a conversion that needs to take place in Potree Desktop or PotreeConverter. Note the documentation hasn't been updated since the new version. From the repo, you'll need to include the <code>build</code>, <code>libs</code>, and <code>pointclouds</code> folders, but that's it. Also the HTML page that correctly points to the folders. You'll want to update the HTML page to point to the <code>metadata.json</code> file assuming you're using the 2.0 Potree conversion.</p> <ol> <li>Download the latest release.</li> <li>Extract it. All you need for hosting on your own site seem to be <code>build</code>, <code>libs</code>, and <code>pointclouds</code> folders. You can use one of the HTML files in the <code>examples</code> folder to update the path to your model.</li> <li>You should have the following folders once you're done (note I took an example HTML file out, called it <code>model.html</code>, and placed it into a new folder called <code>pages</code>).</li> </ol> <pre><code>build\n  potree\n  shaders\nlibs\n  brotli\n  Cesium\n  ...\npages\n  model.html\npointclouds\n  model\n    hierarchy.bin\n    log.txt\n    metadata.json\n    octree.bin\n</code></pre> <p>You can embed a viewer via <code>iframe</code> as below:</p> <pre><code>&lt;iframe src=\"../potree/pages/model.html\" style=\"border:none;height:800px;width:100%;\" title=\"Potree Viewer\"&gt;&lt;/iframe&gt;\n</code></pre>"},{"location":"Reality%20Capture/Display/#Reload%20Saved%20Scene","title":"Reload Saved Scene","text":"<p>This will reload saved dimensions, annotations, etc. After exporting in <code>Poltree</code> format, under the Scene section of the sidebar, you can re-load the <code>potree.json5</code> file by including <code>viewer.loadProject(\"potree.json5\")</code> in the HTML file that renders the file. Make sure the path is correct.</p>"},{"location":"Reality%20Capture/Display/#Show%20Desired%20Units","title":"Show Desired Units","text":"<p>Assuming the point cloud is in meters, but you want to display any measurements in feet, enter <code>viewer.setLengthUnitAndDisplayUnit('m','ft');</code> in the Developer console or the HTML file. You can also change <code>setLengthUnit</code> if it's wrong. All contained within the <code>viewer.js</code> file.</p>"},{"location":"Reality%20Capture/Display/#Make%20High%20Quality","title":"Make High Quality","text":"<p>Add <code>viewer.useHQ = true;</code> to the HTML page for Splat Quality to be High Quality.</p>"},{"location":"Reality%20Capture/Display/#Customize%20Sidebar","title":"Customize Sidebar","text":"<p>By modifying the HTML page that has the model, you can hide various aspects of the sidebar. Below are some of the options I hid. Their naming corresponds to the <code>sidebar.html</code> file.</p> <pre><code>        viewer.loadGUI(() =&gt; {\n            viewer.setLanguage('en');\n            $(\"#menu_appearance\").hide();\n            $(\"#menu_tools\").next().show();\n            $(\"#menu_measurements\").next().show();\n            $(\"#menu_annotations\").hide();\n            $(\"#menu_scene\").next().show();\n            $(\"#menu_filters\").hide();\n            $(\"#menu_classification\").hide();\n            $(\"#menu_other_settings\").hide();\n            $(\"#menu_about\").hide();\n            $(\"#scene_export\").hide();\n            $(\"#sldMoveSpeed\").hide();\n</code></pre> <p>You can also change the color scheme by modifying <code>potree.css</code>. Use the link the Palette in the file, then export a CSS. Copy and paste that into the <code>potree.css</code> file, then change the root colors 0 thru 4 to align with the rgba codes from Palette.</p> <pre><code>/* Palette URL: http://paletton.com/#uid=13p0u0k3V4WaYgf7Lb1ac80gJaQ */\n\n/* Feel free to copy&amp;paste color codes to your application */\n\n/* As hex codes */\n\n.color-primary-0 { color: #161819 } /* Main Primary color */\n.color-primary-1 { color: #364A51 }\n.color-primary-2 { color: #2A3437 }\n.color-primary-3 { color: #1C2528 }\n.color-primary-4 { color: #1B2F36 }\n\n\n/* As RGBa codes - copy the below rgba values into root below */\n\n.rgba-primary-0 { color: rgba( 22, 24, 25,1) }  /* Main Primary color */\n.rgba-primary-1 { color: rgba( 54, 74, 81,1) }\n.rgba-primary-2 { color: rgba( 42, 52, 55,1) }\n.rgba-primary-3 { color: rgba( 28, 37, 40,1) }\n.rgba-primary-4 { color: rgba( 27, 47, 54,1) }\n\n/* Generated by Paletton.com \u00a9 2002-2014 */\n/* http://paletton.com */\n\n:root{\n\n    --color-0:          rgba( 22, 24, 25,1);\n    --color-1:          rgba( 54, 74, 81,1);\n    --color-2:          rgba( 42, 52, 55,1);\n    --color-3:          rgba( 28, 37, 40,1);\n    --color-4:          rgba( 27, 47, 54,1);\n\n...\n</code></pre>"},{"location":"Reality%20Capture/Display/#Add%20Transformation%20Gizmo","title":"Add Transformation Gizmo","text":"<p>To allow movement of the point clouds you can include the following code in <code>potree.js</code>. Just click on the point cloud and it will bring up the transformation gizmo. Thanks to the commenter here for the tip! The transformations are not saved, so you can refresh the page to \"reset\".</p> <pre><code>if(!consumed){\n    if (e.button === MOUSE.LEFT) {\n        if (noMovement) {\n            let selectable = this.hoveredElements\n                .find(el =&gt; el.object._listeners &amp;&amp; el.object._listeners['select']);\n\n// start new code\n\n      let pointCloudIntersect = Utils.getMousePointCloudIntersection(\n          this.mouse,\n          this.viewer.scene.getActiveCamera(),\n          this.viewer,\n          this.viewer.scene.pointclouds,\n          {pickClipped: true})\n      if (selectable || pointCloudIntersect) {\n          selectable = selectable ? selectable.object : pointCloudIntersect.pointcloud;\n\n// end new code, then comment out the below two items. \n\n//          if (selectable) {\n//              selectable = selectable.object;\n                if (this.isSelected(selectable)) {\n                    this.selection\n                        .filter(e =&gt; e !== selectable)\n                        .forEach(e =&gt; this.toggleSelection(e));\n                } else {\n                    this.deselectAll();\n                    this.toggleSelection(selectable);\n                }\n            } else {\n                this.deselectAll();\n</code></pre>"},{"location":"Reality%20Capture/Review%20and%20Edit/","title":"Review and Edit","text":"<p>The page will detail how to edit the various files types, as well as combining different file types for reviewing (i.e. add a 3D model to a point cloud to see if there are any conflicts).</p>"},{"location":"Reality%20Capture/Review%20and%20Edit/#Review","title":"Review","text":"<ol> <li>Export a scan from the iPad (via Scaniverse) to a GLB file. This method should work with PLY files as well, but I got errors.</li> <li>Using modeling software, create whatever 3D geometry you want. Export that to an OBJ with the MTL file if you want it.</li> <li>Download 3D Builder from the Microsoft Store.</li> <li>Also download 3D Viewer.</li> <li>Open 3D Builder, and import your OBJs and GLBs. Modify as needed, and export as a GLB.<ol> <li>OBJ will need to be scaled correctly on import. Typically it's in meters.</li> </ol> </li> </ol>"},{"location":"Reality%20Capture/Review%20and%20Edit/#Edit","title":"Edit","text":"<p>Some popular options for editing meshes and/or point clouds include CloudCompare, Potree Desktop, MeshLab, and Blender. </p>"},{"location":"Shop/CNC%20Overview/","title":"CNC Overview","text":""},{"location":"Shop/CNC%20Overview/#Coordinate%20System%20Directions","title":"Coordinate System Directions","text":"<p> The movement of your CNC along the coordinate system is always based on how your tool moves, not the table. For example, increasing the X coordinate value would move the table left, but when looked at from the perspective of the tool, it\u2019s moving right along a workpiece.</p>"},{"location":"Shop/CNC%20Overview/#How%20CNC%20and%20Human%20Coordinates%20Interact","title":"How CNC and Human Coordinates Interact","text":"<p>As we mentioned above, human operators will use a WCS which provides an easy set of coordinates for writing a CNC program. However, these coordinates are always different from a machine\u2019s coordinates, so how does your CNC machine line the two up? With offsets.</p> <p>A CNC machine will use what\u2019s called a work offset to determine the difference in distance between your WCS and its own home position. These offsets get stored in the controller of the machine, and can typically be accessed in an offset table like the one below. </p> <p>Here we can see that several offsets have already been programmed, G54, G55, and G59. What\u2019s the benefit in having multiple offsets? If you are machining multiple parts in one job, each part can be assigned its own offset. This allows the CNC machine to accurately relate its coordinate system to multiple parts in different places, and complete multiple setups at once. </p>"},{"location":"Shop/CNC%20Overview/#Tool%20Offsets","title":"Tool Offsets","text":"<p> It\u2019s pretty common to use multiple tools for the same job, but you need a way to account for different tool lengths. A tool offset are programmed into your CNC machine to make this easy work. With a tool offset programmed, your CNC machine will know exactly how far each tool extends from the spindle. There are several ways to record a tool offset:</p> <ul> <li>Jogging. Move the tool from the machine\u2019s home position to the part\u2019s zero position. The distance traveled is measured and entered as the tool\u2019s offset.</li> <li>Precision block. Set all tools to a common Z position at the top of a 1-2-3 precision block that rests on the machine\u2019s table.</li> <li>Probing. Use a probe to automatically determine the tool offset. This is the most efficient method but also the most expensive, as it requires the probe equipment.</li> </ul>"},{"location":"Shop/CNC%20Overview/#Climb%20Milling","title":"Climb Milling","text":"<p> - Chip width starts from maximum and decreases so heat generated will more likely transfer to the chip. - Creates cleaner shear plane which causes the tool to rub less and increases tool life. - Chips are removed behind the cutter which reduces the chance of re-cutting. - Downwards forces in horizontal milling are created that help hold the workpiece down; less complex work holdings are needed when coupled with these forces.</p>"},{"location":"Shop/CNC%20Overview/#Conventional%20Milling","title":"Conventional Milling","text":"<p> - Chip width starts from zero and increases which causes more heat to diffuse into the workpiece and produces work hardening. - Tool rubs more at the beginning of the cut causing faster tool wear and decreases tool life. - Chips are carried upward by the tooth and fall in front of cutter creating a marred finish and re-cutting of chips. - Upwards forces created in horizontal milling tend to lift the workpiece, more intricate and expansive work holdings are needed to lessen the lift created.</p>"},{"location":"Shop/Taig%20Micro%20Mill/","title":"Taig Micro Mill","text":"<p>Ordered a refurbished version of this.</p> <p></p>"},{"location":"Shop/Taig%20Micro%20Mill/#Links","title":"Links","text":"<p>Micro Machine Shop Carter Tools Taig Tools </p>"},{"location":"Shop/Taig%20Micro%20Mill/#Description","title":"Description","text":"<p>Taken from link above</p> <p>The Micro Mill is a very rigid and precise machine that uses some of the most advanced techniques compared to its competitors. The Y-axis and Z-axis are supported on 2 1/2 inch square steel tubing to provide a very solid feel. The leadscrews are all 1/2-20 unlike a lot of machines of similar size that use 1/4 inch leadscrews. TAIG prefers to provide added mechanical features to allow the mill to be more useful without raising the price. Being an aerospace manufacturer for over 18 years our machinists know the importance of table back-lash compensation and full gib adjustments for wear as employed in the manufacture of the Micro Mill. Basically, the Micro Mill was designed by machinists and built by machinists. Overall working accuracy should exceed .0005 in. All machines are sold with a 14 day refund and a full 2 year factory warranty on all Mill components and accessories.</p> <p>The Micro Mill has effortless, chatterless, table and millhead movement due to the unique design of oversized gibs, ground \u2018Y\u2019 axis steel ways, and a massive carriage assembly. The ground steel ways on the vertical mill head support provides a very rigid Z-axis and makes the Micro Mill ready for CNC upgrade if you desire. Our small Mill is really a scaled down version of a big Mill with manual operation.</p> <p>This is the machine you don\u2019t have to baby. The Micro Mill is a rugged precision instrument that has plenty of rigidity. It has a life-time ball bearing spindle, coupled with a six speed positive vee belt drive. Spindle speeds in geometric progression (CR version 1000 \u2013 10000 rpm) provide the power to \u201cHOG\u201d 1/8 inch cuts in mild steel or the speed and precision to \u201cdust\u201d a few tenths (compare that to other mills of similar size on the market,\u00a0you can\u2019t!).</p> <p>Other big Mill features include large .001 inch graduations on friction adjustable micrometer dials for the X,Y,&amp; Z axis. Adjustable gibs provide full compensation for X,Y &amp; Z axis wear. The spindle head column can rotate from 0 to 180 degrees to provide for special machining tasks. All this adds up to a BEST VALUE in small Mills.</p> <p>Should there be any questions regarding specific uses of the Micro Mill please feel free to call, write, email, or visit our facility.</p>"},{"location":"Shop/Taig%20Micro%20Mill/#Specifications","title":"Specifications","text":"<p>GENERAL</p> <p>Height 26-3/8 in Width 22 in Depth 21 in Weight 80 lbs (manual) 105 lbs (CNC) Maximum bearing runout 0.0002 in. X axis dovetails 45 deg. Y axis dovetails 90 deg. Z axis steel box ways 1/2\u2033-20 lead screws on X,Y,&amp; Z All lead screw drives have friction adjustable micrometer dials in .001 inch increments Pulley type std. 5/8 in. bore multi-step vee belt. Construction \u2013 Steel, hard anodized aluminum on all moving components, adjustable brass gibs, and precision ground steel ways hand lapped for long life and accuracy.</p> <p>CAPACITY</p> <p>Travel in X axis 12 in. (Model 2019) Travel in Y axis 5.5 in Travel in Z axis 6.0 in Table dimensions 3 1/2 x 18.4 inches (Model 2019) Maximum Z-distance to table 9.0 in Z-Axis swivel 90 degrees 6 spindle speeds 1000-10000 RPM (CR &amp; CNC) Z axis column rotation up to 180 degrees Spindle head rotation 90 degrees</p> <p>SPINDLE (ER16 SPINDLE)</p> <p>Spindle Runout less than .0002 Maximum spindle speed 10000 RPM Sealed precision ball bearing Bearing OD 1.5748 in., ID 0.6692 in. Spindle nose 22mm X 1.5mm Spindle hole 0.406 in. Spindle ID taper 8 deg (16 deg included) Max. collet diameter 3/8 in. Pulley size 5/8 in. bore. Ball Bearings in all lead screw bearing blocks</p>"},{"location":"Shop/Taig%20Micro%20Mill/#Setup%20and%20Alignment","title":"Setup and Alignment","text":"<p>Documentation from here. More good resources at that link as well.</p>"},{"location":"Shop/Taig%20Micro%20Mill/#Quick%20Installation","title":"Quick Installation","text":"<p>The table as it comes from the factory. Clean the mating surface in back of the machine clean of all grease, dirt, etc.</p> <p></p> <p>The column as it comes from the factory. Clean the mating surface (the round shape at the bottom of the column.</p> <p></p> <p>Assemble the column to the table with the wrench. Make it just tight enough to move by hand, but not so loose that it falls to the side (been there, left a nice gouge in my table the first time I did this).</p> <p>Place the square on the table and adjust the column so the headstock is square to the table.</p> <p>Tighten it up and you can start using the mill.</p> <p></p> <p>If you want more accuracy, use a dial test indicator to \"sweep\" the table. It is easier if you use blocks rather than running the tip into the table slots. You can drive yourself crazy trying to take out the last .001\", so don't! But seriously, if you can get it perpendicular to within .001 over 8\" that is pretty good for a milling machine. With practice you can get it under .001\", but it takes some finesse.</p> <p>Tighten the column, reindicate (might have shifted, I told you you could go insane). I find that tightening it as tight as possible with my hand choked up on the wrench so it is near the head is pretty good. Too loose and the column will shift, too tight and it will bend something (40 ft/lbs is too much! I did it and bent the front of the machine)</p> <p></p> <p>The right hand table gib adjustment screw.</p> <p>Tighten the left screw inward while loosening the right screw out to tighten the table, to loosen the table tighten the right in while loosening the left out.</p> <p>The screw in the middle of the front of the table locks it.</p> <p></p> <p>The left hand table gib adjustment screw. (top screw in picture)</p> <p>The y-axis gib screws, adjust the two screws in or out to adjust the gib. The bottom screw locks the table</p> <p></p> <p>The top column gib screw. The top screw will tighten the gib when tightened, while the bottom screw is loosened out. The bottom screw will loosen the gib while tightened, as the top screw is loosened.</p> <p></p> <p>The bottom column gib screw.</p> <p></p> <p>Sometimes the z-axis dovetail mount is out a tiny bit, which can through compounding of errors make the spindle not perpendicuar to the y-axis. Do not adjust it unless you know what you are doing! In practice I have found sometimes slipping a thin (.001) shim in the dovetail plate will correct this problem.</p> <p>But again, don't do it unless you really know how to chase down errors! This can really drive you crazy sometimes. Not to mention driving me crazy when I try to fix your problem via email.</p> <p></p> <p>This is a drawing I did showing the mechanics of the x axis tapered gib from the top. Some clarifications:</p> <p>If either of the screws A and B are loose, then the gib can move freely against the tapered surface. This will cause binding when the table travels to the right and looseness when the table travels to the left. The screws push a thick washer that bears against the gib ends and rides in a counterbored hole. When adjusted both screw heads must be tight against the gib ends.</p> <p>As you can see, if you tighten A and loosen B, then the gib will move right, tightening the gib against the table.</p> <p>Think of the screws not so much as tightening and loosening the gib, but as positioning the gib against it's angled surface. It is the angled surface that actually presses the gib against the x-axis.</p>"},{"location":"Shop/Taig%20Micro%20Mill/#Detailed%20Installation","title":"Detailed Installation","text":"<p>The underside of the mill base.</p> <p></p> <p>Closeup of the y-axis gib retainer plate. The tall screw locks the gib (never used for CNC). The two side screws adjust the gib and the nuts lock the adjustment.</p> <p></p> <p>X axis gib screw.</p> <p></p> <p>Underside of the y-axis bearing plate. Notice the small roll pin that locks the bearing unit in place on the plate.</p> <p></p> <p>The base unit. Those screws in the table hold the small nuts used to hold the vise.</p> <p></p> <p>The column unit.</p> <p></p> <p>The circular boss that mates with the base unit. Clean the mating surface well before assembling.</p> <p></p> <p>You can see the bottom z-axis gib screw here.</p> <p></p> <p>Holding the column up while tightening the nut to fasten the column to the base.</p> <p></p> <p>Notice that I have \"choked up\" on the wrench. You don't want to overtighten the nut.</p> <p></p> <p>Squaring the column initially using a square against the headstock.</p> <p></p> <p>The top z-axis gib screw and part of the motor mount.</p> <p>The two side screws hold the clamping shoes that retain the z-axis on the slide.</p> <p></p> <p>The z-axis top gib screw. These screws position the z-axis gib in the same manner as the x-axis tapered gib explained in the first mill setup article. The gib eliminates twist on the central z-axis slide bar.</p> <p></p> <p>Adjusting the clamping shoe for the z-axis. The factor recommends that you squeeze it together with hand pressure then tighten the screws, without mounting the motor yet. This is usually fine from the factory so don't worry about it unless you need to. There used to be a screw from the front of the slide for adjustment but the factory found hand pressure was better for this adjustment.</p> <p></p> <p>The y-axis gib.</p> <p></p> <p>X-axis gib, wider end.</p> <p></p> <p>X-axis gib narrower end. Both of these screws should be tight once the position of the gib is adjusted.</p>"},{"location":"Shop/Taig%20Micro%20Mill/#Column%20To%20Spindle%20Alignment","title":"Column To Spindle Alignment","text":"<p>Most guides use tramming to ensure alignment, but due to the Taig's design the below is another alignment concern that should be addressed.</p> <p></p> <p>Vertically traveling up and down as show in the next two images will eliminate that issue.</p> <p></p> <p>If the front to back alignment is off:</p> <p></p> <p>Shimming may be required:</p> <p></p>"},{"location":"Shop/Taig%20Micro%20Mill/#CNC%20Stepper%20Motor%20Installation","title":"CNC Stepper Motor Installation","text":"<p>The CNC stepper motor mounts.</p> <p></p> <p>The tube threads onto the bearing block, and the collar clamps it once adjustment is completed.</p> <p></p> <p>The mount completed.</p> <p></p> <p>The stepper motor coupling half. The stepper shaft should be just at the bottom of the bore. The side screw clamps it tight.</p> <p></p> <p>The coupling tubes inserted in the coupling half. One user found that trimming them to diminishing lengths made assembly easier. I asked the factory why tubing instead of solid rod and they said they found that solid rod would shear more easily under the stresses than tubing.</p> <p></p> <p>Inserting the tubes into the screw coupler half. This can take some wiggling and might drive you crazy. Turn the coupler half while rocking the motor around and you'll get it.</p> <p></p> <p>The gap is adjusted to be 1/8\"-1/16\" and the motor butts against the tube end.</p> <p></p> <p>Another view.</p> <p></p> <p>The motor is fastened to the plate. Make sure that the motor doesn't \"cock\" when the screws are tightened.</p> <p></p> <p>Basic assembly of the CNC mill completed.</p> <p></p> <p>The motor mount attached to the headstock.</p> <p></p> <p>The motor mount plate attached with the two screws.</p> <p></p> <p>The motor, mounted.</p> <p></p> <p>The pulleys should be aligned so that the motor and headstock shafts are parallel and the pulleys are in the same plane. The belt will suffer if care isn't taken with alignment. The motor can be adjusted up and down and for twist by moving the motor mount in the headstock slot. Be careful as it is heavy. if the belt makes a clicking noise then you need to adjust the alignment.</p> <p></p> <p>The motor assembled. When running the mill for the first few times you will notice that it has a hard time coming up to speed on the fastest pulley setting. After time the grease will thin and everything will start fine, but at first run it in the next to highest groove until the headstock warms up.</p> <p></p> <p>This is somewhat advanced, determining if the slide travel is perpendicular to the table by running the inidcator up and down a square (1-2-3 block) on the table, and adjusting the column by tapping with a soft hammer while the mounting nut is slightly loose.</p> <p></p> <p>Once the z-axis slide is determined to run perpendicular to the table, you can check that the dovetail headstock mount in parallel to the travel of the slide by running the tip of an indicator along the dovetail. Slack all the dovetail mounting screws, but leave one slightly tight and adjust again by tapping with a soft hammer to bring into alignment. This can really make you crazy. But it will allow the greatest accuracy. But really, don't try this until you are comfortable adjusting things...</p> <p></p> <p>Closeup of the indicator tip against the dovetail. See below about Cosine error....</p> <p></p> <p>Once all that fiddling is done, test to see how well you have it aligned by sweeping the table.</p> <p></p> <p>If you can get it to within .001 over 8\"-12\" you can call yourself an expert. I use the same block rather than two because I don't have a matched pair...</p> <p></p> <p>You want the tip of the indicator to be roughly parallel to the work surface to be gaged. You can read all about Cosine error\u00a0here...if you don't have enough to think about already.</p>"},{"location":"Shop/Taig%20Micro%20Mill/#Backlash%20Adjustment","title":"Backlash Adjustment","text":""},{"location":"Technology/Affinity/","title":"Affinity","text":"<p>The company Serif offers a suite of applications for professional photo editing, publishing, graphic design and illustration. Affinity Designer, Affinity Photo, and Affinity Publisher are those applications. They work on iPadOS, macOS, and Windows. Below are some tips and tricks.</p>"},{"location":"Technology/Affinity/#Designer","title":"Designer","text":""},{"location":"Technology/Affinity/#Start%20New%20Line","title":"Start New Line","text":"<p>Double click on the last node of the pen tool to start a new line.</p>"},{"location":"Technology/Affinity/#Create%20Shapes%20From%20Linework","title":"Create Shapes From Linework","text":"<ul> <li>Select all the lines that will be used.</li> <li>Group them <code>(Ctrl + G)</code></li> <li>Duplicate that group <code>(Ctrl + J)</code><ul> <li>This will make sure you don't lose your original lines.</li> </ul> </li> <li>Make sure the newly duplicated group is selected.</li> <li>Ungroup <code>(Ctrl + Shift + G)</code>. Make sure the lines remain highlighted in the Layers panel.</li> <li>Under the Layer menu, select Expand Stroke</li> <li>do a Boolean operation of Add</li> <li></li> <li>then Divide</li> <li></li> </ul> <p>Warning</p> <p>With the redesign of Designer 2, you now have the extra step to right click on the shape in the canvas (make sure the layer is selected), Geometry, Separate Curves.</p> <p></p> <p>The result will look like the below! </p>"},{"location":"Technology/Cyber%20Security/","title":"Cyber Security","text":"<p>Using a free website called Try Hack Me to learn the basics.</p>"},{"location":"Technology/Cyber%20Security/#Sites","title":"Sites","text":"<ul> <li>Open Worldwide Application Security Project (OWASP)<ul> <li>Used solely to test the security of web applications and services.</li> </ul> </li> </ul>"},{"location":"Technology/Cyber%20Security/#Tools","title":"Tools","text":"<p>Below are some tools of the trade mentioned on TryHackMe.</p> <ul> <li>GoBuster<ul> <li>Command line security app</li> <li><code>gobuster -u http://fakebank.com -w wordlist.txt dir</code> for example to scan for hidden pages using a wordlist.</li> </ul> </li> <li>Metasploit<ul> <li>exploitation tool</li> </ul> </li> <li>AbuseIPDB<ul> <li>Find abusive IPs</li> </ul> </li> <li>Cisco Talos Intelligence<ul> <li>Find abusive IPs, domains, and network owners.</li> </ul> </li> <li>NMap<ul> <li>Network Mapper</li> </ul> </li> </ul>"},{"location":"Technology/Cyber%20Security/#NMap","title":"NMap","text":"<ul> <li><code>nmap 192.168.1.1</code>: At its simplest, an Nmap command can be a scan of a single host. This command scans the host at IP address 192.168.1.1 for open ports and services. This is often the first step in network exploration, providing a quick overview of the target's open ports and services.</li> <li><code>nmap -p 1-100 192.168.1.1</code>: This command is a bit more specific. It scans the first 100 ports on the host. You can adjust the range as needed, allowing for targeted scanning of ports based on your requirements. This is particularly useful when you're interested in a specific range of ports.</li> <li><code>nmap -sV 192.168.1.1</code>: This command performs a service scan. It not only checks for open ports but also tries to determine the service running on each port. This is a crucial step in network exploration as it provides more detailed information about the target, including the versions of the services running on open ports.</li> <li><code>nmap -A 192.168.1.1</code>: This command is like a Swiss Army knife. It enables OS and version detection, script scanning, and traceroute, providing a comprehensive view of the target. This is a powerful command that can provide a wealth of information about a target host, making it a favorite among many Nmap users.</li> <li><code>nmap -p- -sS -T4 192.168.1.1</code>: This command is for those who want to leave no stone unturned. It performs a stealth SYN scan (-sS) on all 65535 ports (-p-) with an aggressive timing option (-T4). This is a more aggressive and comprehensive scan that can provide a complete picture of a target's open ports. However, its aggressive nature means it may be detected by intrusion detection systems, so it should be used with caution.</li> <li><code>nmap --script=vuln 192.168.1.1</code>: This command is a prime example of the power of Nmap's scripting engine. It checks for known vulnerabilities on the host, running a variety of vulnerability scanning scripts against the target. This can be incredibly useful for identifying potential security risks on a host.</li> </ul>"},{"location":"Technology/Cyber%20Security/#Terms","title":"Terms","text":"<ul> <li>Security Operations Center (SOC) </li> <li>Security Information and Event Management (SIEM)</li> <li>Potentially Unwanted Program (PUP) or Potentially Unwanted Application (PUA)<ul> <li>bundleware</li> <li>junkware</li> <li>annoying stuff in general</li> </ul> </li> <li>Smishing (SMS phishing)</li> <li>Vishing generally uses voice to trick users.</li> <li>Whaling is a highly targeted phishing attack - aimed at senior executives - masquerading as a legitimate email.</li> <li>Pharming is the criminal act of producing a fake website and then redirecting users to it.</li> <li>Spear phishing is an email or electronic communications scam targeted towards a specific individual, organization or business.</li> <li>Spam over Internet Telephone (SPIT)</li> <li>Spam over Instant Messaging (SPIM)</li> <li>Bluesnarfing is the unauthorized access of information from a wireless device through a Bluetooth connection</li> </ul>"},{"location":"Technology/Cyber%20Security/#Frameworks","title":"Frameworks","text":"<p>The importance of cybersecurity frameworks cannot be overstated. Here are some reasons why they are essential. Content from The Final Hop.</p> <ol> <li>Risk Management: Cybersecurity frameworks provide a systematic approach to managing security risks. By following these frameworks, organizations can identify their most significant risks and implement appropriate controls to mitigate them.</li> <li>Compliance: Many industries have regulations that require certain security controls and measures. Utilizing a recognized cybersecurity framework can help organizations meet these regulatory requirements and avoid potential fines or sanctions.</li> <li>Standardization: Cybersecurity frameworks offer a common language and set of standards that all organizations can adhere to. This standardization makes it easier for businesses to communicate about cybersecurity risks and controls with stakeholders, including employees, customers, partners, and regulators.</li> <li>Trust and Reputation: Demonstrating adherence to a recognized cybersecurity framework can enhance an organization's reputation. It shows customers, partners, and stakeholders that the organization takes cybersecurity seriously and has taken steps to secure its systems and data.</li> <li> <p>Incident Response: Cybersecurity frameworks typically include guidelines for responding to and recovering from cyber incidents. This ensures organizations are prepared for potential cyber threats and can respond effectively when incidents occur.</p> </li> <li> <p>National Institute of Standards and Technology (NIST)</p> </li> <li>International Organization for Standardization (ISO)</li> <li>International Electrotechnical Commission (IEC)</li> <li>Center for Internet Security (CIS) Controls</li> <li>Control Objectives for Information and Related Technologies (COBIT)</li> <li>Payment Card Industry Data Security Standard (PCI DSS)</li> </ol>"},{"location":"Technology/Cyber%20Security/#Walking%20An%20Application","title":"Walking An Application","text":"<ul> <li>View Source: Use your browser to view the human-readable source code of a website.</li> <li>Inspector: Learn how to inspect page elements and make changes to view usually blocked content.</li> <li>Debugger: Inspect and control the flow of a page's JavaScript</li> <li>Network: See all the network requests a page makes.</li> </ul>"},{"location":"Technology/Cyber%20Security/#DNS%20Records","title":"DNS Records","text":"<ul> <li>A Record: These records resolve to IPv4 addresses, for example 104.26.10.229</li> <li>AAAA Record: These records resolve to IPv6 addresses, for example 2606:4700:20::681a:be5</li> <li>CNAME Record: These records resolve to another domain name, for example, TryHackMe's online shop has the subdomain name store.tryhackme.com which returns a CNAME record shops.shopify.com. Another DNS request would then be made to shops.shopify.com to work out the IP address.</li> <li>MX Record: These records resolve to the address of the servers that handle the email for the domain you are querying, for example an MX record response for tryhackme.com would look something like alt1.aspmx.l.google.com. These records also come with a priority flag. This tells the client in which order to try the servers, this is perfect for if the main server goes down and email needs to be sent to a backup server.</li> <li>TXT Record: TXT records are free text fields where any text-based data can be stored. TXT records have multiple uses, but some common ones can be to list servers that have the authority to send an email on behalf of the domain (this can help in the battle against spam and spoofed email). They can also be used to verify ownership of the domain name when signing up for third party services.</li> </ul>"},{"location":"Technology/Home%20Assistant/","title":"Home Assistant","text":"<p>Home Assistant is free and open-source software for home automation designed to be a central control system for smart home devices with a focus on local control and privacy.</p>"},{"location":"Technology/Home%20Assistant/#TTS%20alert%20to%20mobile%20on%20alarm%20channel","title":"TTS alert to mobile on alarm channel","text":"<p>The below is the complete YAML code from  Automations. It plays the alert on the same audio stream as the alarm does on android. That way you can keep the regular audio stream muted and still get these alerts.</p> <pre><code>alias: High Water Usage\ndescription: \"\"\ntrigger:\n  - platform: numeric_state\n    entity_id: sensor.flume_sensor_home_60_minutes\n    above: \"20\"\ncondition: []\naction:\n  - service: notify.mobile_app_[PHONENAME]\n    data:\n      message: &gt;-\n        You are currently consuming\n        {{states('sensor.flume_sensor_home_60_minutes')}} GPM\n      title: High water usage detected\n  - service: notify.mobile_app_[PHONENAME]\n    data:\n      message: TTS\n      data:\n        tts_text: &gt;-\n          High water usage detected. You are currently consuming\n          {{states('sensor.flume_sensor_home_60_minutes')}} gallons per minute.\n        media_stream: alarm_stream\n        priority: high\n        ttl: 0\nmode: single\n</code></pre> <p>Above is per this link</p>"},{"location":"Technology/Home%20Assistant/#Camera%20Take%20Picture%20on%20Tap","title":"Camera Take Picture on Tap","text":"<p>Create a Script, the input the below, which is taken from this. You can use a Picture Glance card with a service that calls that script on tap.</p> <pre><code>alias: Blink Snap Picture Driveway\nsequence:\n  - service: blink.trigger_camera\n    target:\n      entity_id: camera.blink_driveway\n    data: {}\n  - delay: \"00:00:05\"\n  - service: blink.blink_update\n    data: {}\n  - service: camera.snapshot\n    target:\n      entity_id: camera.blink_driveway\n    data:\n      filename: /media/driveway.jpg\nmode: single\n</code></pre>"},{"location":"Technology/Home%20Assistant/#Remote%20Access","title":"Remote Access","text":"<ul> <li>Setup port forwarding for the HA Server to take TCP traffic from 443 &gt; 8123</li> <li>Go to duckdns.org and create a domain. Grab the token and domain on the page.<ul> <li>Logged in with Google account.</li> </ul> </li> <li>Install the duckdns add-on.<ul> <li>Let's Encrypt, etc. aren't needed.</li> </ul> </li> <li>Set it up. Make sure to set <code>accept_terms</code> to <code>true</code> on the configuration screen.</li> <li>Add the following to the <code>configuration.yaml</code>, which is generated after installing duckdns and running it.</li> </ul> <pre><code>http:   \n ssl_certificate: /ssl/fullchain.pem   \n ssl_key: /ssl/privkey.pem\n</code></pre> <ul> <li>Restart HA.</li> <li>Update home and away URLs to use HTTPS.</li> <li>Good guide here.</li> </ul>"},{"location":"Technology/Home%20Assistant/#Commands","title":"Commands","text":""},{"location":"Technology/Home%20Assistant/#Home%20Assistant_1","title":"Home Assistant","text":"<pre><code>ha core check\nha core info\nha core logs\nha core options\nha core rebuild\nha core restart\nha core start\nha core stats\nha core stop\nha core update\n</code></pre>"},{"location":"Technology/Home%20Assistant/#Supervisor","title":"Supervisor","text":"<pre><code>ha supervisor info\nha supervisor logs\nha supervisor reload\nha supervisor update\n</code></pre>"},{"location":"Technology/Home%20Assistant/#Host","title":"Host","text":"<pre><code>ha host reboot\nha host shutdown\nha host update\n</code></pre>"},{"location":"Technology/Home%20Assistant/#Hardware","title":"Hardware","text":"<pre><code>ha hardware info\nha hardware audio\n</code></pre>"},{"location":"Technology/Home%20Assistant/#Example%20Updates","title":"Example Updates","text":"<p><code>ha core update --version 2022.10.1</code></p> <p><code>ha os update --version 9.2</code></p> <p><code>ha supervisor update --version 2022.10.0</code></p>"},{"location":"Technology/Home%20Assistant/#HA%20Help%20Output","title":"HA Help Output","text":"<pre><code>The Home Assistant CLI is a small and simple command line utility that allows\nyou to control and configure different aspects of Home Assistant\n\nUsage:\n  ha [command]\n\nAvailable Commands:\n  addons         Install, update, remove and configure Home Assistant add-ons\n  audio          Audio device handling.\n  authentication Authentication for Home Assistant users.\n  backups        Create, restore and remove backups\n  banner         Prints the CLI Home Assistant banner along with some useful information\n  cli            Get information, update or configure the Home Assistant cli backend\n  core           Provides control of the Home Assistant Core\n  dns            Get information, update or configure the Home Assistant DNS server\n  docker         Docker backend specific for info and OCI configuration\n  hardware       Provides hardware information about your system\n  help           Help about any command\n  host           Control the host/system that Home Assistant is running on\n  info           Provides a general Home Assistant information overview\n  jobs           Get information and manage running jobs\n  multicast      Get information, update or configure the Home Assistant Multicast\n  network        Network specific for updating, info and configuration imports\n  observer       Get information, update or configure the Home Assistant observer\n  os             Operating System specific for updating, info and configuration imports\n  resolution     Resolution center of Supervisor, show issues and suggest solutions\n  supervisor     Monitor, control and configure the Home Assistant Supervisor\n\nFlags:\n      --api-token string   Home Assistant Supervisor API token\n      --config string      Optional config file (default is $HOME/.homeassistant.yaml)\n      --endpoint string    Endpoint for Home Assistant Supervisor (default is 'supervisor')\n  -h, --help               help for ha\n      --log-level string   Log level (defaults to Warn)\n      --no-progress        Disable the progress spinner\n      --raw-json           Output raw JSON from the API\n\nUse \"ha [command] --help\" for more information about a command.\n</code></pre>"},{"location":"Technology/Keyboard/","title":"Keyboard","text":""},{"location":"Technology/Keyboard/#Specs","title":"Specs","text":"<ul> <li>Sofle V1<ul> <li>Mechboards</li> </ul> </li> <li>Kailh Low Profile Choc Switches (V1)<ul> <li>Brown (Tactile)</li> <li>Choc Hotswap Sockets</li> </ul> </li> <li>MoErgo POM MCC\u00a0Low Profile Split Ergo Keycaps, AMOERKC1116072</li> <li>OLED Screens<ul> <li>128\u00d732 I2C OLED graphic display</li> </ul> </li> <li>Pro Micro Type C\u00a0Controllers<ul> <li>AVR ATmega32u4 8-bit microcontroller</li> </ul> </li> <li>QMK firmware<ul> <li>Compatible with VIA</li> <li>https://github.com/qmk/qmk_firmware/tree/master/keyboards/sofle</li> </ul> </li> <li>EC11 encoder<ul> <li>6mm stud (T18 shaft), default knob is 14mm x 17mm tall.</li> </ul> </li> </ul>"},{"location":"Technology/Keyboard/#Build%20Guide","title":"Build Guide","text":"<p>https://choc.brianlow.com/ - useful but outdated.</p>"},{"location":"Technology/Keyboard/#Things%20to%20check","title":"Things to check","text":"<ul> <li>KMonad</li> <li>xcape</li> </ul>"},{"location":"Technology/Keyboard/#Custom%20Firmware","title":"Custom Firmware","text":"<p>All based on the great guide here. I couldn't get QMK toolbox to flash correctly so I just used MSYS.</p> <p>Info</p> <p>In <code>qmk_firmware/keyboards/sofle/keymaps/via/rules.mk</code>, setting <code>RGBLIGHT_ENABLE = no</code> saved a lot of space. I don't have any RGB so no issues there. I also had to change <code>#define TAPPING_TERM 200</code> in <code>qmk_firmware/keyboards/sofle/rev1/config.h</code> so I could get this to work for me. The default value is <code>100</code> from the repo.</p> <ol> <li>Open VIA in Chrome, backup your layout.</li> <li>Clone the official QMK repo.</li> <li>Download QMK MSYS.</li> <li>Open it, then run <code>qmk setup -H &lt;path&gt;</code></li> <li>Set the default keyboard with <code>qmk config user.keyboard=sofle/rev1</code></li> <li>Set the default keymap with <code>qmk config user.keymap=via</code></li> <li>Make some tweaks. Even thought I have the Sofle V1 choc version, the Sofle V1 VIA version worked fine.</li> <li>Run <code>qmk compile</code> when done. Note this compiles based on the defaults set earlier.<ol> <li>Some sites say to disconnect the cable connecting the two halves, others don't. I had no problem keeping them connected.</li> </ol> </li> <li>If using VIA, make sure you backup your profile at this point.</li> <li>Now run <code>qmk flash</code>. Wait until prompted to hit the reset button.<ol> <li>I only have to hit the reset button Once to get it into bootloader mode to flash.</li> </ol> </li> <li>Disconnect the USB cable and reconnect to the other half.</li> <li>Run it again.</li> <li>Disconnect and reconnect to left half.</li> <li>Open VIA and import your saved layout.</li> <li>Done!</li> </ol>"},{"location":"Technology/Keyboard/#Modifiers%20on%20home%20row","title":"Modifiers on home row","text":"<p>Used the following for modifiers. Note the order is based on how often the key is used as well as what it's used with. See this blog for an extremely detailed write-up.</p> <p>Things have been working pretty good, but even with <code>#define TAPPING_TERM 200</code>, my pinky was still too slow to release sometimes. Since I have the Windows key mapped already and I'm comfortable with it, I just removed it from the mod-tap. I'll work on tapping faster with my pinky, but I use GUI so little it's not a big deal to not have it on the home row at this time. I'll leave the key codes below, however.</p> Full Modifier Name Abbreviation Symbol Shift S \u21e7 Control C \u2388 Alt/Option A \u2387 GUI/Win/Command G \u25c6 <p></p> <pre><code>MT(MOD_LGUI, KC_A), MT(MOD_LALT, KC_S), MT(MOD_LSFT, KC_D), MT(MOD_LCTL, KC_F),\n\nMT(MOD_RCTL, KC_J), MT(MOD_RSFT, KC_K), MT(MOD_RALT, KC_L), MT(MOD_RGUI, KC_SCLN)\n</code></pre>"},{"location":"Technology/Keyboard/#Custom%20Display","title":"Custom Display","text":""},{"location":"Technology/Keyboard/#Links","title":"Links","text":"<ul> <li>QMK Logo Editor</li> <li>Image to CPP</li> <li>How to use the above</li> </ul>"},{"location":"Technology/Keyboard/#WPM","title":"WPM","text":"<p>To get WPM to show up correctly, had to add <code>#define SPLIT_WPM_ENABLE</code> to <code>config.h</code>. Then in <code>oled.c</code> can output the value with <code>oled_write(get_u8_str(get_current_wpm(), '0'), false);</code>. Had to flash both sides before it stopped freaking out.</p> <p>Final readout looks like this:</p> <pre><code>static void print_status_narrow(void) {\n    // Print current mode\n    oled_write_P(PSTR(\"\\n\\n\"), false);\n    oled_write_ln_P(PSTR(\"MODE\"), false);\n    oled_write_P(PSTR(\"\\n\"), false);\n\n    switch (get_highest_layer(layer_state)) {\n        case 0:\n            oled_write_ln_P(PSTR(\"base\"), false);\n            break;\n        case 1:\n            oled_write_ln_P(PSTR(\"alt\"), false);\n            break;\n        default:\n            oled_write_P(PSTR(\"mod\\n\"), false);\n            break;\n    }\n    oled_write_P(PSTR(\"\\n\\n\"), false);\n    oled_write_ln_P(PSTR(\"WPM\"), false);\n    oled_write_P(PSTR(\"\\n\"), false);\n    oled_write(get_u8_str(get_current_wpm(), '0'), false);\n}\n</code></pre>"},{"location":"Technology/Keyboard/#Animation","title":"Animation","text":"<p>Added a cool rocket animation from github. Just add the content between the comment blocks the author added. Set mine to display on the slave side, which needs <code>#define SPLIT_WPM_ENABLE</code> in <code>config.h</code>.</p> <p>To make sure that the animation screen goes dark when the static one does, add <code>#define SPLIT_OLED_ENABLE</code> to <code>config.h</code>.</p>"},{"location":"Technology/Keyboard/#Replace%20Default","title":"Replace Default","text":"<p>Swap out this in <code>oled.c</code>:</p> <pre><code>\u00a0 \u00a0 static const char PROGMEM qmk_logo[] = {\n\u00a0 \u00a0 \u00a0 \u00a0 0x80,0x81,0x82,0x83,0x84,0x85,0x86,0x87,0x88,0x89,0x8a,0x8b,0x8c,0x8d,0x8e,0x8f,0x90,0x91,0x92,0x93,0x94,\n\u00a0 \u00a0 \u00a0 \u00a0 0xa0,0xa1,0xa2,0xa3,0xa4,0xa5,0xa6,0xa7,0xa8,0xa9,0xaa,0xab,0xac,0xad,0xae,0xaf,0xb0,0xb1,0xb2,0xb3,0xb4,\n\u00a0 \u00a0 \u00a0 \u00a0 0xc0,0xc1,0xc2,0xc3,0xc4,0xc5,0xc6,0xc7,0xc8,0xc9,0xca,0xcb,0xcc,0xcd,0xce,0xcf,0xd0,0xd1,0xd2,0xd3,0xd4,0\n\u00a0 \u00a0 };\n\u00a0 \u00a0 oled_write_P(qmk_logo, false);\n}\n</code></pre> <p>To this:</p> <pre><code>\u00a0 \u00a0 static const char PROGMEM qmk_logo[] = {\n        BIG BLOCK OF BYTECODE HERE\n\u00a0 \u00a0 };\n  oled_write_raw_P(qmk_logo, sizeof(qmk_logo));\n}\n</code></pre>"},{"location":"Technology/Keyboard/#Discord%20Chat","title":"Discord Chat","text":"<p>From this discussion: https://discord.com/channels/440868230475677696/440868230475677698/988633092124205096</p> <p>There are some distinction here. The default <code>qmk_logo[]</code>content are actually reference to the image stored in <code>glcdfont.c</code> file. 0x80 refers to the start of the image in that file. Hence you'll use <code>oled_write_P</code> function with that variable syntax. Now that you intend to generate your own image to store inside your own array, that array content is the image itself, not a reference. So you'll need to use <code>oled_write_raw_P</code> to render that array, with a different variable syntax.</p> <p>More specifically: oled_write(_P) writes out blocks, aka \"characters\" from the oled font file. oled_write_raw(_P) writes out the actual pixel values (the \"raw\" values) to be rendered to the screen.</p>"},{"location":"Technology/Keyboard/#Layers","title":"Layers","text":"<p>Here's some examples from Keebio.</p> <ul> <li><code>LALT(KC_TAB)</code> - Sends Alt-Tab</li> <li><code>LCTL(KC_C)</code> - Sends Ctrl-C</li> <li><code>LGUI(KC_C)</code> - Sends Cmd-C or Win-C</li> <li><code>LSFT(LCTL(KC_END))</code> - Sends Shift-Ctrl-End</li> <li><code>MO(1)</code> - Momentarily turn on layer 1</li> <li><code>LCA(KC_DEL)</code> - Sends Ctrl-Alt-Del</li> <li><code>MT(MOD_RSFT, KC_ENT)</code> - Sends Shift if held, Enter if tapped</li> </ul>"},{"location":"Technology/Keyboard/#MOlayer","title":"MO(layer)","text":"<p>Most commonly used layer keycode, as this is basically the equivalent to an <code>Fn</code> key. This momentarily activates the desired layer while you are holding down the key. Once released, the keyboard goes back to its original layer.</p>"},{"location":"Technology/Keyboard/#TGlayer","title":"TG(layer)","text":"<p>Toggles a layer on and off. Similar to Num Lock.</p>"},{"location":"Technology/Keyboard/#DFlayer","title":"DF(layer)","text":"<p>This turns on and off your base layer. Most folks usually have their alphas, but if you're reserving your keyboard for gaming, you can use this to maintain a custom game layer to remain active. Game on, friends!</p>"},{"location":"Technology/Keyboard/#TOlayer","title":"TO(layer)","text":"<p>This turns on one layer. BUT! Be aware this doesn't toggle back, so you need to program a key on this layer to get yourself back. Or be stuck in Kansas. Your choice.</p>"},{"location":"Technology/Keyboard/#OSLlayer","title":"OSL(layer)","text":"<p>This temporarily activates a layer until you press the next key. OSL, standing for \"one-shot layer\". This is generally if you want to do one thing and then jump back to what you were doing before without having to hold down the layer key.</p>"},{"location":"Technology/Keyboard/#TTlayer","title":"TT(layer)","text":"<p>Smush MO and TG together and you get this. holding a key down activates the layer and it releases the layer as the key does. You can configure how many times it needs to be pressed to turn the layer on or off.</p>"},{"location":"Technology/Keyboard/#Encoders","title":"Encoders","text":"<p>Note</p> <p>The below covers the older style of use encoders, using Callbacks. The newer way (I'm using) is an Encoder Map. Details here.</p> <p>For a list of supported keys, look here.</p> <p></p>"},{"location":"Technology/Keyboard/#Correct%20Jumping","title":"Correct Jumping","text":"<p>Initially the keyboard jumped around with the encoders more than I wanted. Fixed by setting the resolution to 4 in <code>info.json</code> from the value 2 it was set at.</p> <pre><code>    \"encoder\": {\n        \"rotary\": [\n            {\"pin_a\": \"F5\", \"pin_b\": \"F4\", \"resolution\": 4}\n        ]\n    },\n    \"split\": {\n        \"soft_serial_pin\": \"D2\",\n        \"encoder\": {\n            \"right\": {\n                \"rotary\": [\n                    {\"pin_a\": \"F4\", \"pin_b\": \"F5\", \"resolution\": 4}\n</code></pre>"},{"location":"Technology/Keyboard/#Audio%20Control","title":"Audio Control","text":"<p>Simple but effective, controlling audio is what most people will do with at least one of their encoders.</p> <pre><code>if (clockwise) {  \n  tap_code(KC_VOLU);  \n} else {  \n  tap_code(KC_VOLD);  \n}\n</code></pre>"},{"location":"Technology/Keyboard/#Scrolling","title":"Scrolling","text":"<p>There are many ways to scroll. You can use the mousewheel scroll keycodes, or simply arrow up or down a few times. My preferred way is to use Page Up and Page Down, as I find it faster and more reliable for my needs.</p> <pre><code>if (clockwise) {  \n  tap_code(KC_PGDN);  \n} else {  \n  tap_code(KC_PGUP);  \n}\n</code></pre>"},{"location":"Technology/Keyboard/#Tabbing","title":"Tabbing","text":"<p>Moving through your browser tabs is easy enough with Control + Tab and Control + Shift + Tab, but you can also do it with an encoder.</p> <pre><code>if (clockwise) {  \n  tap_code16(C(KC_TAB));  \n} else {  \n  tap_code16(S(C(KC_TAB)));  \n}\n</code></pre>"},{"location":"Technology/Keyboard/#Window%20Movement","title":"Window Movement","text":"<p>Like with tabs, you can also move through applications. In Windows, you can do this with Alt + Tab and Alt + Shift + Tab.</p> <p>The code sample below is a modified version of the Alt Tab with a macro version listed in the QMK documentation about Macros.</p> <p>Alt Tab with an encoder involves adding three pieces of code. Add the first bit at the top of your <code>keymap.c</code>:</p> <pre><code>bool is_alt_tab_active = false;  \nuint16_t alt_tab_timer = 0;\n</code></pre> <p>Second, place this piece of code in your encoder code. It will start holding Alt if it's not holding it yet, and send a tab for each click you turn on the encoder.</p> <pre><code>if (clockwise) {  \n  if (!is_alt_tab_active) {  \n    is_alt_tab_active = true;  \n    register_code(KC_LALT);  \n  }  \n  alt_tab_timer = timer_read();  \n  tap_code16(KC_TAB);  \n} else {  \n  if (!is_alt_tab_active) {  \n    is_alt_tab_active = true;  \n    register_code(KC_LALT);  \n  }  \n  alt_tab_timer = timer_read();  \n  tap_code16(S(KC_TAB));  \n}\n</code></pre> <p>And last, the part that makes it all work. This'll release Alt for you if you haven't send a tab yet in a second. You can change the 1250 part (in milliseconds) to be higher or lower if you prefer. If <code>matrix_scan_user</code> already exists, add the body of the function below to the already existing function:</p> <pre><code>void matrix_scan_user(void) {  \n  if (is_alt_tab_active) {  \n    if (timer_elapsed(alt_tab_timer) &gt; 1250) {  \n      unregister_code(KC_LALT);  \n      is_alt_tab_active = false;  \n    }  \n  }  \n}  \n</code></pre>"},{"location":"Technology/Keyboard/#History%20Scrubbing","title":"History Scrubbing","text":"<p>This will perform Control + Z when you turn the encoder clockwise, and Control + Y when turning it counterclockwise. With this, you can easily \"scroll\" through the history when editing a document. In some Adobe products, Control + Shift + Z is used for undo. You can hold Shift while turning counterclockwise to undo in that case.</p> <pre><code>if (clockwise) {  \n  tap_code16(C(KC_Y));  \n} else {  \n  tap_code16(C(KC_Z));  \n}\n</code></pre>"},{"location":"Technology/Keyboard/#Scrolling%20Horizontally%20by%20Word","title":"Scrolling Horizontally by Word","text":"<p>This will perform Control + Right Arrow when you turn the encoder clockwise, and Control + Left Arrow when turning it counterclockwise. If you hold shift while turning the encoder, you'll be able to select words while the cursor moves!</p> <pre><code>if (clockwise) {  \n  tap_code16(C(KC_RGHT));  \n} else {  \n  tap_code16(C(KC_LEFT));  \n}\n</code></pre>"},{"location":"Technology/Keyboard/#Scrolling%20Through%20Search%20Results","title":"Scrolling Through Search Results","text":"<p>When you search for something in your text editor, often you'll also have shortcuts to move to the next or previous result. In Visual Studio Code, these are F3 and Shift + F3. Here's how to do that on an encoder:</p> <pre><code>if (clockwise) {  \n  tap_code(KC_F3);  \n} else {  \n  tap_code16(S(KC_F3));  \n}\n</code></pre>"},{"location":"Technology/Keyboard/#VIA%20JSON","title":"VIA JSON","text":"<pre><code>{\n  \"name\": \"Sofle\",\n  \"vendorProductId\": 4231135879,\n  \"macros\": [\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\"\n  ],\n  \"layers\": [\n    [\n      \"KC_GRV\",\n      \"KC_1\",\n      \"KC_2\",\n      \"KC_3\",\n      \"KC_4\",\n      \"KC_5\",\n      \"KC_ESC\",\n      \"KC_Q\",\n      \"KC_W\",\n      \"KC_E\",\n      \"KC_R\",\n      \"KC_T\",\n      \"KC_TAB\",\n      \"KC_A\",\n      \"MT(MOD_LALT,KC_S)\",\n      \"MT(MOD_LSFT,KC_D)\",\n      \"MT(MOD_LCTL,KC_F)\",\n      \"KC_G\",\n      \"KC_LSFT\",\n      \"KC_Z\",\n      \"KC_X\",\n      \"KC_C\",\n      \"KC_V\",\n      \"KC_B\",\n      \"KC_LCTL\",\n      \"KC_LALT\",\n      \"KC_LGUI\",\n      \"MO(1)\",\n      \"KC_ENT\",\n      \"LAG(KC_K)\",\n      \"KC_MINS\",\n      \"KC_0\",\n      \"KC_9\",\n      \"KC_8\",\n      \"KC_7\",\n      \"KC_6\",\n      \"KC_BSPC\",\n      \"KC_P\",\n      \"KC_O\",\n      \"KC_I\",\n      \"KC_U\",\n      \"KC_Y\",\n      \"KC_QUOT\",\n      \"KC_SCLN\",\n      \"MT(MOD_LALT | MOD_RALT,KC_L)\",\n      \"MT(MOD_LSFT | MOD_RSFT,KC_K)\",\n      \"MT(MOD_LCTL | MOD_RCTL,KC_J)\",\n      \"KC_H\",\n      \"KC_APP\",\n      \"KC_SLSH\",\n      \"KC_DOT\",\n      \"KC_COMM\",\n      \"KC_M\",\n      \"KC_N\",\n      \"KC_DOWN\",\n      \"KC_UP\",\n      \"KC_RGHT\",\n      \"KC_LEFT\",\n      \"KC_SPC\",\n      \"KC_PSCR\"\n    ],\n    [\n      \"LCA(KC_DEL)\",\n      \"KC_F1\",\n      \"KC_F2\",\n      \"KC_F3\",\n      \"KC_F4\",\n      \"KC_F5\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_PGUP\",\n      \"KC_UP\",\n      \"KC_PGDN\",\n      \"KC_NO\",\n      \"KC_TRNS\",\n      \"KC_NO\",\n      \"KC_LEFT\",\n      \"KC_DOWN\",\n      \"KC_RGHT\",\n      \"KC_DEL\",\n      \"KC_TRNS\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_TRNS\",\n      \"KC_TRNS\",\n      \"KC_TRNS\",\n      \"KC_TRNS\",\n      \"KC_TRNS\",\n      \"KC_MUTE\",\n      \"KC_EQL\",\n      \"KC_F10\",\n      \"KC_F9\",\n      \"KC_F8\",\n      \"KC_F7\",\n      \"KC_F6\",\n      \"KC_BSLS\",\n      \"KC_RBRC\",\n      \"KC_LBRC\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_TRNS\",\n      \"KC_TRNS\",\n      \"KC_TRNS\",\n      \"KC_TRNS\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_END\",\n      \"KC_HOME\",\n      \"KC_PGDN\",\n      \"KC_PGUP\",\n      \"KC_TRNS\",\n      \"KC_HOME\"\n    ],\n    [\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\"\n    ],\n    [\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_TRNS\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_NO\",\n      \"KC_TRNS\",\n      \"KC_NO\",\n      \"KC_NO\"\n    ]\n  ],\n  \"encoders\": [\n    [\n      [\"KC_PGDN\", \"KC_PGUP\"],\n      [\"KC_VOLU\", \"KC_VOLD\"],\n      [\"KC_PGUP\", \"KC_PGDN\"],\n      [\"KC_PGUP\", \"KC_PGDN\"]\n    ],\n    [\n      [\"KC_RGHT\", \"KC_LEFT\"],\n      [\"KC_DOWN\", \"KC_UP\"],\n      [\"KC_RGHT\", \"KC_LEFT\"],\n      [\"KC_RGHT\", \"KC_LEFT\"]\n    ]\n  ]\n}\n</code></pre>"},{"location":"Technology/PC%20Build/","title":"PC Build","text":""},{"location":"Technology/PC%20Build/#Case","title":"Case","text":""},{"location":"Technology/PC%20Build/#NR200","title":"NR200","text":"<ul> <li>185mm wide</li> <li>274mm tall</li> <li>360mm deep</li> </ul>"},{"location":"Technology/PC%20Build/#3000D","title":"3000D","text":"<ul> <li>230mm wide</li> <li>466mm tall</li> <li>462mm deep</li> </ul>"},{"location":"Technology/PC%20Build/#4000D","title":"4000D","text":"<ul> <li>230mm wide</li> <li>466mm tall</li> <li>453mm deep</li> </ul>"},{"location":"Technology/PC%20Build/#Components","title":"Components","text":""},{"location":"Technology/PC%20Build/#GPU","title":"GPU","text":"<ul> <li>EVGA GeForce RTX 3090 FTW3 ULTRA GAMING</li> <li>24G-P5-3987-KR, 24GB GDDR6X, iCX3 Technology, ARGB LED, Metal Backplate<ul> <li>Height: 5.38 in (136.75mm)</li> <li>Length: 11.81 in (300mm)</li> <li>Width: 2.75 Slots</li> </ul> </li> <li>Boost Clock: 1800 MHz</li> <li>Memory Clock: 19500 MHz Effective</li> <li>TDP: 420W</li> <li>CUDA Cores: 10496</li> <li>Bus Type: PCIe 4.0</li> <li>Memory Detail: 24576MB GDDR6X</li> <li>Memory Bit Width: 384 Bit</li> <li>Memory Bandwidth: 936 GB/s</li> <li>2nd Gen Ray Tracing Cores</li> <li>3rd Gen Tensor Cores</li> <li>PCI Express Gen 4</li> <li>Microsoft DirectX 12 Ultimate</li> <li>GDDR6X Graphics Memory</li> <li>NVIDIA DLSS</li> <li>NVIDIA GeForce Experience</li> <li>NVIDIA G-SYNC</li> <li>NVIDIA GPU Boost</li> <li>NVIDIA NVLink (SLI-Ready)</li> <li>Game Ready Drivers</li> <li>Vulkan RT API, OpenGL 4.6</li> <li>DisplayPort 1.4a</li> <li>Supports 4K 120Hz HDR, 8K 60Hz HDR and Variable Refresh Rate as specified in HDMI 2.1</li> <li>HDCP 2.3</li> <li>VR Ready</li> <li>750 Watt or greater power supply.</li> <li>PCI Express, PCI Express 2.0 or PCI Express 3.0 compliant motherboard with one graphics slot.</li> <li>Three available 8-pin or 6+2pin PCIe power dongles</li> <li>Windows 11, Windows 10, Windows 7</li> </ul>"},{"location":"Technology/PC%20Build/#PSU","title":"PSU","text":"<p>Cooler Master V850 SFX Gold (MPY-8501-SFHAGV)</p> Item Details ATX Version SFX 12V Ver. 3.42 PFC Active PFC Input Voltage 100-240V Input Current 12-6A Input Frequency 50-60Hz Dimensions (L x W x H) 100 x 125 x 63.5 mm Fan Size 92mm Fan Bearing FDB Efficiency 90% @ Typical Load 80 PLUS Rating 80 PLUS Gold ETA Rating Gold LAMBDA Rating Standard+ ErP 2014 Lot 3 Yes Operating Temperature 0-50\u00b0C Power Good Signal 100 - 500 ms Hold Up Time 16ms MTBF &gt;100,000 Hours Protections OVP, OPP, SCP, OCP, UVP, OTP, Surge and Inrush Protection Regulatory TUV, cTUVus, CE, BSMI, FCC, CCC, EAC, RCM, KCC, CB, UKCA ATX 24 Pin Connectors 1 EPS 4+4 Pin Connectors 1 EPS 8 Pin Connector 1 SATA Connectors 8 Peripheral 4 Pin Connectors 4 PCI-e 6+2 Pin Connectors 4 80 Plus Gold Modular Full Modular"},{"location":"Technology/Pixel%206a/","title":"Pixel 6a","text":""},{"location":"Technology/Pixel%206a/#Wired%20Video%20Output","title":"Wired Video Output","text":"<p>Per Google, it's possible to project using a wired dock. Seems you need a DisplayLink certified/compatible dock. Download DisplayLink Presenter. After you connect to an appropriate adapter, you'll get a popup asking to connect and \"record\" screen. Click yes, and you're done!</p> <p>Danger</p> <p>SecondScreen sort of works. On my phone it change the PHONE'S resolution and DPI, which made it hard to interact with. USE EXTREME CAUTION DOING THIS.</p> <p>Now if you want it to look more like a native desktop experience, you'll need a few other things. A way to change the resolution/DPI, and a launcher that looks more desktop-y. Download SecondScreen to take care of the first part. After install, install ADB on your pc and run the command <code>adb shell pm grant com.farmerbb.secondscreen.free android.permission.WRITE_SECURE_SETTINGS</code> while the phone is plugged in. You can search on the web how to install ADB and use it. I had to reset the app once, but after that it sort of worked. It asked for a restart and changed the PHONE's resolution and DPI, which is a little scary as you may not be able to unlock it, but I was able to with a mouse.</p> <p>Fyi</p> <p>My current monitor resolution is around ~110 ppi</p>"},{"location":"Technology/Programming/","title":"Programming","text":""},{"location":"Technology/Programming/#Git","title":"Git","text":""},{"location":"Technology/Programming/#Shrink%20local%20files","title":"Shrink local files","text":"<ul> <li>To shrink local .git folder, run <code>git repack -a -d -f --depth=250 --window=250</code></li> </ul>"},{"location":"Technology/Programming/#Remove%20all%20history","title":"Remove all history","text":"<p>Make sure there are no protection rules under Settings &gt; Branches first.</p> <ol> <li>Checkout</li> </ol> <p><code>git checkout --orphan latest_branch</code></p> <ol> <li>Add all the files</li> </ol> <p><code>git add -A</code></p> <ol> <li>Commit the changes</li> </ol> <p><code>git commit -am \"commit message\"</code></p> <ol> <li>Delete the branch</li> </ol> <p><code>git branch -D main</code></p> <ol> <li>Rename the current branch to main</li> </ol> <p><code>git branch -m main</code></p> <ol> <li>Finally, force update your repository</li> </ol> <p><code>git push -f origin main</code></p>"},{"location":"Technology/Programming/#Python","title":"Python","text":""},{"location":"Technology/Programming/#Setup","title":"Setup","text":"<ol> <li>Navigate to folder where you want to place files.</li> <li>Clone repo with <code>git clone https://github.com/URL/PROJECT.git</code></li> <li>Create a virtual environment with <code>python -m venv venv</code></li> <li>Activate with <code>.\\venv\\Scripts\\Activate.ps1</code></li> <li>Install requirements with <code>pip install -r requirements.txt</code></li> <li>Deactivate when done with <code>deactivate</code></li> <li>If needed (and assuming our virtual environment is in a directory called <code>venv</code>), <code>rm -r venv</code>.</li> </ol>"},{"location":"Technology/Programming/#Tips","title":"Tips","text":"<ol> <li>Don\u2019t install the latest major version of Python</li> <li>Use only the python.org installer on Windows and Mac, or official repositories on Linux.</li> <li>Never install or run anything outside of a virtual environment</li> <li>Limit yourself to the basics: \u201cpip\u201d and \u201cvenv\u201d</li> <li>If you run a command, use \u201c-m\u201d</li> <li>When creating a virtual environment, be explicit about which Python you use</li> <li>I would recommend to <code>python -m venv</code> and that's all.</li> </ol> <p>The <code>-m</code> flag is, at its simplest, a means to execute python scripts from the command line by using modulenames rather than filenames. The real power of <code>-m</code>, however, is in its ability to combine the power of <code>import</code> statements (e.g., support for explicit relative imports and automatic package <code>__init__</code> evaluation) with the convenience of the command line.</p>"},{"location":"Technology/Proxmox/","title":"Proxmox","text":"<p>Followed this guide to migrate Home Assistant for a Raspberry Pi 3b to a HP Thin Client.</p>"},{"location":"Technology/Proxmox/#Tips","title":"Tips","text":"<ul> <li>Download the latest Proxmox VE ISO Installer and save it, burn it to a USB with something like Balena Etcher.</li> <li>In the BIOS of the device, make sure...<ul> <li>Secure Boot is disabled </li> <li>Legacy Boot is enabled </li> <li>Virtualization Technology is enabled</li> </ul> </li> <li>Used the console installer and not the GUI. The GUI one failed twice by getting stuck at different random locations. Console was fine.</li> </ul>"},{"location":"Technology/Windows/","title":"Windows","text":""},{"location":"Technology/Windows/#Set%20all%20folders%20to%20same%20style","title":"Set all folders to same style","text":"<p>Also seems to get rid of the <code>Group By</code> setting that keeps applying itself to the Downloads folder.</p> <ol> <li>Download WinSetView.</li> <li>Extract.</li> <li>Open and set the style to what you'd like, then Submit.</li> </ol>"},{"location":"Technology/Windows/#Utilities","title":"Utilities","text":"<ul> <li>Chocolately</li> <li>Everything</li> <li>VoiceMeeter</li> <li>WizTree</li> </ul>"},{"location":"Travel/Hikes/","title":"Hikes","text":""},{"location":"Travel/Hikes/#Day%20Hikes","title":"Day Hikes","text":"<ul> <li>The High Divide Trail \u2013 Seven Lakes Basin Loop, 19 miles, can do in a day</li> <li>Chain Lakes</li> <li>Sahale Glacier Camp is the spot; you get there via the Cascade Pass / Sahale Arm Trail.</li> <li>Mt. Defiance</li> <li>Devil's Rest</li> </ul>"},{"location":"Travel/Places%20To%20Visit/","title":"Places To Visit","text":""},{"location":"Travel/Places%20To%20Visit/#Alaska","title":"Alaska","text":"<ul> <li>Must have software for public camping land</li> <li>Denali, AK</li> <li>Glacier NP</li> <li>Banff</li> <li>Moraine Lake (in Banff)</li> <li>Homer Beach</li> <li>Tombstone Park</li> <li>Salmon Glacier</li> </ul>"},{"location":"Travel/Places%20To%20Visit/#New%20Mexico","title":"New Mexico","text":"<ul> <li>Five points Vista in Lincoln NF</li> </ul>"},{"location":"Travel/Places%20To%20Visit/#Utah","title":"Utah","text":"<ul> <li>Balanced Rock</li> <li>Temple of the Sun</li> <li>Sunrise Point</li> </ul>"},{"location":"Travel/Places%20To%20Visit/#Hamburg","title":"Hamburg","text":"<ul> <li>Elbphilharmonie, concert hall</li> </ul>"},{"location":"Vehicles/Motorcycle/","title":"Motorcycle","text":""},{"location":"Vehicles/Motorcycle/#Part%20Numbers","title":"Part Numbers","text":"<ul> <li>2x 32717658947 (weights)</li> <li>1x 13537669776 (fuel filter)</li> <li>15W-50 is BMW oil</li> </ul>"},{"location":"Vehicles/Motorcycle/#Proper%20Riding%20Techniques","title":"Proper Riding Techniques","text":""},{"location":"Vehicles/Motorcycle/#Turning","title":"Turning","text":"<p>The rider will enter into a continuous turn, creating an unbroken circle, riding at approximately 5 mph. As each technique is employed, the rider will note that the radius of the circle tightens.</p>"},{"location":"Vehicles/Motorcycle/#Stage%201%20The%20Novice%20Turn","title":"Stage 1: The Novice Turn","text":"<p>This is a typical entry-level student turning technique. The bike is steered into a turning position, but the rider remains completely neutral; usually out of fear that any shift of weight will lead to slipping on whatever godforsaken Teflon they find themselves traversing. This technique limits the rider to a very large turning radius, which can be tightened a bit by feathering the clutch and throttle. Careful though: Too slow, and the bike cannot be leaned at all. Remember to grip the bike with your legs, so that your hands are left only to steer and actuate the controls. (Bar risers, aftermarket footpegs and Rotating the Handlebars can help to relax your grip).</p>"},{"location":"Vehicles/Motorcycle/#Stage%202%20Shifting%20Weight","title":"Stage 2: Shifting Weight","text":"<p>While continuing the circle, the rider shifts their hip and shoulder weight toward the outside of the turn, leaning away from the motorcycle. The inside foot becomes light on the peg, while the outside foot bares nearly all the weight of the rider. This offers 2 benefits: 1. The riders body mass acts as a counterweight against that of the bike. This partially \u2019neutralizes\u2019 the collective weight of rider and machine, giving the motorcycle a lighter, more manageable feel. 2. The shift in weight helps apply traction, as it places essential mass directly above the grip patch of the tire. This is one of the most counter-intuitive elements of Adventure Riding, since for most people the idea of \u2018leaning out\u2019 of a turn is completely foreign. We simply don\u2019t employ this technique anywhere else, at least not that we\u2019re aware of. But when done properly the machine will become more stable, and the turn radius will tighten.</p>"},{"location":"Vehicles/Motorcycle/#Stage%203%20The%20Toe%20Turn","title":"Stage 3: The Toe Turn","text":"<p>Now the rider rotates their outside foot, lifting it from the peg and reapplying at a 45 degree (ish) angle. This allows the rider to press a knee into the tank and rotate their body mass even further from the machine. The additional counter-weighting allows the bike to be leaned more heavily into the turn, tightening the steering and narrowing the radius even further. The legs are \u2018squeezed together\u2019 in order to hold on to the bike, and lessen the grip on the handlebars. Bonus: Lift your inside Leg. Once the rider becomes comfortable turning their toes and leaning away from the machine, the inside foot will become completely unhindered by rider weight. In this instance, the foot can be completely removed from the inside peg. The rider then hooks the inside of their leg against the seat edge, squeezing for grip and leaning further still from the machine. Fair Warning: This technique requires a leap of faith, as the motorcycle has the potential to lean further than most have ever dared go (without falling over, that is), and the turning radius so tight that the handlebars will begin to bump off their steering limit. This should only be employed after the rider is comfortable with the other turning drills. Once these techniques are mastered, riders will find use for all stages in a real world setting. Stage 1 works best for mild turns on high-traction off-road riding. Stages 2 and 3 become essential when the turns become tight or technical, or both! Just remember; like all things, turning technique is a perishable skill, especially when in the learning process. So keep at it and don\u2019t get discouraged, even the most accomplished riders have to start somewhere! Turning off-road is something that should be learned at the slowest pace possible. Only then can you understand how tight you can turn your bike when using the right technique. The hardest thing for me to learn was not leaning into the corner, when either standing or sitting.</p> <p>As road riders, we want to lean our bodies into the corner to keep the bike more upright, which increases tire contact/traction. In the dirt, the tire design works better by leaning the bike into corners, while you remain standing or sitting upright. This allows the knobby or big tread tires to dig into the dirt and provide more traction.</p> <p>Start learning with slow turns. Remember to always weight the outside peg, and keep your shoulders square to the bars.  Began left-hand circles at a slow pace. While standing, keep your body upright, and shoulders square to the bars.</p> <p>Keep your shoulders square, even if you have your bars locked in the tightest turning position. Do this by turning your upper body in the direction you are going. Some people only twist their upper bodies. Others, including me, like to move the entire body, including the feet slightly, or whatever is allowed due to space constraints, in that direction.</p> <p>Continuing with this left turn, keep all your weight on your right leg. While practicing, I\u2019ll also take my left foot completely off the peg, making sure all the weight is on the outside. Keep practicing and eventually you\u2019ll be able to lock the bars and complete the tightest turns your bike possibly allows. Oh, and when learning, plan on dropping your bike a few times; don\u2019t worry, this is normal.</p> <p>Practice slow turning in both directions for the rest of your riding career\u2014especially at the beginning of a season. The slower the better; you\u2019ll improve your balance over time.</p> <p>As for fast corners, get all braking completed before turning the bike; trail braking (keeping pressure on at start of turn) is great on the street, but will wipe you out in the dirt. Keep the weight a bit forward for added front-tire traction, and initiate turn-in with the bike, not the body (stay upright!).</p> <p>Based on speed, this is where things can get fun. Initiate turn, point, and get on the throttle to slide the rear tire and finish the turn. Another advanced technique is locking the rear tire to help the bike initiate the turn with a slide\u2014extreme fun.</p> <p>Stop with Front; Steer with Rear Brake </p> <p>There\u2019s still much confusion out there concerning braking off-road. I discussed this with Baja 1000 winner and Dakar podium finisher Jimmy Lewis at the Touratech Rally East this past August. You still need the front brake to stop.</p> <p>The front brake is for stopping, and the rear is for steering. Rely on the front brakes for slowing/stopping, and use the rear to steer the bike, such as skidding the rear to point the bike into whatever direction is needed.</p> <p>Even in the dirt, think of the braking bias as 80 percent front/20 percent rear. Learn the threshold of locking up the front tire, and you\u2019ll be able to brake harder than you\u2019ve ever imagined.</p>"},{"location":"Vehicles/Tacoma/","title":"Tacoma","text":""},{"location":"Vehicles/Tacoma/#GFC","title":"GFC","text":""},{"location":"Vehicles/Tacoma/#Foam%20Density","title":"Foam Density","text":"<ul> <li>For any one that wants the exact specs of the stock foam it's a 2# polyurethane 35 ILD. If you want softer get a lower ILD but don't go too low or you'll just bottom out. Higher if you want more firm.</li> <li>50\" x 90\" sleeping platform</li> <li>If opening is 13\", panel is 50\"x12\"</li> <li>50\"x90\" mattress (76\"), actual 48\" wide pad</li> <li>Another source says 2.8 lb density.</li> </ul>"},{"location":"Vehicles/Tacoma/#Dimensions","title":"Dimensions","text":"<ul> <li>Sleeping platform: 50\u201d x 90\u201d interior for Mid Size Trucks, 53\u201d x 93\u201d exterior (excluding corner brackets)</li> <li>56\u201d x 90\u201d for Full Size Trucks.</li> <li>1\u201d of space between mattress &amp; roof panel when closed, 6\u201d thick closed (exterior)</li> <li>Interior height (from truck bed floor): 96\u201d</li> <li>Canopy/cargo space (from truck bed floor): 41\u201d</li> <li>Weight: 275-300 lbs (depending on vehicle)</li> </ul>"},{"location":"Vehicles/Tacoma/#Construction","title":"Construction","text":"<ul> <li>DOM tube space frame, in orange or forge gray powder coat</li> <li>0.080\u201d 5052 aluminum sheet doors, construction details</li> <li>Attachment method to truck bed</li> <li>Panel attachment to space-frame</li> </ul>"},{"location":"Vehicles/Tacoma/#Electronics","title":"Electronics","text":""},{"location":"Vehicles/Tacoma/#Headunit","title":"Headunit","text":"<ul> <li>Ideal resolution for screen is 1280 x 679</li> <li>28 pin harness: https://www.tacomaworld.com/threads/28-pin-head-unit-wiring-harness-adapter-and-oem-style-camera-gps-switches.458293/</li> <li>If ebrake light comes on, cut pin 15: https://www.tacomaworld.com/threads/3rd-gen-tacoma-front-rear-camera-navigation-bypass-homelink-smartphone-mirroring-mod.473033/page-6#post-15365053</li> <li>If no video going at speed, might need to add switch to pin 17: https://www.tacomaworld.com/threads/3rd-gen-tacoma-front-rear-camera-navigation-bypass-homelink-smartphone-mirroring-mod.473033/page-5#post-15223124</li> </ul>"},{"location":"Vehicles/Tacoma/#Standards","title":"Standards","text":"<ul> <li>GPT wire (SAE J1128-GPT) - General Purpose Wire rated -40F to 176F (Generic wire found in most auto parts stores)</li> <li>GXL (SAE J1128-GXL) - Thin insulation, Automotive Cross-link Wire rated -49F to 257F</li> <li>TXL (SAE J1128-TXL) - Extra thin insulation, Automotive Cross-link Wire rated -49F to 257F</li> </ul>"},{"location":"Vehicles/Tacoma/#Parts","title":"Parts","text":""},{"location":"Vehicles/Tacoma/#Wipers","title":"Wipers","text":"<p>85212-0E050 - Blade, Wiper RH 85222-04040 - Blade, Wiper LH 85214-0E140 - Insert 85214-04030 - Insert</p>"},{"location":"Vehicles/Tacoma/#Seat%20Covers","title":"Seat Covers","text":"<p>Covercraft, but maybe get these next time.</p>"},{"location":"Vehicles/Tacoma/#Road%20Shower","title":"Road Shower","text":"<p> - Dimensions: 56.5\" x 7\" x 5\". - Slot Channel is 55\" long and the mounting bolts can be moved over this entire length. - Holds 5 gallons of water. - Empty Weight: 15 lbs. Full weight: 55 lbs. - Boxed weight: 19 lbs. Box size: 9\" x 9\" x 58\". - Powder Coated Aluminum 1/10\" thick walls. - Pressure relief valves opens at 22 PSI. - Hose length is 55\". - Mounting carriage bolts take a 1/2\" nut. Nylock nuts included. 1/2\" wrench needed. - Elbow is 1/2\"NPT thread x Male US GHT (Garden Hose Thread). - Female hose end is GHT thread. Male hose end is GHT. - Hose is 5/8\" ID food grade hose such as used in the brewing industry. - Intake air valve is Shrader valve. Road Shower 2 uses a 1/4\" NPT thread. It is very tough.</p>"},{"location":"Vehicles/Tacoma/#Repair","title":"Repair","text":"<p>All from a 2nd gen forum, but probably close for 3rd: https://www.tacomaworld.com/threads/complete-list-of-tools-sockets-and-wrenches-for-2nd-gen-tacoma.158302/</p>"},{"location":"Vehicles/Tacoma/#Metric%20sockets","title":"Metric sockets","text":"<ul> <li>5.5 mm, blower motor resistor screws.</li> <li>8 mm, Running boards if you have them.</li> <li>10 mm, Center console bolts, Stereo, engine cover, tail lights, interior</li> <li>11 mm, Battery terminal</li> <li>12 mm, Skid plate bolts, e-brake mounting bracket</li> <li>13 mm, Tube steps if you have them.</li> <li>14 mm, Transmission drain plug, Oil drain plug and Drive shaft bolts, exhaust system, center support bearing, Radiator bolts, and many, many more!</li> <li>16 mm, Deep socket for spark plugs (16mm is virtually same as 5/8\"; If you carry a 5/8 dedicated spark plug socket you don't need the 16mm)</li> <li>17 mm, Power steering, Sway Bar, Cab mount nuts, leaf spring bolts, nuts.</li> <li>19 mm, Lower Control Arm bolts and nuts., Deep socket for PCV valve</li> <li>21 mm, Wheel Lug nuts</li> <li>22 mm, Crank pulley bolt, Alternator</li> <li>24 mm, Transfer case &amp; Rear diff, drain and fill plugs</li> <li>27 mm, shallow socket for reverse switch on manual transmissions</li> <li>30 mm, Rear diff flange</li> <li>35 mm, front Axle nut</li> </ul>"},{"location":"Vehicles/Tacoma/#SAE%20sockets","title":"SAE sockets","text":"<ul> <li>7/32 socket for Blower Motor Resistor screws, 5.5mm works too.</li> </ul>"},{"location":"Vehicles/Tacoma/#Metric%20Hex%20Sockets%20Same%20as%20Allen%20Keys","title":"Metric Hex Sockets (Same as Allen Keys)","text":"<ul> <li>5 mm, Seat, transmission overflow plug</li> <li>6 mm, Suspension, Front Axle</li> <li>8 mm, 1GR-FE ENGINE CONTROL SYSTEM</li> <li>10 mm, Front Diff fill and drain plug, 1GR-FE ENGINE CONTROL SYSTEM</li> <li>12 mm, Front Diff Removal</li> </ul>"},{"location":"Vehicles/Tacoma/#Torx%20Sockets","title":"Torx Sockets","text":"<ul> <li>T20, Audio / Visual</li> <li>T25, mirrors</li> <li>T30, Steering Column, SRS, Wiper and Wahser, Seat, tailgate bolts</li> <li>T40, Bed D-Rings</li> <li>T55, Bed bolts</li> </ul>"},{"location":"Vehicles/Tacoma/#External%20%20Interior%20%20Female%20Torx%20Sockets","title":"External / Interior / Female Torx Sockets","text":"<ul> <li>E7 Torx socket to remove the 2 studs from the intake manifold</li> <li>E14 Torx (diff removal)</li> </ul>"},{"location":"Vehicles/Tacoma/#Other","title":"Other","text":"<ul> <li>Drive shaft bolts are M11 x 1.0 x 30mm</li> <li>Toyota uses 7/16-20 SAE fine thread for seat belt bolt hardware if your shopping for replacements.</li> <li>10 mm flare nut wrench (brake lines)</li> <li>(2) M8 x 1.25 bolts (Needed to remove the rear brake drums, need to be at least an inch and a half long) YOU CAN USE THE BOLTS THAT HOLD THE FACTORY SKID PLATE ON TO DO THIS. THEY WORK GREAT.</li> <li>Bi-hexagon Wrench 10 mm, 1GR-FE ENGINE CONTROL SYSTEM</li> <li>Straight Hexagon Wrench 14 mm, 1GR-FE ENGINE MECHANICAL</li> <li>Oil Filter wrench</li> <li>5/8\" Spark Plug Socket or 16mm deep socket will also work for spark plugs.</li> <li>Torque wrench</li> <li>Breaker Bar</li> <li>Large and Small pair of adjustable pliers</li> <li>Long Needle nose pliers</li> <li>Knife or box cutter</li> <li>Long 8\" screw driver</li> <li>Assorted ratchet extensions 3\", 6\" and 8\"</li> <li>Phillips screw drivers, flex extension</li> <li>Grease gun (if 4x4) for zerks on drive shaft</li> </ul>"}]}